{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exact solution u = H\n",
    "def exact_solution_h(x, y, t):\n",
    "    return -torch.sin(x)*torch.sin(y)*torch.cos(t)\n",
    "\n",
    "def initial_condition_h(x, y):\n",
    "    return -torch.sin(x)*torch.sin(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exact solution p = E\n",
    "def exact_solution_e1(x, y, t):\n",
    "    return -torch.sin(x)*torch.sin(t)*torch.cos(y)\n",
    "\n",
    "def initial_condition_e1(x, y):\n",
    "    return 0.0*torch.sin(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exact solution p = E\n",
    "def exact_solution_e2(x, y, t):\n",
    "    return torch.sin(y)*torch.sin(t)*torch.cos(x)\n",
    "\n",
    "def initial_condition_e2(x, y):\n",
    "    return 0.0*torch.sin(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning number of points\n",
    "initial_pts = 200 \n",
    "left_boundary_pts = 200 \n",
    "right_boundary_pts = 200\n",
    "back_boundary_pts = 200\n",
    "front_boundary_pts = 200\n",
    "residual_pts = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of optimizer (ADAM or LBFGS)\n",
    "opt_type = \"LBFGS\"\n",
    "\n",
    "x_init = torch.rand((initial_pts,1)) # initial pts\n",
    "y_init = torch.rand((initial_pts,1))\n",
    "t_init =  0*x_init\n",
    "init =  torch.cat([x_init, y_init, t_init],1)\n",
    "h_init = initial_condition_h(init[:,0], init[:, 1]).reshape(-1, 1)\n",
    "e1_init = initial_condition_e1(init[:,0], init[:, 1]).reshape(-1, 1)\n",
    "e2_init = initial_condition_e2(init[:,0], init[:, 1]).reshape(-1, 1)\n",
    "w_init = torch.cat([h_init, e1_init, e2_init],1)\n",
    "\n",
    "\n",
    "xb_left = torch.zeros((left_boundary_pts, 1)) # left spatial boundary\n",
    "yb_left = torch.rand((left_boundary_pts, 1)) # left spatial boundary\n",
    "tb_left = torch.rand((left_boundary_pts, 1)) # \n",
    "b_left = torch.cat([xb_left, yb_left, tb_left ],1)\n",
    "h_b_l = exact_solution_h(xb_left, yb_left, tb_left).reshape(-1, 1)\n",
    "e1_b_l = exact_solution_e1(xb_left, yb_left, tb_left).reshape(-1, 1)\n",
    "e2_b_l = exact_solution_e2(xb_left, yb_left, tb_left).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "xb_right = torch.ones((right_boundary_pts, 1)) # right spatial boundary\n",
    "yb_right = torch.rand((right_boundary_pts, 1)) # right spatial boundary\n",
    "tb_right = torch.rand((right_boundary_pts, 1)) # right boundary pts\n",
    "b_right = torch.cat([xb_right, yb_right, tb_right ],1)\n",
    "h_b_r = exact_solution_h(xb_right, yb_right, tb_right).reshape(-1, 1)\n",
    "e1_b_r = exact_solution_e1(xb_right, yb_right, tb_right).reshape(-1, 1)\n",
    "e2_b_r = exact_solution_e2(xb_right, yb_right, tb_right).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "xb_front = torch.rand((front_boundary_pts, 1)) # front spatial boundary\n",
    "yb_front = torch.zeros((front_boundary_pts, 1)) # front spatial boundary\n",
    "tb_front = torch.rand((front_boundary_pts, 1)) # \n",
    "b_front = torch.cat([xb_front, yb_front, tb_front ],1)\n",
    "h_b_f = exact_solution_h(xb_front, yb_front, tb_front).reshape(-1, 1)\n",
    "e1_b_f = exact_solution_e1(xb_front, yb_front, tb_front).reshape(-1, 1)\n",
    "e2_b_f = exact_solution_e2(xb_front, yb_front, tb_front).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "xb_back = torch.rand((back_boundary_pts, 1)) # back spatial boundary\n",
    "yb_back = torch.ones((back_boundary_pts, 1)) # back spatial boundary\n",
    "tb_back = torch.rand((back_boundary_pts, 1)) # back boundary pts\n",
    "b_back = torch.cat([xb_back, yb_back, tb_back ],1)\n",
    "h_b_b = exact_solution_h(xb_back, yb_back, tb_back).reshape(-1, 1)\n",
    "e1_b_b = exact_solution_e1(xb_back, yb_back, tb_back).reshape(-1, 1)\n",
    "e2_b_b = exact_solution_e2(xb_back, yb_back, tb_back).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "x_interior = torch.rand((residual_pts, 1))\n",
    "y_interior = torch.rand((residual_pts, 1))\n",
    "t_interior = torch.rand((residual_pts, 1))\n",
    "interior = torch.cat([x_interior, y_interior, t_interior],1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_set = DataLoader(torch.utils.data.TensorDataset(init, w_init, b_left,  b_right, b_front, b_back), batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension, output_dimension, n_hidden_layers, neurons):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # Number of input dimensions n\n",
    "        self.input_dimension = input_dimension\n",
    "        # Number of output dimensions m\n",
    "        self.output_dimension = output_dimension\n",
    "        # Number of neurons per layer \n",
    "        self.neurons = neurons\n",
    "        # Number of hidden layers \n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        # Activation function \n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        self.input_layer = nn.Linear(self.input_dimension, self.neurons)\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(self.neurons, self.neurons) for _ in range(n_hidden_layers)])\n",
    "        self.output_layer = nn.Linear(self.neurons, self.output_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward function performs the set of affine and non-linear transformations defining the network \n",
    "        # (see equation above)\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        for k, l in enumerate(self.hidden_layers):\n",
    "            x = self.activation(l(x))\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "my_network = NeuralNet(input_dimension = init.shape[1], output_dimension = w_init.shape[1], n_hidden_layers=4, neurons=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_xavier(model, retrain_seed):\n",
    "    torch.manual_seed(retrain_seed)\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear and m.weight.requires_grad and m.bias.requires_grad:\n",
    "            g = nn.init.calculate_gain('tanh')\n",
    "            torch.nn.init.xavier_uniform_(m.weight, gain=g)\n",
    "            #torch.nn.init.xavier_normal_(m.weight, gain=g)\n",
    "            m.bias.data.fill_(0)\n",
    "    model.apply(init_weights)\n",
    "\n",
    "# Random Seed for weight initialization\n",
    "retrain = 128\n",
    "# Xavier weight initialization\n",
    "init_xavier(my_network, retrain)\n",
    "#print(my_network(init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt_type == \"ADAM\":\n",
    "    optimizer_ = optim.Adam(my_network.parameters(), lr=0.001)\n",
    "elif opt_type == \"LBFGS\":\n",
    "    optimizer_ = optim.LBFGS(my_network.parameters(), lr=0.1, max_iter=1, max_eval=50000, tolerance_change=1.0 * np.finfo(float).eps)\n",
    "else:\n",
    "    raise ValueError(\"Optimizer not recognized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, training_set, interior, num_epochs, optimizer, p, verbose=True):\n",
    "    history = list()\n",
    "    \n",
    "    # Loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose: print(\"################################ \", epoch, \" ################################\")\n",
    "\n",
    "        running_loss = list([0])\n",
    "        \n",
    "        # Loop over batches\n",
    "        for j, (initial, w_initial, bd_left,  bd_right, bd_front, bd_back) in enumerate(training_set):\n",
    "            \n",
    "            def closure():\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # for initial\n",
    "                initial.requires_grad = True\n",
    "                w_initial_pred_ = model(initial)\n",
    "                h_initial_pred_ = w_initial_pred_[:,0].reshape(-1,1)\n",
    "                e1_initial_pred_ = w_initial_pred_[:,1].reshape(-1,1)\n",
    "                e2_initial_pred_ = w_initial_pred_[:,2].reshape(-1,1)\n",
    "                \n",
    "                \n",
    "                # with derivative\n",
    "                inpu = torch.ones(initial_pts, 1 )\n",
    "                \n",
    "                grad_h_ini = torch.autograd.grad(h_initial_pred_, initial, grad_outputs=inpu, create_graph=True, allow_unused=True)[0]\n",
    "                h_initial_t = grad_h_ini[:, 2]\n",
    "                \n",
    "                grad_e1_ini = torch.autograd.grad(e1_initial_pred_, initial, grad_outputs=inpu, create_graph=True, allow_unused=True)[0]\n",
    "                e1_initial_t = grad_e1_ini[:, 2]\n",
    "                \n",
    "                grad_e2_ini = torch.autograd.grad(e2_initial_pred_, initial, grad_outputs=inpu, create_graph=True, allow_unused=True)[0]\n",
    "                e2_initial_t = grad_e2_ini[:, 2]\n",
    "                \n",
    "                \n",
    "                \n",
    "                # for left boundary\n",
    "                w_bd_left_pred_ = model(bd_left)\n",
    "                h_bd_left_pred_ = w_bd_left_pred_[:,0].reshape(-1,1)\n",
    "                e1_bd_left_pred_ = w_bd_left_pred_[:,1].reshape(-1,1)\n",
    "                e2_bd_left_pred_ = w_bd_left_pred_[:,2].reshape(-1,1)\n",
    "                \n",
    "                # for right boundary\n",
    "                w_bd_right_pred_ = model(bd_right)\n",
    "                h_bd_right_pred_ = w_bd_right_pred_[:,0].reshape(-1,1)\n",
    "                e1_bd_right_pred_ = w_bd_right_pred_[:,1].reshape(-1,1)\n",
    "                e2_bd_right_pred_ = w_bd_right_pred_[:,2].reshape(-1,1)\n",
    "                \n",
    "                # for front boundary\n",
    "                w_bd_front_pred_ = model(bd_front)\n",
    "                h_bd_front_pred_ = w_bd_front_pred_[:,0].reshape(-1,1)\n",
    "                e1_bd_front_pred_ = w_bd_front_pred_[:,1].reshape(-1,1)\n",
    "                e2_bd_front_pred_ = w_bd_front_pred_[:,2].reshape(-1,1)\n",
    "                \n",
    "                # for back boundary\n",
    "                w_bd_back_pred_ = model(bd_back)\n",
    "                h_bd_back_pred_ = w_bd_back_pred_[:,0].reshape(-1,1)\n",
    "                e1_bd_back_pred_ = w_bd_back_pred_[:,1].reshape(-1,1)\n",
    "                e2_bd_back_pred_ = w_bd_back_pred_[:,2].reshape(-1,1)\n",
    "                \n",
    "                # residual calculation\n",
    "                interior.requires_grad = True\n",
    "                w_hat = model(interior)\n",
    "                h_hat = w_hat[:,0].reshape(-1,1)\n",
    "                e1_hat = w_hat[:,1].reshape(-1,1)\n",
    "                e2_hat = w_hat[:,2].reshape(-1,1)\n",
    "                \n",
    "                inputs = torch.ones(residual_pts, 1 )\n",
    "                inputs2 = torch.ones(residual_pts, 1)\n",
    "                \n",
    "                grad_h_hat = torch.autograd.grad(h_hat.reshape(-1,1), interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                h_x = grad_h_hat[:, 0].reshape(-1,1)\n",
    "                h_y = grad_h_hat[:, 1].reshape(-1,1)\n",
    "                \n",
    "                grad_e1_hat = torch.autograd.grad(e1_hat, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                e1_x = grad_e1_hat[:, 0].reshape(-1,1)\n",
    "                e1_y = grad_e1_hat[:, 1].reshape(-1,1)\n",
    "                \n",
    "                grad_e2_hat = torch.autograd.grad(e2_hat, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                e2_x = grad_e2_hat[:, 0].reshape(-1,1)\n",
    "                e2_y = grad_e2_hat[:, 1].reshape(-1,1)\n",
    "                \n",
    "                h_t = grad_h_hat[:, 2].reshape(-1,1)\n",
    "                e1_t = grad_e1_hat[:, 2].reshape(-1,1)\n",
    "                e2_t = grad_e2_hat[:, 2].reshape(-1,1)\n",
    "                \n",
    "                \n",
    "                # Item 1. below\n",
    "                loss1 = torch.mean((h_initial_pred_.reshape(-1, ) - w_initial[:,0].reshape(-1, ))**p) + torch.mean((2*h_t.reshape(-1, ) + e2_x.reshape(-1, ) - e1_y.reshape(-1, ))**p)+torch.mean((h_bd_left_pred_.reshape(-1,)- h_b_l.reshape(-1,))**p) + torch.mean((h_bd_right_pred_.reshape(-1,)- h_b_r.reshape(-1,))**p) +torch.mean((h_bd_front_pred_.reshape(-1,)- h_b_f.reshape(-1,))**p) + torch.mean((h_bd_back_pred_.reshape(-1,)- h_b_b.reshape(-1,))**p)\n",
    "                loss2 = torch.mean((e1_initial_pred_.reshape(-1, ) - w_initial[:,1].reshape(-1, ))**p)+ torch.mean((4*e1_t.reshape(-1, ) + 2*torch.cos(interior[:, 0])*torch.cos(interior[:, 2])*torch.sin(interior[:, 1]) - h_y.reshape(-1, ) + 3*torch.sin(interior[:, 0])*torch.cos(interior[:, 2])*torch.cos(interior[:, 1]) - 2*torch.cos(interior[:, 0])*torch.cos(interior[:, 2])*torch.sin(interior[:, 1]) )**p) +torch.mean((e1_bd_left_pred_.reshape(-1,)- e1_b_l.reshape(-1,))**p) + torch.mean((e1_bd_right_pred_.reshape(-1,)- e1_b_r.reshape(-1,))**p) +torch.mean((e1_bd_front_pred_.reshape(-1,)- e1_b_f.reshape(-1,))**p) + torch.mean((e1_bd_back_pred_.reshape(-1,)- e1_b_b.reshape(-1,))**p)\n",
    "                loss3 = torch.mean((e2_initial_pred_.reshape(-1, ) - w_initial[:,2].reshape(-1, ))**p)+ torch.mean((-2*torch.sin(interior[:, 0])*torch.cos(interior[:, 2])*torch.cos(interior[:, 1]) + e2_t.reshape(-1, )  + h_x.reshape(-1, ) + 2*torch.sin(interior[:, 0])*torch.cos(interior[:, 2])*torch.cos(interior[:, 1]))**p) +torch.mean((e2_bd_left_pred_.reshape(-1,)- e2_b_l.reshape(-1,))**p) + torch.mean((e2_bd_right_pred_.reshape(-1,)- e2_b_r.reshape(-1,))**p) +torch.mean((e2_bd_front_pred_.reshape(-1,)- e2_b_f.reshape(-1,))**p) + torch.mean((e2_bd_back_pred_.reshape(-1,)- e2_b_b.reshape(-1,))**p)\n",
    "                loss = loss1 + loss2 + loss3\n",
    "                \n",
    "                # Item 2. below\n",
    "                loss.backward()\n",
    "                # Compute average training loss over batches for the current epoch\n",
    "                running_loss[0] += loss.item()\n",
    "                return loss\n",
    "            \n",
    "            # Item 3. below\n",
    "            optimizer.step(closure=closure)\n",
    "            \n",
    "        print('Loss: ', (running_loss[0] / len(training_set)))\n",
    "        history.append(running_loss[0])\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################  0  ################################\n",
      "Loss:  137.0339813232422\n",
      "################################  1  ################################\n",
      "Loss:  134.1363067626953\n",
      "################################  2  ################################\n",
      "Loss:  113.90143585205078\n",
      "################################  3  ################################\n",
      "Loss:  89.89928436279297\n",
      "################################  4  ################################\n",
      "Loss:  66.98069763183594\n",
      "################################  5  ################################\n",
      "Loss:  53.799625396728516\n",
      "################################  6  ################################\n",
      "Loss:  45.88216781616211\n",
      "################################  7  ################################\n",
      "Loss:  40.06132888793945\n",
      "################################  8  ################################\n",
      "Loss:  35.32625198364258\n",
      "################################  9  ################################\n",
      "Loss:  31.256216049194336\n",
      "################################  10  ################################\n",
      "Loss:  27.63594627380371\n",
      "################################  11  ################################\n",
      "Loss:  24.360502243041992\n",
      "################################  12  ################################\n",
      "Loss:  21.389114379882812\n",
      "################################  13  ################################\n",
      "Loss:  18.709484100341797\n",
      "################################  14  ################################\n",
      "Loss:  16.31264305114746\n",
      "################################  15  ################################\n",
      "Loss:  14.183518409729004\n",
      "################################  16  ################################\n",
      "Loss:  12.302112579345703\n",
      "################################  17  ################################\n",
      "Loss:  10.646367073059082\n",
      "################################  18  ################################\n",
      "Loss:  9.193841934204102\n",
      "################################  19  ################################\n",
      "Loss:  7.92308235168457\n",
      "################################  20  ################################\n",
      "Loss:  6.815066814422607\n",
      "################################  21  ################################\n",
      "Loss:  5.853765487670898\n",
      "################################  22  ################################\n",
      "Loss:  5.025311470031738\n",
      "################################  23  ################################\n",
      "Loss:  4.316593647003174\n",
      "################################  24  ################################\n",
      "Loss:  3.714298725128174\n",
      "################################  25  ################################\n",
      "Loss:  3.2048258781433105\n",
      "################################  26  ################################\n",
      "Loss:  2.7747669219970703\n",
      "################################  27  ################################\n",
      "Loss:  2.4115445613861084\n",
      "################################  28  ################################\n",
      "Loss:  2.1039164066314697\n",
      "################################  29  ################################\n",
      "Loss:  1.8422600030899048\n",
      "################################  30  ################################\n",
      "Loss:  1.61861252784729\n",
      "################################  31  ################################\n",
      "Loss:  1.426530361175537\n",
      "################################  32  ################################\n",
      "Loss:  1.2608528137207031\n",
      "################################  33  ################################\n",
      "Loss:  1.1174664497375488\n",
      "################################  34  ################################\n",
      "Loss:  0.9925327301025391\n",
      "################################  35  ################################\n",
      "Loss:  0.8763650059700012\n",
      "################################  36  ################################\n",
      "Loss:  0.7614933252334595\n",
      "################################  37  ################################\n",
      "Loss:  0.6871019601821899\n",
      "################################  38  ################################\n",
      "Loss:  0.6245167255401611\n",
      "################################  39  ################################\n",
      "Loss:  0.567598819732666\n",
      "################################  40  ################################\n",
      "Loss:  0.5116422176361084\n",
      "################################  41  ################################\n",
      "Loss:  0.4604496359825134\n",
      "################################  42  ################################\n",
      "Loss:  0.424297571182251\n",
      "################################  43  ################################\n",
      "Loss:  0.3904067575931549\n",
      "################################  44  ################################\n",
      "Loss:  0.3576867878437042\n",
      "################################  45  ################################\n",
      "Loss:  0.3296435475349426\n",
      "################################  46  ################################\n",
      "Loss:  0.30009061098098755\n",
      "################################  47  ################################\n",
      "Loss:  0.27575981616973877\n",
      "################################  48  ################################\n",
      "Loss:  0.2550259530544281\n",
      "################################  49  ################################\n",
      "Loss:  0.23437118530273438\n",
      "################################  50  ################################\n",
      "Loss:  0.2180679738521576\n",
      "################################  51  ################################\n",
      "Loss:  0.20300857722759247\n",
      "################################  52  ################################\n",
      "Loss:  0.1893351972103119\n",
      "################################  53  ################################\n",
      "Loss:  0.17782855033874512\n",
      "################################  54  ################################\n",
      "Loss:  0.1665532886981964\n",
      "################################  55  ################################\n",
      "Loss:  0.15699227154254913\n",
      "################################  56  ################################\n",
      "Loss:  0.14606820046901703\n",
      "################################  57  ################################\n",
      "Loss:  0.13697054982185364\n",
      "################################  58  ################################\n",
      "Loss:  0.12722840905189514\n",
      "################################  59  ################################\n",
      "Loss:  0.11783527582883835\n",
      "################################  60  ################################\n",
      "Loss:  0.11046788096427917\n",
      "################################  61  ################################\n",
      "Loss:  0.10199645161628723\n",
      "################################  62  ################################\n",
      "Loss:  0.09654057770967484\n",
      "################################  63  ################################\n",
      "Loss:  0.09096147119998932\n",
      "################################  64  ################################\n",
      "Loss:  0.08592632412910461\n",
      "################################  65  ################################\n",
      "Loss:  0.08109687268733978\n",
      "################################  66  ################################\n",
      "Loss:  0.07666015625\n",
      "################################  67  ################################\n",
      "Loss:  0.07250663638114929\n",
      "################################  68  ################################\n",
      "Loss:  0.06891882419586182\n",
      "################################  69  ################################\n",
      "Loss:  0.06565877795219421\n",
      "################################  70  ################################\n",
      "Loss:  0.06258096545934677\n",
      "################################  71  ################################\n",
      "Loss:  0.0597492977976799\n",
      "################################  72  ################################\n",
      "Loss:  0.05698096752166748\n",
      "################################  73  ################################\n",
      "Loss:  0.054429199546575546\n",
      "################################  74  ################################\n",
      "Loss:  0.05193908512592316\n",
      "################################  75  ################################\n",
      "Loss:  0.04959499463438988\n",
      "################################  76  ################################\n",
      "Loss:  0.047375600785017014\n",
      "################################  77  ################################\n",
      "Loss:  0.0452091284096241\n",
      "################################  78  ################################\n",
      "Loss:  0.04313987120985985\n",
      "################################  79  ################################\n",
      "Loss:  0.04108194261789322\n",
      "################################  80  ################################\n",
      "Loss:  0.03907381743192673\n",
      "################################  81  ################################\n",
      "Loss:  0.03701172024011612\n",
      "################################  82  ################################\n",
      "Loss:  0.034985899925231934\n",
      "################################  83  ################################\n",
      "Loss:  0.03303757309913635\n",
      "################################  84  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.03122430108487606\n",
      "################################  85  ################################\n",
      "Loss:  0.029567496851086617\n",
      "################################  86  ################################\n",
      "Loss:  0.028024829924106598\n",
      "################################  87  ################################\n",
      "Loss:  0.02657976746559143\n",
      "################################  88  ################################\n",
      "Loss:  0.02524963952600956\n",
      "################################  89  ################################\n",
      "Loss:  0.02397732250392437\n",
      "################################  90  ################################\n",
      "Loss:  0.02281743474304676\n",
      "################################  91  ################################\n",
      "Loss:  0.02175598405301571\n",
      "################################  92  ################################\n",
      "Loss:  0.020787885412573814\n",
      "################################  93  ################################\n",
      "Loss:  0.01989966258406639\n",
      "################################  94  ################################\n",
      "Loss:  0.019093062728643417\n",
      "################################  95  ################################\n",
      "Loss:  0.01833522878587246\n",
      "################################  96  ################################\n",
      "Loss:  0.017668312415480614\n",
      "################################  97  ################################\n",
      "Loss:  0.01702890917658806\n",
      "################################  98  ################################\n",
      "Loss:  0.016465935856103897\n",
      "################################  99  ################################\n",
      "Loss:  0.015909945592284203\n",
      "################################  100  ################################\n",
      "Loss:  0.015411682426929474\n",
      "################################  101  ################################\n",
      "Loss:  0.014919552020728588\n",
      "################################  102  ################################\n",
      "Loss:  0.014461309649050236\n",
      "################################  103  ################################\n",
      "Loss:  0.01398453302681446\n",
      "################################  104  ################################\n",
      "Loss:  0.01352757215499878\n",
      "################################  105  ################################\n",
      "Loss:  0.01306105311959982\n",
      "################################  106  ################################\n",
      "Loss:  0.012594913132488728\n",
      "################################  107  ################################\n",
      "Loss:  0.012144094333052635\n",
      "################################  108  ################################\n",
      "Loss:  0.01167928334325552\n",
      "################################  109  ################################\n",
      "Loss:  0.011228794232010841\n",
      "################################  110  ################################\n",
      "Loss:  0.010786999017000198\n",
      "################################  111  ################################\n",
      "Loss:  0.010346862487494946\n",
      "################################  112  ################################\n",
      "Loss:  0.00994456559419632\n",
      "################################  113  ################################\n",
      "Loss:  0.009553559124469757\n",
      "################################  114  ################################\n",
      "Loss:  0.009195451624691486\n",
      "################################  115  ################################\n",
      "Loss:  0.008849356323480606\n",
      "################################  116  ################################\n",
      "Loss:  0.008518138900399208\n",
      "################################  117  ################################\n",
      "Loss:  0.008201759308576584\n",
      "################################  118  ################################\n",
      "Loss:  0.007898068055510521\n",
      "################################  119  ################################\n",
      "Loss:  0.007633046247065067\n",
      "################################  120  ################################\n",
      "Loss:  0.007386409677565098\n",
      "################################  121  ################################\n",
      "Loss:  0.007160330656915903\n",
      "################################  122  ################################\n",
      "Loss:  0.006951444316655397\n",
      "################################  123  ################################\n",
      "Loss:  0.006757059600204229\n",
      "################################  124  ################################\n",
      "Loss:  0.006576489191502333\n",
      "################################  125  ################################\n",
      "Loss:  0.006407845299690962\n",
      "################################  126  ################################\n",
      "Loss:  0.006256517022848129\n",
      "################################  127  ################################\n",
      "Loss:  0.006116590462625027\n",
      "################################  128  ################################\n",
      "Loss:  0.005991040728986263\n",
      "################################  129  ################################\n",
      "Loss:  0.005874380003660917\n",
      "################################  130  ################################\n",
      "Loss:  0.005764498375356197\n",
      "################################  131  ################################\n",
      "Loss:  0.005660536698997021\n",
      "################################  132  ################################\n",
      "Loss:  0.00556035153567791\n",
      "################################  133  ################################\n",
      "Loss:  0.005464581772685051\n",
      "################################  134  ################################\n",
      "Loss:  0.005372588522732258\n",
      "################################  135  ################################\n",
      "Loss:  0.005284218117594719\n",
      "################################  136  ################################\n",
      "Loss:  0.005199245642870665\n",
      "################################  137  ################################\n",
      "Loss:  0.005115729756653309\n",
      "################################  138  ################################\n",
      "Loss:  0.005035088397562504\n",
      "################################  139  ################################\n",
      "Loss:  0.004954962991178036\n",
      "################################  140  ################################\n",
      "Loss:  0.0048774732276797295\n",
      "################################  141  ################################\n",
      "Loss:  0.0048003653064370155\n",
      "################################  142  ################################\n",
      "Loss:  0.004724565893411636\n",
      "################################  143  ################################\n",
      "Loss:  0.004649484064429998\n",
      "################################  144  ################################\n",
      "Loss:  0.004574736580252647\n",
      "################################  145  ################################\n",
      "Loss:  0.004502297379076481\n",
      "################################  146  ################################\n",
      "Loss:  0.004430251196026802\n",
      "################################  147  ################################\n",
      "Loss:  0.004358880687505007\n",
      "################################  148  ################################\n",
      "Loss:  0.004285857081413269\n",
      "################################  149  ################################\n",
      "Loss:  0.004215112421661615\n",
      "################################  150  ################################\n",
      "Loss:  0.00414873193949461\n",
      "################################  151  ################################\n",
      "Loss:  0.004082792904227972\n",
      "################################  152  ################################\n",
      "Loss:  0.004020482301712036\n",
      "################################  153  ################################\n",
      "Loss:  0.003957116045057774\n",
      "################################  154  ################################\n",
      "Loss:  0.00389524782076478\n",
      "################################  155  ################################\n",
      "Loss:  0.0038327458314597607\n",
      "################################  156  ################################\n",
      "Loss:  0.0037719765678048134\n",
      "################################  157  ################################\n",
      "Loss:  0.003712903941050172\n",
      "################################  158  ################################\n",
      "Loss:  0.0036519260611385107\n",
      "################################  159  ################################\n",
      "Loss:  0.0035924813710153103\n",
      "################################  160  ################################\n",
      "Loss:  0.003535577328875661\n",
      "################################  161  ################################\n",
      "Loss:  0.0034809475764632225\n",
      "################################  162  ################################\n",
      "Loss:  0.00342971901409328\n",
      "################################  163  ################################\n",
      "Loss:  0.003377665998414159\n",
      "################################  164  ################################\n",
      "Loss:  0.0033327671699225903\n",
      "################################  165  ################################\n",
      "Loss:  0.0032877218909561634\n",
      "################################  166  ################################\n",
      "Loss:  0.00324522377923131\n",
      "################################  167  ################################\n",
      "Loss:  0.0032019850332289934\n",
      "################################  168  ################################\n",
      "Loss:  0.0031525706872344017\n",
      "################################  169  ################################\n",
      "Loss:  0.003106431569904089\n",
      "################################  170  ################################\n",
      "Loss:  0.0030627308879047632\n",
      "################################  171  ################################\n",
      "Loss:  0.0030176397413015366\n",
      "################################  172  ################################\n",
      "Loss:  0.0029721041209995747\n",
      "################################  173  ################################\n",
      "Loss:  0.002927448134869337\n",
      "################################  174  ################################\n",
      "Loss:  0.0028859348967671394\n",
      "################################  175  ################################\n",
      "Loss:  0.00284657534211874\n",
      "################################  176  ################################\n",
      "Loss:  0.002808251418173313\n",
      "################################  177  ################################\n",
      "Loss:  0.0027716467157006264\n",
      "################################  178  ################################\n",
      "Loss:  0.0027355332858860493\n",
      "################################  179  ################################\n",
      "Loss:  0.0027004475705325603\n",
      "################################  180  ################################\n",
      "Loss:  0.0026656375266611576\n",
      "################################  181  ################################\n",
      "Loss:  0.0026317110750824213\n",
      "################################  182  ################################\n",
      "Loss:  0.0025993622839450836\n",
      "################################  183  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.002569020725786686\n",
      "################################  184  ################################\n",
      "Loss:  0.0025395641569048166\n",
      "################################  185  ################################\n",
      "Loss:  0.0025109786074608564\n",
      "################################  186  ################################\n",
      "Loss:  0.002482098061591387\n",
      "################################  187  ################################\n",
      "Loss:  0.0024527423083782196\n",
      "################################  188  ################################\n",
      "Loss:  0.0024243162479251623\n",
      "################################  189  ################################\n",
      "Loss:  0.0023961130063980818\n",
      "################################  190  ################################\n",
      "Loss:  0.0023689279332756996\n",
      "################################  191  ################################\n",
      "Loss:  0.002342216670513153\n",
      "################################  192  ################################\n",
      "Loss:  0.002315706107765436\n",
      "################################  193  ################################\n",
      "Loss:  0.00228868518024683\n",
      "################################  194  ################################\n",
      "Loss:  0.0022611920721828938\n",
      "################################  195  ################################\n",
      "Loss:  0.0022344933822751045\n",
      "################################  196  ################################\n",
      "Loss:  0.0022079988848417997\n",
      "################################  197  ################################\n",
      "Loss:  0.002183073665946722\n",
      "################################  198  ################################\n",
      "Loss:  0.0021591957192867994\n",
      "################################  199  ################################\n",
      "Loss:  0.002135353395715356\n",
      "################################  200  ################################\n",
      "Loss:  0.0021113939583301544\n",
      "################################  201  ################################\n",
      "Loss:  0.0020875404588878155\n",
      "################################  202  ################################\n",
      "Loss:  0.0020637675188481808\n",
      "################################  203  ################################\n",
      "Loss:  0.0020399964414536953\n",
      "################################  204  ################################\n",
      "Loss:  0.002017428632825613\n",
      "################################  205  ################################\n",
      "Loss:  0.0019951595459133387\n",
      "################################  206  ################################\n",
      "Loss:  0.001973384525626898\n",
      "################################  207  ################################\n",
      "Loss:  0.0019520659698173404\n",
      "################################  208  ################################\n",
      "Loss:  0.0019316192483529449\n",
      "################################  209  ################################\n",
      "Loss:  0.0019120308570563793\n",
      "################################  210  ################################\n",
      "Loss:  0.0018931066151708364\n",
      "################################  211  ################################\n",
      "Loss:  0.0018749837763607502\n",
      "################################  212  ################################\n",
      "Loss:  0.001856641611084342\n",
      "################################  213  ################################\n",
      "Loss:  0.0018391420599073172\n",
      "################################  214  ################################\n",
      "Loss:  0.001820824109017849\n",
      "################################  215  ################################\n",
      "Loss:  0.0018057324923574924\n",
      "################################  216  ################################\n",
      "Loss:  0.0017878639046102762\n",
      "################################  217  ################################\n",
      "Loss:  0.001769564114511013\n",
      "################################  218  ################################\n",
      "Loss:  0.001751261530444026\n",
      "################################  219  ################################\n",
      "Loss:  0.0017351190326735377\n",
      "################################  220  ################################\n",
      "Loss:  0.0017198928399011493\n",
      "################################  221  ################################\n",
      "Loss:  0.0017040728125721216\n",
      "################################  222  ################################\n",
      "Loss:  0.0016886182129383087\n",
      "################################  223  ################################\n",
      "Loss:  0.0016735814278945327\n",
      "################################  224  ################################\n",
      "Loss:  0.0016586846904829144\n",
      "################################  225  ################################\n",
      "Loss:  0.001644634292460978\n",
      "################################  226  ################################\n",
      "Loss:  0.0016308240592479706\n",
      "################################  227  ################################\n",
      "Loss:  0.0016177936922758818\n",
      "################################  228  ################################\n",
      "Loss:  0.0016048925463110209\n",
      "################################  229  ################################\n",
      "Loss:  0.0015921080484986305\n",
      "################################  230  ################################\n",
      "Loss:  0.0015792648773640394\n",
      "################################  231  ################################\n",
      "Loss:  0.001567101920954883\n",
      "################################  232  ################################\n",
      "Loss:  0.0015551599208265543\n",
      "################################  233  ################################\n",
      "Loss:  0.0015428498154506087\n",
      "################################  234  ################################\n",
      "Loss:  0.0015306593850255013\n",
      "################################  235  ################################\n",
      "Loss:  0.0015188474208116531\n",
      "################################  236  ################################\n",
      "Loss:  0.001507624750956893\n",
      "################################  237  ################################\n",
      "Loss:  0.0014966132584959269\n",
      "################################  238  ################################\n",
      "Loss:  0.0014865699922665954\n",
      "################################  239  ################################\n",
      "Loss:  0.0014769810950383544\n",
      "################################  240  ################################\n",
      "Loss:  0.0014677844010293484\n",
      "################################  241  ################################\n",
      "Loss:  0.001459214836359024\n",
      "################################  242  ################################\n",
      "Loss:  0.0014506683219224215\n",
      "################################  243  ################################\n",
      "Loss:  0.0014429837465286255\n",
      "################################  244  ################################\n",
      "Loss:  0.0014350719284266233\n",
      "################################  245  ################################\n",
      "Loss:  0.0014270894462242723\n",
      "################################  246  ################################\n",
      "Loss:  0.0014188464265316725\n",
      "################################  247  ################################\n",
      "Loss:  0.0014103095745667815\n",
      "################################  248  ################################\n",
      "Loss:  0.0014019148657098413\n",
      "################################  249  ################################\n",
      "Loss:  0.0013933891896158457\n",
      "################################  250  ################################\n",
      "Loss:  0.001385464915074408\n",
      "################################  251  ################################\n",
      "Loss:  0.001377115841023624\n",
      "################################  252  ################################\n",
      "Loss:  0.0013696309179067612\n",
      "################################  253  ################################\n",
      "Loss:  0.0013615621719509363\n",
      "################################  254  ################################\n",
      "Loss:  0.0013529977295547724\n",
      "################################  255  ################################\n",
      "Loss:  0.0013444869546219707\n",
      "################################  256  ################################\n",
      "Loss:  0.0013355235569179058\n",
      "################################  257  ################################\n",
      "Loss:  0.0013272478245198727\n",
      "################################  258  ################################\n",
      "Loss:  0.0013185776770114899\n",
      "################################  259  ################################\n",
      "Loss:  0.0013106388505548239\n",
      "################################  260  ################################\n",
      "Loss:  0.0013022605562582612\n",
      "################################  261  ################################\n",
      "Loss:  0.0012935578124597669\n",
      "################################  262  ################################\n",
      "Loss:  0.0012843667063862085\n",
      "################################  263  ################################\n",
      "Loss:  0.001274679321795702\n",
      "################################  264  ################################\n",
      "Loss:  0.0012655695900321007\n",
      "################################  265  ################################\n",
      "Loss:  0.0012560811592265964\n",
      "################################  266  ################################\n",
      "Loss:  0.00124690355733037\n",
      "################################  267  ################################\n",
      "Loss:  0.0012382210697978735\n",
      "################################  268  ################################\n",
      "Loss:  0.0012296063359826803\n",
      "################################  269  ################################\n",
      "Loss:  0.001221805578097701\n",
      "################################  270  ################################\n",
      "Loss:  0.001213947543874383\n",
      "################################  271  ################################\n",
      "Loss:  0.0012062995228916407\n",
      "################################  272  ################################\n",
      "Loss:  0.0011989973718300462\n",
      "################################  273  ################################\n",
      "Loss:  0.0011915075592696667\n",
      "################################  274  ################################\n",
      "Loss:  0.0011846576817333698\n",
      "################################  275  ################################\n",
      "Loss:  0.001178045873530209\n",
      "################################  276  ################################\n",
      "Loss:  0.0011715767905116081\n",
      "################################  277  ################################\n",
      "Loss:  0.0011652333196252584\n",
      "################################  278  ################################\n",
      "Loss:  0.001159120351076126\n",
      "################################  279  ################################\n",
      "Loss:  0.001153282355517149\n",
      "################################  280  ################################\n",
      "Loss:  0.0011476639192551374\n",
      "################################  281  ################################\n",
      "Loss:  0.001142427558079362\n",
      "################################  282  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0011373843299224973\n",
      "################################  283  ################################\n",
      "Loss:  0.0011323620565235615\n",
      "################################  284  ################################\n",
      "Loss:  0.001127481460571289\n",
      "################################  285  ################################\n",
      "Loss:  0.0011224646586924791\n",
      "################################  286  ################################\n",
      "Loss:  0.001117593958042562\n",
      "################################  287  ################################\n",
      "Loss:  0.0011127105681225657\n",
      "################################  288  ################################\n",
      "Loss:  0.0011078794486820698\n",
      "################################  289  ################################\n",
      "Loss:  0.0011031043250113726\n",
      "################################  290  ################################\n",
      "Loss:  0.0010983586544170976\n",
      "################################  291  ################################\n",
      "Loss:  0.0010935793397948146\n",
      "################################  292  ################################\n",
      "Loss:  0.0010889454279094934\n",
      "################################  293  ################################\n",
      "Loss:  0.0010843084892258048\n",
      "################################  294  ################################\n",
      "Loss:  0.001079794019460678\n",
      "################################  295  ################################\n",
      "Loss:  0.0010753218084573746\n",
      "################################  296  ################################\n",
      "Loss:  0.0010706889443099499\n",
      "################################  297  ################################\n",
      "Loss:  0.001066046068444848\n",
      "################################  298  ################################\n",
      "Loss:  0.0010612719925120473\n",
      "################################  299  ################################\n",
      "Loss:  0.0010564777767285705\n",
      "################################  300  ################################\n",
      "Loss:  0.00105161196552217\n",
      "################################  301  ################################\n",
      "Loss:  0.0010468345135450363\n",
      "################################  302  ################################\n",
      "Loss:  0.0010422312188893557\n",
      "################################  303  ################################\n",
      "Loss:  0.0010377968428656459\n",
      "################################  304  ################################\n",
      "Loss:  0.0010334544349461794\n",
      "################################  305  ################################\n",
      "Loss:  0.0010292241349816322\n",
      "################################  306  ################################\n",
      "Loss:  0.001024959608912468\n",
      "################################  307  ################################\n",
      "Loss:  0.0010207430459558964\n",
      "################################  308  ################################\n",
      "Loss:  0.0010163621045649052\n",
      "################################  309  ################################\n",
      "Loss:  0.0010119926882907748\n",
      "################################  310  ################################\n",
      "Loss:  0.00100740697234869\n",
      "################################  311  ################################\n",
      "Loss:  0.0010028372053056955\n",
      "################################  312  ################################\n",
      "Loss:  0.0009981943294405937\n",
      "################################  313  ################################\n",
      "Loss:  0.0009934059344232082\n",
      "################################  314  ################################\n",
      "Loss:  0.000988788204267621\n",
      "################################  315  ################################\n",
      "Loss:  0.0009843395091593266\n",
      "################################  316  ################################\n",
      "Loss:  0.0009798486717045307\n",
      "################################  317  ################################\n",
      "Loss:  0.0009753081249073148\n",
      "################################  318  ################################\n",
      "Loss:  0.000970797089394182\n",
      "################################  319  ################################\n",
      "Loss:  0.0009659805800765753\n",
      "################################  320  ################################\n",
      "Loss:  0.0009609030676074326\n",
      "################################  321  ################################\n",
      "Loss:  0.0009559767786413431\n",
      "################################  322  ################################\n",
      "Loss:  0.0009507522918283939\n",
      "################################  323  ################################\n",
      "Loss:  0.0009460604633204639\n",
      "################################  324  ################################\n",
      "Loss:  0.0009411498322151601\n",
      "################################  325  ################################\n",
      "Loss:  0.0009362314594909549\n",
      "################################  326  ################################\n",
      "Loss:  0.0009311120957136154\n",
      "################################  327  ################################\n",
      "Loss:  0.0009257402271032333\n",
      "################################  328  ################################\n",
      "Loss:  0.0009201603825204074\n",
      "################################  329  ################################\n",
      "Loss:  0.00091455940855667\n",
      "################################  330  ################################\n",
      "Loss:  0.0009091674583032727\n",
      "################################  331  ################################\n",
      "Loss:  0.0009035546099767089\n",
      "################################  332  ################################\n",
      "Loss:  0.0008981408318504691\n",
      "################################  333  ################################\n",
      "Loss:  0.0008926521986722946\n",
      "################################  334  ################################\n",
      "Loss:  0.0008872151374816895\n",
      "################################  335  ################################\n",
      "Loss:  0.0008816518820822239\n",
      "################################  336  ################################\n",
      "Loss:  0.0008760925848037004\n",
      "################################  337  ################################\n",
      "Loss:  0.000870611984282732\n",
      "################################  338  ################################\n",
      "Loss:  0.0008651058888062835\n",
      "################################  339  ################################\n",
      "Loss:  0.0008595222025178373\n",
      "################################  340  ################################\n",
      "Loss:  0.0008540911367163062\n",
      "################################  341  ################################\n",
      "Loss:  0.0008485885919071734\n",
      "################################  342  ################################\n",
      "Loss:  0.0008434080518782139\n",
      "################################  343  ################################\n",
      "Loss:  0.0008382966043427587\n",
      "################################  344  ################################\n",
      "Loss:  0.0008335181046277285\n",
      "################################  345  ################################\n",
      "Loss:  0.0008289648685604334\n",
      "################################  346  ################################\n",
      "Loss:  0.0008245346252806485\n",
      "################################  347  ################################\n",
      "Loss:  0.0008204798214137554\n",
      "################################  348  ################################\n",
      "Loss:  0.0008164924802258611\n",
      "################################  349  ################################\n",
      "Loss:  0.0008127570617944002\n",
      "################################  350  ################################\n",
      "Loss:  0.000809145683888346\n",
      "################################  351  ################################\n",
      "Loss:  0.0008054654463194311\n",
      "################################  352  ################################\n",
      "Loss:  0.0008017095387913287\n",
      "################################  353  ################################\n",
      "Loss:  0.0007986126001924276\n",
      "################################  354  ################################\n",
      "Loss:  0.0007956478511914611\n",
      "################################  355  ################################\n",
      "Loss:  0.0007926394464448094\n",
      "################################  356  ################################\n",
      "Loss:  0.0007897421019151807\n",
      "################################  357  ################################\n",
      "Loss:  0.0007868382381275296\n",
      "################################  358  ################################\n",
      "Loss:  0.000783890369348228\n",
      "################################  359  ################################\n",
      "Loss:  0.0007808383088558912\n",
      "################################  360  ################################\n",
      "Loss:  0.0007779611623845994\n",
      "################################  361  ################################\n",
      "Loss:  0.0007752676028758287\n",
      "################################  362  ################################\n",
      "Loss:  0.0007724764291197062\n",
      "################################  363  ################################\n",
      "Loss:  0.0007698716362938285\n",
      "################################  364  ################################\n",
      "Loss:  0.0007672474021092057\n",
      "################################  365  ################################\n",
      "Loss:  0.0007645570440217853\n",
      "################################  366  ################################\n",
      "Loss:  0.0007619247189722955\n",
      "################################  367  ################################\n",
      "Loss:  0.0007591969915665686\n",
      "################################  368  ################################\n",
      "Loss:  0.0007564796833321452\n",
      "################################  369  ################################\n",
      "Loss:  0.0007537712226621807\n",
      "################################  370  ################################\n",
      "Loss:  0.0007511109579354525\n",
      "################################  371  ################################\n",
      "Loss:  0.0007485335227102041\n",
      "################################  372  ################################\n",
      "Loss:  0.0007459601620212197\n",
      "################################  373  ################################\n",
      "Loss:  0.0007434779545292258\n",
      "################################  374  ################################\n",
      "Loss:  0.0007409497047774494\n",
      "################################  375  ################################\n",
      "Loss:  0.0007384429918602109\n",
      "################################  376  ################################\n",
      "Loss:  0.000735943263862282\n",
      "################################  377  ################################\n",
      "Loss:  0.0007333742687478662\n",
      "################################  378  ################################\n",
      "Loss:  0.0007307723863050342\n",
      "################################  379  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0007280114805325866\n",
      "################################  380  ################################\n",
      "Loss:  0.0007249313639476895\n",
      "################################  381  ################################\n",
      "Loss:  0.0007219309918582439\n",
      "################################  382  ################################\n",
      "Loss:  0.0007186520379036665\n",
      "################################  383  ################################\n",
      "Loss:  0.0007151878671720624\n",
      "################################  384  ################################\n",
      "Loss:  0.0007117975037544966\n",
      "################################  385  ################################\n",
      "Loss:  0.0007081778603605926\n",
      "################################  386  ################################\n",
      "Loss:  0.000704647449310869\n",
      "################################  387  ################################\n",
      "Loss:  0.0007007218664512038\n",
      "################################  388  ################################\n",
      "Loss:  0.0006968409870751202\n",
      "################################  389  ################################\n",
      "Loss:  0.000692820583935827\n",
      "################################  390  ################################\n",
      "Loss:  0.0006884936010465026\n",
      "################################  391  ################################\n",
      "Loss:  0.0006840333808213472\n",
      "################################  392  ################################\n",
      "Loss:  0.0006799166440032423\n",
      "################################  393  ################################\n",
      "Loss:  0.000675699207931757\n",
      "################################  394  ################################\n",
      "Loss:  0.0006715341005474329\n",
      "################################  395  ################################\n",
      "Loss:  0.0006676171906292439\n",
      "################################  396  ################################\n",
      "Loss:  0.0006639002822339535\n",
      "################################  397  ################################\n",
      "Loss:  0.0006602566572837532\n",
      "################################  398  ################################\n",
      "Loss:  0.0006567951058968902\n",
      "################################  399  ################################\n",
      "Loss:  0.0006535148713737726\n",
      "################################  400  ################################\n",
      "Loss:  0.0006502438336610794\n",
      "################################  401  ################################\n",
      "Loss:  0.0006472055683843791\n",
      "################################  402  ################################\n",
      "Loss:  0.0006442929152399302\n",
      "################################  403  ################################\n",
      "Loss:  0.000641702557913959\n",
      "################################  404  ################################\n",
      "Loss:  0.0006392194773070514\n",
      "################################  405  ################################\n",
      "Loss:  0.0006368214380927384\n",
      "################################  406  ################################\n",
      "Loss:  0.0006344431894831359\n",
      "################################  407  ################################\n",
      "Loss:  0.0006321118562482297\n",
      "################################  408  ################################\n",
      "Loss:  0.0006298068910837173\n",
      "################################  409  ################################\n",
      "Loss:  0.0006274330080486834\n",
      "################################  410  ################################\n",
      "Loss:  0.0006250494043342769\n",
      "################################  411  ################################\n",
      "Loss:  0.0006229493883438408\n",
      "################################  412  ################################\n",
      "Loss:  0.0006208809791132808\n",
      "################################  413  ################################\n",
      "Loss:  0.0006189458072185516\n",
      "################################  414  ################################\n",
      "Loss:  0.0006169360131025314\n",
      "################################  415  ################################\n",
      "Loss:  0.0006148910033516586\n",
      "################################  416  ################################\n",
      "Loss:  0.0006127420347183943\n",
      "################################  417  ################################\n",
      "Loss:  0.0006104751955717802\n",
      "################################  418  ################################\n",
      "Loss:  0.0006081967148929834\n",
      "################################  419  ################################\n",
      "Loss:  0.0006058434955775738\n",
      "################################  420  ################################\n",
      "Loss:  0.0006032153614796698\n",
      "################################  421  ################################\n",
      "Loss:  0.0006005369359627366\n",
      "################################  422  ################################\n",
      "Loss:  0.0005981608992442489\n",
      "################################  423  ################################\n",
      "Loss:  0.0005956431268714368\n",
      "################################  424  ################################\n",
      "Loss:  0.0005930006736889482\n",
      "################################  425  ################################\n",
      "Loss:  0.0005899615935049951\n",
      "################################  426  ################################\n",
      "Loss:  0.0005874872440472245\n",
      "################################  427  ################################\n",
      "Loss:  0.0005849021254107356\n",
      "################################  428  ################################\n",
      "Loss:  0.0005811892333440483\n",
      "################################  429  ################################\n",
      "Loss:  0.0005786176188848913\n",
      "################################  430  ################################\n",
      "Loss:  0.0005746921524405479\n",
      "################################  431  ################################\n",
      "Loss:  0.0005715225706808269\n",
      "################################  432  ################################\n",
      "Loss:  0.0005674278945662081\n",
      "################################  433  ################################\n",
      "Loss:  0.0005633515538647771\n",
      "################################  434  ################################\n",
      "Loss:  0.0005594268441200256\n",
      "################################  435  ################################\n",
      "Loss:  0.0005554468370974064\n",
      "################################  436  ################################\n",
      "Loss:  0.0005514018121175468\n",
      "################################  437  ################################\n",
      "Loss:  0.0005477851955220103\n",
      "################################  438  ################################\n",
      "Loss:  0.0005445412243716419\n",
      "################################  439  ################################\n",
      "Loss:  0.0005416616331785917\n",
      "################################  440  ################################\n",
      "Loss:  0.0005390095757320523\n",
      "################################  441  ################################\n",
      "Loss:  0.0005364564131014049\n",
      "################################  442  ################################\n",
      "Loss:  0.0005342577351257205\n",
      "################################  443  ################################\n",
      "Loss:  0.0005321034695953131\n",
      "################################  444  ################################\n",
      "Loss:  0.0005298185278661549\n",
      "################################  445  ################################\n",
      "Loss:  0.0005277258460409939\n",
      "################################  446  ################################\n",
      "Loss:  0.0005256483564153314\n",
      "################################  447  ################################\n",
      "Loss:  0.00052395008970052\n",
      "################################  448  ################################\n",
      "Loss:  0.0005223755724728107\n",
      "################################  449  ################################\n",
      "Loss:  0.00052080542081967\n",
      "################################  450  ################################\n",
      "Loss:  0.0005193579709157348\n",
      "################################  451  ################################\n",
      "Loss:  0.0005179739091545343\n",
      "################################  452  ################################\n",
      "Loss:  0.000516679254360497\n",
      "################################  453  ################################\n",
      "Loss:  0.0005154291866347194\n",
      "################################  454  ################################\n",
      "Loss:  0.0005142131703905761\n",
      "################################  455  ################################\n",
      "Loss:  0.0005130113568156958\n",
      "################################  456  ################################\n",
      "Loss:  0.0005118048284202814\n",
      "################################  457  ################################\n",
      "Loss:  0.0005105715245008469\n",
      "################################  458  ################################\n",
      "Loss:  0.0005094358930364251\n",
      "################################  459  ################################\n",
      "Loss:  0.000508416211232543\n",
      "################################  460  ################################\n",
      "Loss:  0.0005073586944490671\n",
      "################################  461  ################################\n",
      "Loss:  0.0005064158467575908\n",
      "################################  462  ################################\n",
      "Loss:  0.0005054364446550608\n",
      "################################  463  ################################\n",
      "Loss:  0.0005043270066380501\n",
      "################################  464  ################################\n",
      "Loss:  0.0005031645996496081\n",
      "################################  465  ################################\n",
      "Loss:  0.000502048758789897\n",
      "################################  466  ################################\n",
      "Loss:  0.0005009573069401085\n",
      "################################  467  ################################\n",
      "Loss:  0.0004999389639124274\n",
      "################################  468  ################################\n",
      "Loss:  0.0004988833097741008\n",
      "################################  469  ################################\n",
      "Loss:  0.0004978665965609252\n",
      "################################  470  ################################\n",
      "Loss:  0.0004968565190210938\n",
      "################################  471  ################################\n",
      "Loss:  0.0004958444042131305\n",
      "################################  472  ################################\n",
      "Loss:  0.0004948433488607407\n",
      "################################  473  ################################\n",
      "Loss:  0.0004938748897984624\n",
      "################################  474  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0004928975831717253\n",
      "################################  475  ################################\n",
      "Loss:  0.0004918756894767284\n",
      "################################  476  ################################\n",
      "Loss:  0.0004908346454612911\n",
      "################################  477  ################################\n",
      "Loss:  0.000489740923512727\n",
      "################################  478  ################################\n",
      "Loss:  0.0004886271781288087\n",
      "################################  479  ################################\n",
      "Loss:  0.0004874600563198328\n",
      "################################  480  ################################\n",
      "Loss:  0.00048625306226313114\n",
      "################################  481  ################################\n",
      "Loss:  0.0004850068362429738\n",
      "################################  482  ################################\n",
      "Loss:  0.0004836317675653845\n",
      "################################  483  ################################\n",
      "Loss:  0.000482311996165663\n",
      "################################  484  ################################\n",
      "Loss:  0.00048081440036185086\n",
      "################################  485  ################################\n",
      "Loss:  0.0004792825202457607\n",
      "################################  486  ################################\n",
      "Loss:  0.0004775336419697851\n",
      "################################  487  ################################\n",
      "Loss:  0.00047570434981025755\n",
      "################################  488  ################################\n",
      "Loss:  0.0004737070412375033\n",
      "################################  489  ################################\n",
      "Loss:  0.0004720052529592067\n",
      "################################  490  ################################\n",
      "Loss:  0.00047023541992530227\n",
      "################################  491  ################################\n",
      "Loss:  0.00046834407839924097\n",
      "################################  492  ################################\n",
      "Loss:  0.0004663607105612755\n",
      "################################  493  ################################\n",
      "Loss:  0.00046417777775786817\n",
      "################################  494  ################################\n",
      "Loss:  0.0004618916427716613\n",
      "################################  495  ################################\n",
      "Loss:  0.0004594571073539555\n",
      "################################  496  ################################\n",
      "Loss:  0.0004571425961330533\n",
      "################################  497  ################################\n",
      "Loss:  0.0004547926946543157\n",
      "################################  498  ################################\n",
      "Loss:  0.0004524405812844634\n",
      "################################  499  ################################\n",
      "Loss:  0.0004501082585193217\n",
      "################################  500  ################################\n",
      "Loss:  0.0004479840863496065\n",
      "################################  501  ################################\n",
      "Loss:  0.0004459504853002727\n",
      "################################  502  ################################\n",
      "Loss:  0.0004441259370651096\n",
      "################################  503  ################################\n",
      "Loss:  0.00044238221016712487\n",
      "################################  504  ################################\n",
      "Loss:  0.00044066482223570347\n",
      "################################  505  ################################\n",
      "Loss:  0.00043896347051486373\n",
      "################################  506  ################################\n",
      "Loss:  0.000437378155766055\n",
      "################################  507  ################################\n",
      "Loss:  0.0004357981088105589\n",
      "################################  508  ################################\n",
      "Loss:  0.0004342888714745641\n",
      "################################  509  ################################\n",
      "Loss:  0.00043280384852550924\n",
      "################################  510  ################################\n",
      "Loss:  0.0004312474047765136\n",
      "################################  511  ################################\n",
      "Loss:  0.00042972207302227616\n",
      "################################  512  ################################\n",
      "Loss:  0.00042827712604776025\n",
      "################################  513  ################################\n",
      "Loss:  0.00042686989763751626\n",
      "################################  514  ################################\n",
      "Loss:  0.00042548374040052295\n",
      "################################  515  ################################\n",
      "Loss:  0.0004241146089043468\n",
      "################################  516  ################################\n",
      "Loss:  0.0004227401805110276\n",
      "################################  517  ################################\n",
      "Loss:  0.00042135734111070633\n",
      "################################  518  ################################\n",
      "Loss:  0.0004200338153168559\n",
      "################################  519  ################################\n",
      "Loss:  0.00041877623880282044\n",
      "################################  520  ################################\n",
      "Loss:  0.000417600036598742\n",
      "################################  521  ################################\n",
      "Loss:  0.0004163901321589947\n",
      "################################  522  ################################\n",
      "Loss:  0.0004152350011281669\n",
      "################################  523  ################################\n",
      "Loss:  0.0004140509117860347\n",
      "################################  524  ################################\n",
      "Loss:  0.00041298323776572943\n",
      "################################  525  ################################\n",
      "Loss:  0.00041197548853233457\n",
      "################################  526  ################################\n",
      "Loss:  0.00041093601612374187\n",
      "################################  527  ################################\n",
      "Loss:  0.000409910426242277\n",
      "################################  528  ################################\n",
      "Loss:  0.0004088752903044224\n",
      "################################  529  ################################\n",
      "Loss:  0.0004077991470694542\n",
      "################################  530  ################################\n",
      "Loss:  0.0004067245463375002\n",
      "################################  531  ################################\n",
      "Loss:  0.0004058009944856167\n",
      "################################  532  ################################\n",
      "Loss:  0.00040482525946572423\n",
      "################################  533  ################################\n",
      "Loss:  0.00040402106242254376\n",
      "################################  534  ################################\n",
      "Loss:  0.00040310603799298406\n",
      "################################  535  ################################\n",
      "Loss:  0.00040215777698904276\n",
      "################################  536  ################################\n",
      "Loss:  0.0004009446711279452\n",
      "################################  537  ################################\n",
      "Loss:  0.00039975339313969016\n",
      "################################  538  ################################\n",
      "Loss:  0.00039851898327469826\n",
      "################################  539  ################################\n",
      "Loss:  0.0003973673447035253\n",
      "################################  540  ################################\n",
      "Loss:  0.00039619437302462757\n",
      "################################  541  ################################\n",
      "Loss:  0.00039495714008808136\n",
      "################################  542  ################################\n",
      "Loss:  0.00039373472100123763\n",
      "################################  543  ################################\n",
      "Loss:  0.0003925057244487107\n",
      "################################  544  ################################\n",
      "Loss:  0.00039132399251684546\n",
      "################################  545  ################################\n",
      "Loss:  0.00039011589251458645\n",
      "################################  546  ################################\n",
      "Loss:  0.000388961227145046\n",
      "################################  547  ################################\n",
      "Loss:  0.00038771674735471606\n",
      "################################  548  ################################\n",
      "Loss:  0.00038660503923892975\n",
      "################################  549  ################################\n",
      "Loss:  0.000385360443033278\n",
      "################################  550  ################################\n",
      "Loss:  0.0003841909929178655\n",
      "################################  551  ################################\n",
      "Loss:  0.0003828605986200273\n",
      "################################  552  ################################\n",
      "Loss:  0.0003815892559941858\n",
      "################################  553  ################################\n",
      "Loss:  0.0003800072299782187\n",
      "################################  554  ################################\n",
      "Loss:  0.0003787278546951711\n",
      "################################  555  ################################\n",
      "Loss:  0.00037717141094617546\n",
      "################################  556  ################################\n",
      "Loss:  0.00037579162744805217\n",
      "################################  557  ################################\n",
      "Loss:  0.00037437613354995847\n",
      "################################  558  ################################\n",
      "Loss:  0.0003727625007741153\n",
      "################################  559  ################################\n",
      "Loss:  0.0003711584722623229\n",
      "################################  560  ################################\n",
      "Loss:  0.0003693237667903304\n",
      "################################  561  ################################\n",
      "Loss:  0.0003675522457342595\n",
      "################################  562  ################################\n",
      "Loss:  0.0003654309257399291\n",
      "################################  563  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0003637355985119939\n",
      "################################  564  ################################\n",
      "Loss:  0.0003615233290474862\n",
      "################################  565  ################################\n",
      "Loss:  0.00035959063097834587\n",
      "################################  566  ################################\n",
      "Loss:  0.0003574382863007486\n",
      "################################  567  ################################\n",
      "Loss:  0.0003551411209627986\n",
      "################################  568  ################################\n",
      "Loss:  0.0003528776578605175\n",
      "################################  569  ################################\n",
      "Loss:  0.00035069973091594875\n",
      "################################  570  ################################\n",
      "Loss:  0.0003486160421743989\n",
      "################################  571  ################################\n",
      "Loss:  0.0003466372727416456\n",
      "################################  572  ################################\n",
      "Loss:  0.0003447816998232156\n",
      "################################  573  ################################\n",
      "Loss:  0.00034301739651709795\n",
      "################################  574  ################################\n",
      "Loss:  0.00034133356530219316\n",
      "################################  575  ################################\n",
      "Loss:  0.00033975898986682296\n",
      "################################  576  ################################\n",
      "Loss:  0.0003383124421816319\n",
      "################################  577  ################################\n",
      "Loss:  0.0003370011691004038\n",
      "################################  578  ################################\n",
      "Loss:  0.0003358233079779893\n",
      "################################  579  ################################\n",
      "Loss:  0.00033471512142568827\n",
      "################################  580  ################################\n",
      "Loss:  0.0003336785011924803\n",
      "################################  581  ################################\n",
      "Loss:  0.000332707742927596\n",
      "################################  582  ################################\n",
      "Loss:  0.00033179426100105047\n",
      "################################  583  ################################\n",
      "Loss:  0.00033094370155595243\n",
      "################################  584  ################################\n",
      "Loss:  0.0003300727403257042\n",
      "################################  585  ################################\n",
      "Loss:  0.0003293697373010218\n",
      "################################  586  ################################\n",
      "Loss:  0.00032868830021470785\n",
      "################################  587  ################################\n",
      "Loss:  0.0003280591336078942\n",
      "################################  588  ################################\n",
      "Loss:  0.00032745994394645095\n",
      "################################  589  ################################\n",
      "Loss:  0.00032681142329238355\n",
      "################################  590  ################################\n",
      "Loss:  0.00032601511338725686\n",
      "################################  591  ################################\n",
      "Loss:  0.0003254348994232714\n",
      "################################  592  ################################\n",
      "Loss:  0.0003248357097618282\n",
      "################################  593  ################################\n",
      "Loss:  0.0003241166705265641\n",
      "################################  594  ################################\n",
      "Loss:  0.00032335298601537943\n",
      "################################  595  ################################\n",
      "Loss:  0.00032254226971417665\n",
      "################################  596  ################################\n",
      "Loss:  0.0003217760822735727\n",
      "################################  597  ################################\n",
      "Loss:  0.0003209861752111465\n",
      "################################  598  ################################\n",
      "Loss:  0.0003201499639544636\n",
      "################################  599  ################################\n",
      "Loss:  0.0003193546726834029\n",
      "################################  600  ################################\n",
      "Loss:  0.0003185239911545068\n",
      "################################  601  ################################\n",
      "Loss:  0.00031772119109518826\n",
      "################################  602  ################################\n",
      "Loss:  0.00031691364711150527\n",
      "################################  603  ################################\n",
      "Loss:  0.00031611823942512274\n",
      "################################  604  ################################\n",
      "Loss:  0.000315362645778805\n",
      "################################  605  ################################\n",
      "Loss:  0.000314563512802124\n",
      "################################  606  ################################\n",
      "Loss:  0.0003138259635306895\n",
      "################################  607  ################################\n",
      "Loss:  0.0003130619879812002\n",
      "################################  608  ################################\n",
      "Loss:  0.0003123120404779911\n",
      "################################  609  ################################\n",
      "Loss:  0.00031140283681452274\n",
      "################################  610  ################################\n",
      "Loss:  0.000310365081531927\n",
      "################################  611  ################################\n",
      "Loss:  0.0003090345999225974\n",
      "################################  612  ################################\n",
      "Loss:  0.00030799955129623413\n",
      "################################  613  ################################\n",
      "Loss:  0.0003067104844376445\n",
      "################################  614  ################################\n",
      "Loss:  0.0003053534310311079\n",
      "################################  615  ################################\n",
      "Loss:  0.00030392903136089444\n",
      "################################  616  ################################\n",
      "Loss:  0.0003025007899850607\n",
      "################################  617  ################################\n",
      "Loss:  0.00030107173370197415\n",
      "################################  618  ################################\n",
      "Loss:  0.0002996408147737384\n",
      "################################  619  ################################\n",
      "Loss:  0.0002982590231113136\n",
      "################################  620  ################################\n",
      "Loss:  0.00029688916401937604\n",
      "################################  621  ################################\n",
      "Loss:  0.0002955814416054636\n",
      "################################  622  ################################\n",
      "Loss:  0.0002943167637567967\n",
      "################################  623  ################################\n",
      "Loss:  0.0002931341587100178\n",
      "################################  624  ################################\n",
      "Loss:  0.0002920370898209512\n",
      "################################  625  ################################\n",
      "Loss:  0.0002910105395130813\n",
      "################################  626  ################################\n",
      "Loss:  0.00029010651633143425\n",
      "################################  627  ################################\n",
      "Loss:  0.00028923735953867435\n",
      "################################  628  ################################\n",
      "Loss:  0.00028848680085502565\n",
      "################################  629  ################################\n",
      "Loss:  0.00028776004910469055\n",
      "################################  630  ################################\n",
      "Loss:  0.0002870699390769005\n",
      "################################  631  ################################\n",
      "Loss:  0.0002863887348212302\n",
      "################################  632  ################################\n",
      "Loss:  0.0002857841900549829\n",
      "################################  633  ################################\n",
      "Loss:  0.00028515030862763524\n",
      "################################  634  ################################\n",
      "Loss:  0.00028446916257962584\n",
      "################################  635  ################################\n",
      "Loss:  0.0002837684587575495\n",
      "################################  636  ################################\n",
      "Loss:  0.00028319197008386254\n",
      "################################  637  ################################\n",
      "Loss:  0.0002826181589625776\n",
      "################################  638  ################################\n",
      "Loss:  0.000281959684798494\n",
      "################################  639  ################################\n",
      "Loss:  0.0002811228623613715\n",
      "################################  640  ################################\n",
      "Loss:  0.0002804333926178515\n",
      "################################  641  ################################\n",
      "Loss:  0.0002796738699544221\n",
      "################################  642  ################################\n",
      "Loss:  0.0002788436249829829\n",
      "################################  643  ################################\n",
      "Loss:  0.0002779866917990148\n",
      "################################  644  ################################\n",
      "Loss:  0.000277087528957054\n",
      "################################  645  ################################\n",
      "Loss:  0.0002762096410151571\n",
      "################################  646  ################################\n",
      "Loss:  0.00027527566999197006\n",
      "################################  647  ################################\n",
      "Loss:  0.00027433785726316273\n",
      "################################  648  ################################\n",
      "Loss:  0.00027324919938109815\n",
      "################################  649  ################################\n",
      "Loss:  0.00027198600582778454\n",
      "################################  650  ################################\n",
      "Loss:  0.000270634627668187\n",
      "################################  651  ################################\n",
      "Loss:  0.0002694460563361645\n",
      "################################  652  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.00026831781724467874\n",
      "################################  653  ################################\n",
      "Loss:  0.00026705992058850825\n",
      "################################  654  ################################\n",
      "Loss:  0.00026588482432998717\n",
      "################################  655  ################################\n",
      "Loss:  0.00026449502911418676\n",
      "################################  656  ################################\n",
      "Loss:  0.00026354880537837744\n",
      "################################  657  ################################\n",
      "Loss:  0.0002625786582939327\n",
      "################################  658  ################################\n",
      "Loss:  0.0002616079873405397\n",
      "################################  659  ################################\n",
      "Loss:  0.0002607104543130845\n",
      "################################  660  ################################\n",
      "Loss:  0.00025992890004999936\n",
      "################################  661  ################################\n",
      "Loss:  0.00025920040206983685\n",
      "################################  662  ################################\n",
      "Loss:  0.00025849376106634736\n",
      "################################  663  ################################\n",
      "Loss:  0.00025780906435102224\n",
      "################################  664  ################################\n",
      "Loss:  0.0002571829245425761\n",
      "################################  665  ################################\n",
      "Loss:  0.00025661554536782205\n",
      "################################  666  ################################\n",
      "Loss:  0.0002561225846875459\n",
      "################################  667  ################################\n",
      "Loss:  0.000255650986218825\n",
      "################################  668  ################################\n",
      "Loss:  0.0002552238292992115\n",
      "################################  669  ################################\n",
      "Loss:  0.0002547974290791899\n",
      "################################  670  ################################\n",
      "Loss:  0.0002543515875004232\n",
      "################################  671  ################################\n",
      "Loss:  0.0002539168344810605\n",
      "################################  672  ################################\n",
      "Loss:  0.00025351386284455657\n",
      "################################  673  ################################\n",
      "Loss:  0.00025313819060102105\n",
      "################################  674  ################################\n",
      "Loss:  0.00025277200620621443\n",
      "################################  675  ################################\n",
      "Loss:  0.0002524260780774057\n",
      "################################  676  ################################\n",
      "Loss:  0.00025209656450897455\n",
      "################################  677  ################################\n",
      "Loss:  0.0002517656539566815\n",
      "################################  678  ################################\n",
      "Loss:  0.00025144420214928687\n",
      "################################  679  ################################\n",
      "Loss:  0.00025108069530688226\n",
      "################################  680  ################################\n",
      "Loss:  0.00025079844635911286\n",
      "################################  681  ################################\n",
      "Loss:  0.00025045740767382085\n",
      "################################  682  ################################\n",
      "Loss:  0.0002500576665624976\n",
      "################################  683  ################################\n",
      "Loss:  0.00024954648688435555\n",
      "################################  684  ################################\n",
      "Loss:  0.0002489713951945305\n",
      "################################  685  ################################\n",
      "Loss:  0.00024832767667248845\n",
      "################################  686  ################################\n",
      "Loss:  0.00024778718943707645\n",
      "################################  687  ################################\n",
      "Loss:  0.0002471634070388973\n",
      "################################  688  ################################\n",
      "Loss:  0.00024645193479955196\n",
      "################################  689  ################################\n",
      "Loss:  0.000245689123403281\n",
      "################################  690  ################################\n",
      "Loss:  0.0002449316962156445\n",
      "################################  691  ################################\n",
      "Loss:  0.0002441252290736884\n",
      "################################  692  ################################\n",
      "Loss:  0.0002433482150081545\n",
      "################################  693  ################################\n",
      "Loss:  0.0002425956481602043\n",
      "################################  694  ################################\n",
      "Loss:  0.00024178613966796547\n",
      "################################  695  ################################\n",
      "Loss:  0.00024105192278511822\n",
      "################################  696  ################################\n",
      "Loss:  0.00024029100313782692\n",
      "################################  697  ################################\n",
      "Loss:  0.00023946352303028107\n",
      "################################  698  ################################\n",
      "Loss:  0.000238661072216928\n",
      "################################  699  ################################\n",
      "Loss:  0.00023784251243341714\n",
      "################################  700  ################################\n",
      "Loss:  0.00023704578052274883\n",
      "################################  701  ################################\n",
      "Loss:  0.00023621850414201617\n",
      "################################  702  ################################\n",
      "Loss:  0.00023539975518360734\n",
      "################################  703  ################################\n",
      "Loss:  0.00023459884687326849\n",
      "################################  704  ################################\n",
      "Loss:  0.00023366400273516774\n",
      "################################  705  ################################\n",
      "Loss:  0.00023288928787223995\n",
      "################################  706  ################################\n",
      "Loss:  0.00023211461666505784\n",
      "################################  707  ################################\n",
      "Loss:  0.0002312443102709949\n",
      "################################  708  ################################\n",
      "Loss:  0.0002302991779288277\n",
      "################################  709  ################################\n",
      "Loss:  0.00022943876683712006\n",
      "################################  710  ################################\n",
      "Loss:  0.00022858510783407837\n",
      "################################  711  ################################\n",
      "Loss:  0.00022777612321078777\n",
      "################################  712  ################################\n",
      "Loss:  0.00022695920779369771\n",
      "################################  713  ################################\n",
      "Loss:  0.0002261665795231238\n",
      "################################  714  ################################\n",
      "Loss:  0.00022529400303028524\n",
      "################################  715  ################################\n",
      "Loss:  0.0002245922078145668\n",
      "################################  716  ################################\n",
      "Loss:  0.00022388785146176815\n",
      "################################  717  ################################\n",
      "Loss:  0.00022313592489808798\n",
      "################################  718  ################################\n",
      "Loss:  0.00022238073870539665\n",
      "################################  719  ################################\n",
      "Loss:  0.00022171763703227043\n",
      "################################  720  ################################\n",
      "Loss:  0.00022099309717305005\n",
      "################################  721  ################################\n",
      "Loss:  0.00022035112488083541\n",
      "################################  722  ################################\n",
      "Loss:  0.00021966148051433265\n",
      "################################  723  ################################\n",
      "Loss:  0.0002189037186326459\n",
      "################################  724  ################################\n",
      "Loss:  0.00021815189393237233\n",
      "################################  725  ################################\n",
      "Loss:  0.00021738599753007293\n",
      "################################  726  ################################\n",
      "Loss:  0.00021665566600859165\n",
      "################################  727  ################################\n",
      "Loss:  0.00021593572455458343\n",
      "################################  728  ################################\n",
      "Loss:  0.0002152626111637801\n",
      "################################  729  ################################\n",
      "Loss:  0.00021459718118421733\n",
      "################################  730  ################################\n",
      "Loss:  0.00021397399541456252\n",
      "################################  731  ################################\n",
      "Loss:  0.0002133606030838564\n",
      "################################  732  ################################\n",
      "Loss:  0.00021269739954732358\n",
      "################################  733  ################################\n",
      "Loss:  0.00021209000260569155\n",
      "################################  734  ################################\n",
      "Loss:  0.00021149129315745085\n",
      "################################  735  ################################\n",
      "Loss:  0.00021097503486089408\n",
      "################################  736  ################################\n",
      "Loss:  0.0002104603045154363\n",
      "################################  737  ################################\n",
      "Loss:  0.0002099010453093797\n",
      "################################  738  ################################\n",
      "Loss:  0.00020939686510246247\n",
      "################################  739  ################################\n",
      "Loss:  0.00020891074382234365\n",
      "################################  740  ################################\n",
      "Loss:  0.00020843325182795525\n",
      "################################  741  ################################\n",
      "Loss:  0.00020794387091882527\n",
      "################################  742  ################################\n",
      "Loss:  0.0002074726071441546\n",
      "################################  743  ################################\n",
      "Loss:  0.00020698861044365913\n",
      "################################  744  ################################\n",
      "Loss:  0.0002064686268568039\n",
      "################################  745  ################################\n",
      "Loss:  0.00020600779680535197\n",
      "################################  746  ################################\n",
      "Loss:  0.00020552169007714838\n",
      "################################  747  ################################\n",
      "Loss:  0.00020510453032329679\n",
      "################################  748  ################################\n",
      "Loss:  0.00020465513807721436\n",
      "################################  749  ################################\n",
      "Loss:  0.0002042226551566273\n",
      "################################  750  ################################\n",
      "Loss:  0.0002037275116890669\n",
      "################################  751  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.00020316962036304176\n",
      "################################  752  ################################\n",
      "Loss:  0.00020264057093299925\n",
      "################################  753  ################################\n",
      "Loss:  0.0002021054388023913\n",
      "################################  754  ################################\n",
      "Loss:  0.0002015677746385336\n",
      "################################  755  ################################\n",
      "Loss:  0.0002010419120779261\n",
      "################################  756  ################################\n",
      "Loss:  0.00020047735597472638\n",
      "################################  757  ################################\n",
      "Loss:  0.0002000071544898674\n",
      "################################  758  ################################\n",
      "Loss:  0.00019951157446485013\n",
      "################################  759  ################################\n",
      "Loss:  0.0001988690928556025\n",
      "################################  760  ################################\n",
      "Loss:  0.00019837736908812076\n",
      "################################  761  ################################\n",
      "Loss:  0.00019784949836321175\n",
      "################################  762  ################################\n",
      "Loss:  0.000197254354134202\n",
      "################################  763  ################################\n",
      "Loss:  0.00019671328482218087\n",
      "################################  764  ################################\n",
      "Loss:  0.0001961849193321541\n",
      "################################  765  ################################\n",
      "Loss:  0.00019563185924198478\n",
      "################################  766  ################################\n",
      "Loss:  0.00019510294077917933\n",
      "################################  767  ################################\n",
      "Loss:  0.0001945764379343018\n",
      "################################  768  ################################\n",
      "Loss:  0.0001940890506375581\n",
      "################################  769  ################################\n",
      "Loss:  0.00019362960301805288\n",
      "################################  770  ################################\n",
      "Loss:  0.0001931829610839486\n",
      "################################  771  ################################\n",
      "Loss:  0.000192762614460662\n",
      "################################  772  ################################\n",
      "Loss:  0.00019234188948757946\n",
      "################################  773  ################################\n",
      "Loss:  0.0001919515780173242\n",
      "################################  774  ################################\n",
      "Loss:  0.0001915512839332223\n",
      "################################  775  ################################\n",
      "Loss:  0.00019116562907584012\n",
      "################################  776  ################################\n",
      "Loss:  0.00019075586169492453\n",
      "################################  777  ################################\n",
      "Loss:  0.00019032119598705322\n",
      "################################  778  ################################\n",
      "Loss:  0.0001898784830700606\n",
      "################################  779  ################################\n",
      "Loss:  0.00018944642215501517\n",
      "################################  780  ################################\n",
      "Loss:  0.00018901537987403572\n",
      "################################  781  ################################\n",
      "Loss:  0.00018855556845664978\n",
      "################################  782  ################################\n",
      "Loss:  0.0001881478528957814\n",
      "################################  783  ################################\n",
      "Loss:  0.00018773850752040744\n",
      "################################  784  ################################\n",
      "Loss:  0.00018733085016719997\n",
      "################################  785  ################################\n",
      "Loss:  0.00018693783204071224\n",
      "################################  786  ################################\n",
      "Loss:  0.0001865184458438307\n",
      "################################  787  ################################\n",
      "Loss:  0.0001861333439592272\n",
      "################################  788  ################################\n",
      "Loss:  0.0001857110473793\n",
      "################################  789  ################################\n",
      "Loss:  0.00018528176588006318\n",
      "################################  790  ################################\n",
      "Loss:  0.00018486283079255372\n",
      "################################  791  ################################\n",
      "Loss:  0.0001844546350184828\n",
      "################################  792  ################################\n",
      "Loss:  0.00018406863091513515\n",
      "################################  793  ################################\n",
      "Loss:  0.00018369179451838136\n",
      "################################  794  ################################\n",
      "Loss:  0.00018332485342398286\n",
      "################################  795  ################################\n",
      "Loss:  0.00018296980124432594\n",
      "################################  796  ################################\n",
      "Loss:  0.0001826397201512009\n",
      "################################  797  ################################\n",
      "Loss:  0.0001823354250518605\n",
      "################################  798  ################################\n",
      "Loss:  0.00018205300148110837\n",
      "################################  799  ################################\n",
      "Loss:  0.000181782670551911\n",
      "################################  800  ################################\n",
      "Loss:  0.00018152652774006128\n",
      "################################  801  ################################\n",
      "Loss:  0.00018127483781427145\n",
      "################################  802  ################################\n",
      "Loss:  0.00018103649199474603\n",
      "################################  803  ################################\n",
      "Loss:  0.0001808019442250952\n",
      "################################  804  ################################\n",
      "Loss:  0.00018055742839351296\n",
      "################################  805  ################################\n",
      "Loss:  0.0001803207560442388\n",
      "################################  806  ################################\n",
      "Loss:  0.000180061484570615\n",
      "################################  807  ################################\n",
      "Loss:  0.00017982105782721192\n",
      "################################  808  ################################\n",
      "Loss:  0.00017955657676793635\n",
      "################################  809  ################################\n",
      "Loss:  0.00017923771520145237\n",
      "################################  810  ################################\n",
      "Loss:  0.0001789210655260831\n",
      "################################  811  ################################\n",
      "Loss:  0.0001785923377610743\n",
      "################################  812  ################################\n",
      "Loss:  0.00017826941621024162\n",
      "################################  813  ################################\n",
      "Loss:  0.0001779087178874761\n",
      "################################  814  ################################\n",
      "Loss:  0.00017755397129803896\n",
      "################################  815  ################################\n",
      "Loss:  0.00017709545500110835\n",
      "################################  816  ################################\n",
      "Loss:  0.00017672656395006925\n",
      "################################  817  ################################\n",
      "Loss:  0.00017615458637010306\n",
      "################################  818  ################################\n",
      "Loss:  0.00017552818462718278\n",
      "################################  819  ################################\n",
      "Loss:  0.0001746279012877494\n",
      "################################  820  ################################\n",
      "Loss:  0.00017371798458043486\n",
      "################################  821  ################################\n",
      "Loss:  0.0001726225600577891\n",
      "################################  822  ################################\n",
      "Loss:  0.0001714203244773671\n",
      "################################  823  ################################\n",
      "Loss:  0.00017027903231792152\n",
      "################################  824  ################################\n",
      "Loss:  0.0001690732897259295\n",
      "################################  825  ################################\n",
      "Loss:  0.00016794777184259146\n",
      "################################  826  ################################\n",
      "Loss:  0.0001668357872404158\n",
      "################################  827  ################################\n",
      "Loss:  0.00016577873611822724\n",
      "################################  828  ################################\n",
      "Loss:  0.00016478856559842825\n",
      "################################  829  ################################\n",
      "Loss:  0.00016383346519432962\n",
      "################################  830  ################################\n",
      "Loss:  0.000162955213454552\n",
      "################################  831  ################################\n",
      "Loss:  0.00016212923219427466\n",
      "################################  832  ################################\n",
      "Loss:  0.0001614416833035648\n",
      "################################  833  ################################\n",
      "Loss:  0.00016077281907200813\n",
      "################################  834  ################################\n",
      "Loss:  0.00016023222997318953\n",
      "################################  835  ################################\n",
      "Loss:  0.00015960633754730225\n",
      "################################  836  ################################\n",
      "Loss:  0.00015912952949292958\n",
      "################################  837  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.00015867008187342435\n",
      "################################  838  ################################\n",
      "Loss:  0.00015816329687368125\n",
      "################################  839  ################################\n",
      "Loss:  0.00015773417544551194\n",
      "################################  840  ################################\n",
      "Loss:  0.00015717239875812083\n",
      "################################  841  ################################\n",
      "Loss:  0.00015660616918466985\n",
      "################################  842  ################################\n",
      "Loss:  0.00015604116197209805\n",
      "################################  843  ################################\n",
      "Loss:  0.0001554035407025367\n",
      "################################  844  ################################\n",
      "Loss:  0.0001548226864542812\n",
      "################################  845  ################################\n",
      "Loss:  0.00015427258040290326\n",
      "################################  846  ################################\n",
      "Loss:  0.0001536982599645853\n",
      "################################  847  ################################\n",
      "Loss:  0.00015312628238461912\n",
      "################################  848  ################################\n",
      "Loss:  0.00015262173837982118\n",
      "################################  849  ################################\n",
      "Loss:  0.00015215537860058248\n",
      "################################  850  ################################\n",
      "Loss:  0.00015175614680629224\n",
      "################################  851  ################################\n",
      "Loss:  0.00015139591414481401\n",
      "################################  852  ################################\n",
      "Loss:  0.00015103444457054138\n",
      "################################  853  ################################\n",
      "Loss:  0.00015073124086484313\n",
      "################################  854  ################################\n",
      "Loss:  0.00015044239989947528\n",
      "################################  855  ################################\n",
      "Loss:  0.00015016742690932006\n",
      "################################  856  ################################\n",
      "Loss:  0.00014991889474913478\n",
      "################################  857  ################################\n",
      "Loss:  0.0001496391778346151\n",
      "################################  858  ################################\n",
      "Loss:  0.00014943706628400832\n",
      "################################  859  ################################\n",
      "Loss:  0.00014922524860594422\n",
      "################################  860  ################################\n",
      "Loss:  0.00014899815141689032\n",
      "################################  861  ################################\n",
      "Loss:  0.00014876300701871514\n",
      "################################  862  ################################\n",
      "Loss:  0.00014854769688099623\n",
      "################################  863  ################################\n",
      "Loss:  0.00014828736311756074\n",
      "################################  864  ################################\n",
      "Loss:  0.00014796631876379251\n",
      "################################  865  ################################\n",
      "Loss:  0.00014763636863790452\n",
      "################################  866  ################################\n",
      "Loss:  0.0001473110169172287\n",
      "################################  867  ################################\n",
      "Loss:  0.0001469869166612625\n",
      "################################  868  ################################\n",
      "Loss:  0.00014663978072348982\n",
      "################################  869  ################################\n",
      "Loss:  0.00014629552606493235\n",
      "################################  870  ################################\n",
      "Loss:  0.00014593484229408205\n",
      "################################  871  ################################\n",
      "Loss:  0.0001455914753023535\n",
      "################################  872  ################################\n",
      "Loss:  0.00014524733705911785\n",
      "################################  873  ################################\n",
      "Loss:  0.00014487694716081023\n",
      "################################  874  ################################\n",
      "Loss:  0.00014450591697823256\n",
      "################################  875  ################################\n",
      "Loss:  0.0001441483764210716\n",
      "################################  876  ################################\n",
      "Loss:  0.0001437846221961081\n",
      "################################  877  ################################\n",
      "Loss:  0.00014344528608489782\n",
      "################################  878  ################################\n",
      "Loss:  0.0001430980919394642\n",
      "################################  879  ################################\n",
      "Loss:  0.00014276347064878792\n",
      "################################  880  ################################\n",
      "Loss:  0.0001424249348929152\n",
      "################################  881  ################################\n",
      "Loss:  0.00014206086052581668\n",
      "################################  882  ################################\n",
      "Loss:  0.00014170428039506078\n",
      "################################  883  ################################\n",
      "Loss:  0.0001413258578395471\n",
      "################################  884  ################################\n",
      "Loss:  0.00014098295650910586\n",
      "################################  885  ################################\n",
      "Loss:  0.00014067566371522844\n",
      "################################  886  ################################\n",
      "Loss:  0.00014035176718607545\n",
      "################################  887  ################################\n",
      "Loss:  0.00014006337733007967\n",
      "################################  888  ################################\n",
      "Loss:  0.00013973393652122468\n",
      "################################  889  ################################\n",
      "Loss:  0.00013948242121841758\n",
      "################################  890  ################################\n",
      "Loss:  0.00013920142373535782\n",
      "################################  891  ################################\n",
      "Loss:  0.00013886438682675362\n",
      "################################  892  ################################\n",
      "Loss:  0.00013852884876541793\n",
      "################################  893  ################################\n",
      "Loss:  0.0001381398760713637\n",
      "################################  894  ################################\n",
      "Loss:  0.00013776317064184695\n",
      "################################  895  ################################\n",
      "Loss:  0.00013732565275859088\n",
      "################################  896  ################################\n",
      "Loss:  0.00013684951409231871\n",
      "################################  897  ################################\n",
      "Loss:  0.00013634125934913754\n",
      "################################  898  ################################\n",
      "Loss:  0.00013579599908553064\n",
      "################################  899  ################################\n",
      "Loss:  0.00013529312855098397\n",
      "################################  900  ################################\n",
      "Loss:  0.00013479289191309363\n",
      "################################  901  ################################\n",
      "Loss:  0.00013428520469460636\n",
      "################################  902  ################################\n",
      "Loss:  0.00013382945326156914\n",
      "################################  903  ################################\n",
      "Loss:  0.00013337447308003902\n",
      "################################  904  ################################\n",
      "Loss:  0.00013295412645675242\n",
      "################################  905  ################################\n",
      "Loss:  0.00013254483928903937\n",
      "################################  906  ################################\n",
      "Loss:  0.00013210895122028887\n",
      "################################  907  ################################\n",
      "Loss:  0.0001317020069109276\n",
      "################################  908  ################################\n",
      "Loss:  0.00013130292063578963\n",
      "################################  909  ################################\n",
      "Loss:  0.00013093779853079468\n",
      "################################  910  ################################\n",
      "Loss:  0.00013059080811217427\n",
      "################################  911  ################################\n",
      "Loss:  0.0001302550663240254\n",
      "################################  912  ################################\n",
      "Loss:  0.00012993099517188966\n",
      "################################  913  ################################\n",
      "Loss:  0.00012962053006049246\n",
      "################################  914  ################################\n",
      "Loss:  0.00012931077799294144\n",
      "################################  915  ################################\n",
      "Loss:  0.00012905846233479679\n",
      "################################  916  ################################\n",
      "Loss:  0.0001288128551095724\n",
      "################################  917  ################################\n",
      "Loss:  0.00012860260903835297\n",
      "################################  918  ################################\n",
      "Loss:  0.00012838182738050818\n",
      "################################  919  ################################\n",
      "Loss:  0.00012814407818950713\n",
      "################################  920  ################################\n",
      "Loss:  0.00012788997264578938\n",
      "################################  921  ################################\n",
      "Loss:  0.00012764587881974876\n",
      "################################  922  ################################\n",
      "Loss:  0.00012741975660901517\n",
      "################################  923  ################################\n",
      "Loss:  0.00012716188211925328\n",
      "################################  924  ################################\n",
      "Loss:  0.0001269006752409041\n",
      "################################  925  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.00012660547508858144\n",
      "################################  926  ################################\n",
      "Loss:  0.0001263317244593054\n",
      "################################  927  ################################\n",
      "Loss:  0.00012601196067407727\n",
      "################################  928  ################################\n",
      "Loss:  0.00012565804354380816\n",
      "################################  929  ################################\n",
      "Loss:  0.00012529274681583047\n",
      "################################  930  ################################\n",
      "Loss:  0.00012490311928559095\n",
      "################################  931  ################################\n",
      "Loss:  0.0001244909653905779\n",
      "################################  932  ################################\n",
      "Loss:  0.0001240515266545117\n",
      "################################  933  ################################\n",
      "Loss:  0.00012366133159957826\n",
      "################################  934  ################################\n",
      "Loss:  0.0001232355134561658\n",
      "################################  935  ################################\n",
      "Loss:  0.00012285771663300693\n",
      "################################  936  ################################\n",
      "Loss:  0.00012248153507243842\n",
      "################################  937  ################################\n",
      "Loss:  0.0001220711856149137\n",
      "################################  938  ################################\n",
      "Loss:  0.00012169012188678607\n",
      "################################  939  ################################\n",
      "Loss:  0.0001212857459904626\n",
      "################################  940  ################################\n",
      "Loss:  0.00012093559780623764\n",
      "################################  941  ################################\n",
      "Loss:  0.00012060195149388164\n",
      "################################  942  ################################\n",
      "Loss:  0.00012024882016703486\n",
      "################################  943  ################################\n",
      "Loss:  0.00011992224608547986\n",
      "################################  944  ################################\n",
      "Loss:  0.00011960815754719079\n",
      "################################  945  ################################\n",
      "Loss:  0.00011930931214010343\n",
      "################################  946  ################################\n",
      "Loss:  0.00011902661208296195\n",
      "################################  947  ################################\n",
      "Loss:  0.00011874859046656638\n",
      "################################  948  ################################\n",
      "Loss:  0.00011848222493426874\n",
      "################################  949  ################################\n",
      "Loss:  0.00011823484965134412\n",
      "################################  950  ################################\n",
      "Loss:  0.00011798075865954161\n",
      "################################  951  ################################\n",
      "Loss:  0.00011775409075198695\n",
      "################################  952  ################################\n",
      "Loss:  0.00011751502461265773\n",
      "################################  953  ################################\n",
      "Loss:  0.00011722259660018608\n",
      "################################  954  ################################\n",
      "Loss:  0.00011695397552102804\n",
      "################################  955  ################################\n",
      "Loss:  0.00011669560626614839\n",
      "################################  956  ################################\n",
      "Loss:  0.00011644413461908698\n",
      "################################  957  ################################\n",
      "Loss:  0.0001162013941211626\n",
      "################################  958  ################################\n",
      "Loss:  0.0001159443927463144\n",
      "################################  959  ################################\n",
      "Loss:  0.0001157238002633676\n",
      "################################  960  ################################\n",
      "Loss:  0.00011548923794180155\n",
      "################################  961  ################################\n",
      "Loss:  0.00011522311251610518\n",
      "################################  962  ################################\n",
      "Loss:  0.00011493002239149064\n",
      "################################  963  ################################\n",
      "Loss:  0.00011464690032880753\n",
      "################################  964  ################################\n",
      "Loss:  0.00011437525972723961\n",
      "################################  965  ################################\n",
      "Loss:  0.00011410321167204529\n",
      "################################  966  ################################\n",
      "Loss:  0.00011384858953533694\n",
      "################################  967  ################################\n",
      "Loss:  0.00011358043411746621\n",
      "################################  968  ################################\n",
      "Loss:  0.00011333702423144132\n",
      "################################  969  ################################\n",
      "Loss:  0.00011308233661111444\n",
      "################################  970  ################################\n",
      "Loss:  0.00011283524509053677\n",
      "################################  971  ################################\n",
      "Loss:  0.00011258207086939365\n",
      "################################  972  ################################\n",
      "Loss:  0.00011229695519432425\n",
      "################################  973  ################################\n",
      "Loss:  0.00011202548921573907\n",
      "################################  974  ################################\n",
      "Loss:  0.00011176569387316704\n",
      "################################  975  ################################\n",
      "Loss:  0.00011151790386065841\n",
      "################################  976  ################################\n",
      "Loss:  0.00011127785546705127\n",
      "################################  977  ################################\n",
      "Loss:  0.00011104375880677253\n",
      "################################  978  ################################\n",
      "Loss:  0.00011081974662374705\n",
      "################################  979  ################################\n",
      "Loss:  0.0001105878473026678\n",
      "################################  980  ################################\n",
      "Loss:  0.0001103757822420448\n",
      "################################  981  ################################\n",
      "Loss:  0.00011015792551916093\n",
      "################################  982  ################################\n",
      "Loss:  0.00010996474884450436\n",
      "################################  983  ################################\n",
      "Loss:  0.00010974819451803342\n",
      "################################  984  ################################\n",
      "Loss:  0.00010950112482532859\n",
      "################################  985  ################################\n",
      "Loss:  0.00010924117668764666\n",
      "################################  986  ################################\n",
      "Loss:  0.00010899391782004386\n",
      "################################  987  ################################\n",
      "Loss:  0.00010874040890485048\n",
      "################################  988  ################################\n",
      "Loss:  0.00010845718497876078\n",
      "################################  989  ################################\n",
      "Loss:  0.00010819215094670653\n",
      "################################  990  ################################\n",
      "Loss:  0.00010789539373945445\n",
      "################################  991  ################################\n",
      "Loss:  0.00010765576735138893\n",
      "################################  992  ################################\n",
      "Loss:  0.00010742626182036474\n",
      "################################  993  ################################\n",
      "Loss:  0.00010715903044911101\n",
      "################################  994  ################################\n",
      "Loss:  0.00010691446368582547\n",
      "################################  995  ################################\n",
      "Loss:  0.00010661630949471146\n",
      "################################  996  ################################\n",
      "Loss:  0.00010636841761879623\n",
      "################################  997  ################################\n",
      "Loss:  0.00010602796101011336\n",
      "################################  998  ################################\n",
      "Loss:  0.00010571422171778977\n",
      "################################  999  ################################\n",
      "Loss:  0.00010537867638049647\n",
      "################################  1000  ################################\n",
      "Loss:  0.0001050399150699377\n",
      "################################  1001  ################################\n",
      "Loss:  0.00010470759298186749\n",
      "################################  1002  ################################\n",
      "Loss:  0.00010437516175443307\n",
      "################################  1003  ################################\n",
      "Loss:  0.00010404834756627679\n",
      "################################  1004  ################################\n",
      "Loss:  0.00010375749843660742\n",
      "################################  1005  ################################\n",
      "Loss:  0.00010348096839152277\n",
      "################################  1006  ################################\n",
      "Loss:  0.00010324071627110243\n",
      "################################  1007  ################################\n",
      "Loss:  0.00010302141890861094\n",
      "################################  1008  ################################\n",
      "Loss:  0.00010277636465616524\n",
      "################################  1009  ################################\n",
      "Loss:  0.00010259275586577132\n",
      "################################  1010  ################################\n",
      "Loss:  0.00010239881521556526\n",
      "################################  1011  ################################\n",
      "Loss:  0.00010219195974059403\n",
      "################################  1012  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.00010197373921982944\n",
      "################################  1013  ################################\n",
      "Loss:  0.00010179000673815608\n",
      "################################  1014  ################################\n",
      "Loss:  0.00010162009129999205\n",
      "################################  1015  ################################\n",
      "Loss:  0.00010144675616174936\n",
      "################################  1016  ################################\n",
      "Loss:  0.00010127669520443305\n",
      "################################  1017  ################################\n",
      "Loss:  0.00010109090362675488\n",
      "################################  1018  ################################\n",
      "Loss:  0.00010095293691847473\n",
      "################################  1019  ################################\n",
      "Loss:  0.00010082102380692959\n",
      "################################  1020  ################################\n",
      "Loss:  0.00010068040137412027\n",
      "################################  1021  ################################\n",
      "Loss:  0.00010052215657196939\n",
      "################################  1022  ################################\n",
      "Loss:  0.00010036797175416723\n",
      "################################  1023  ################################\n",
      "Loss:  0.00010023075446952134\n",
      "################################  1024  ################################\n",
      "Loss:  0.00010008687968365848\n",
      "################################  1025  ################################\n",
      "Loss:  9.99493568087928e-05\n",
      "################################  1026  ################################\n",
      "Loss:  9.98062314465642e-05\n",
      "################################  1027  ################################\n",
      "Loss:  9.964298078557476e-05\n",
      "################################  1028  ################################\n",
      "Loss:  9.947884973371401e-05\n",
      "################################  1029  ################################\n",
      "Loss:  9.930839587468654e-05\n",
      "################################  1030  ################################\n",
      "Loss:  9.913045505527407e-05\n",
      "################################  1031  ################################\n",
      "Loss:  9.89678519545123e-05\n",
      "################################  1032  ################################\n",
      "Loss:  9.879493882181123e-05\n",
      "################################  1033  ################################\n",
      "Loss:  9.863250306807458e-05\n",
      "################################  1034  ################################\n",
      "Loss:  9.846611646935344e-05\n",
      "################################  1035  ################################\n",
      "Loss:  9.825937740970403e-05\n",
      "################################  1036  ################################\n",
      "Loss:  9.808529284782708e-05\n",
      "################################  1037  ################################\n",
      "Loss:  9.790631884243339e-05\n",
      "################################  1038  ################################\n",
      "Loss:  9.769942698767409e-05\n",
      "################################  1039  ################################\n",
      "Loss:  9.749011223902926e-05\n",
      "################################  1040  ################################\n",
      "Loss:  9.726577263791114e-05\n",
      "################################  1041  ################################\n",
      "Loss:  9.707224671728909e-05\n",
      "################################  1042  ################################\n",
      "Loss:  9.68828535405919e-05\n",
      "################################  1043  ################################\n",
      "Loss:  9.668254642747343e-05\n",
      "################################  1044  ################################\n",
      "Loss:  9.648760897107422e-05\n",
      "################################  1045  ################################\n",
      "Loss:  9.630141721572727e-05\n",
      "################################  1046  ################################\n",
      "Loss:  9.610804409021512e-05\n",
      "################################  1047  ################################\n",
      "Loss:  9.593875438440591e-05\n",
      "################################  1048  ################################\n",
      "Loss:  9.576719457982108e-05\n",
      "################################  1049  ################################\n",
      "Loss:  9.561221668263897e-05\n",
      "################################  1050  ################################\n",
      "Loss:  9.545589273329824e-05\n",
      "################################  1051  ################################\n",
      "Loss:  9.528685041004792e-05\n",
      "################################  1052  ################################\n",
      "Loss:  9.513238910585642e-05\n",
      "################################  1053  ################################\n",
      "Loss:  9.497851715423167e-05\n",
      "################################  1054  ################################\n",
      "Loss:  9.483049507252872e-05\n",
      "################################  1055  ################################\n",
      "Loss:  9.468282223679125e-05\n",
      "################################  1056  ################################\n",
      "Loss:  9.453036182094365e-05\n",
      "################################  1057  ################################\n",
      "Loss:  9.438797133043408e-05\n",
      "################################  1058  ################################\n",
      "Loss:  9.425009920960292e-05\n",
      "################################  1059  ################################\n",
      "Loss:  9.410924394614995e-05\n",
      "################################  1060  ################################\n",
      "Loss:  9.39720994210802e-05\n",
      "################################  1061  ################################\n",
      "Loss:  9.383767610415816e-05\n",
      "################################  1062  ################################\n",
      "Loss:  9.370889893034473e-05\n",
      "################################  1063  ################################\n",
      "Loss:  9.358243551105261e-05\n",
      "################################  1064  ################################\n",
      "Loss:  9.345625585410744e-05\n",
      "################################  1065  ################################\n",
      "Loss:  9.333431808045134e-05\n",
      "################################  1066  ################################\n",
      "Loss:  9.320760000264272e-05\n",
      "################################  1067  ################################\n",
      "Loss:  9.30851892917417e-05\n",
      "################################  1068  ################################\n",
      "Loss:  9.29595043999143e-05\n",
      "################################  1069  ################################\n",
      "Loss:  9.285019768867642e-05\n",
      "################################  1070  ################################\n",
      "Loss:  9.27354849409312e-05\n",
      "################################  1071  ################################\n",
      "Loss:  9.260617662221193e-05\n",
      "################################  1072  ################################\n",
      "Loss:  9.248193236999214e-05\n",
      "################################  1073  ################################\n",
      "Loss:  9.23491534194909e-05\n",
      "################################  1074  ################################\n",
      "Loss:  9.222411608789116e-05\n",
      "################################  1075  ################################\n",
      "Loss:  9.208767005475238e-05\n",
      "################################  1076  ################################\n",
      "Loss:  9.192785364575684e-05\n",
      "################################  1077  ################################\n",
      "Loss:  9.174583829008043e-05\n",
      "################################  1078  ################################\n",
      "Loss:  9.159983892459422e-05\n",
      "################################  1079  ################################\n",
      "Loss:  9.142119233729318e-05\n",
      "################################  1080  ################################\n",
      "Loss:  9.119605965679511e-05\n",
      "################################  1081  ################################\n",
      "Loss:  9.098496229853481e-05\n",
      "################################  1082  ################################\n",
      "Loss:  9.077516006072983e-05\n",
      "################################  1083  ################################\n",
      "Loss:  9.056314593181014e-05\n",
      "################################  1084  ################################\n",
      "Loss:  9.033978858496994e-05\n",
      "################################  1085  ################################\n",
      "Loss:  9.011506335809827e-05\n",
      "################################  1086  ################################\n",
      "Loss:  8.988176705315709e-05\n",
      "################################  1087  ################################\n",
      "Loss:  8.965031884144992e-05\n",
      "################################  1088  ################################\n",
      "Loss:  8.942166459746659e-05\n",
      "################################  1089  ################################\n",
      "Loss:  8.919209358282387e-05\n",
      "################################  1090  ################################\n",
      "Loss:  8.896080544218421e-05\n",
      "################################  1091  ################################\n",
      "Loss:  8.872350008459762e-05\n",
      "################################  1092  ################################\n",
      "Loss:  8.851004531607032e-05\n",
      "################################  1093  ################################\n",
      "Loss:  8.831598097458482e-05\n",
      "################################  1094  ################################\n",
      "Loss:  8.811744919512421e-05\n",
      "################################  1095  ################################\n",
      "Loss:  8.795097528491169e-05\n",
      "################################  1096  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  8.779177005635574e-05\n",
      "################################  1097  ################################\n",
      "Loss:  8.763327059568837e-05\n",
      "################################  1098  ################################\n",
      "Loss:  8.749008702579886e-05\n",
      "################################  1099  ################################\n",
      "Loss:  8.733443974051625e-05\n",
      "################################  1100  ################################\n",
      "Loss:  8.720775076653808e-05\n",
      "################################  1101  ################################\n",
      "Loss:  8.707161759957671e-05\n",
      "################################  1102  ################################\n",
      "Loss:  8.692855772096664e-05\n",
      "################################  1103  ################################\n",
      "Loss:  8.678568701725453e-05\n",
      "################################  1104  ################################\n",
      "Loss:  8.664435154059902e-05\n",
      "################################  1105  ################################\n",
      "Loss:  8.650781092001125e-05\n",
      "################################  1106  ################################\n",
      "Loss:  8.637588325655088e-05\n",
      "################################  1107  ################################\n",
      "Loss:  8.624324982520193e-05\n",
      "################################  1108  ################################\n",
      "Loss:  8.611956582171842e-05\n",
      "################################  1109  ################################\n",
      "Loss:  8.599861757829785e-05\n",
      "################################  1110  ################################\n",
      "Loss:  8.588620403315872e-05\n",
      "################################  1111  ################################\n",
      "Loss:  8.578702545491979e-05\n",
      "################################  1112  ################################\n",
      "Loss:  8.565741882193834e-05\n",
      "################################  1113  ################################\n",
      "Loss:  8.557078399462625e-05\n",
      "################################  1114  ################################\n",
      "Loss:  8.546932804165408e-05\n",
      "################################  1115  ################################\n",
      "Loss:  8.535278175259009e-05\n",
      "################################  1116  ################################\n",
      "Loss:  8.522479038219899e-05\n",
      "################################  1117  ################################\n",
      "Loss:  8.509599138051271e-05\n",
      "################################  1118  ################################\n",
      "Loss:  8.497034286847338e-05\n",
      "################################  1119  ################################\n",
      "Loss:  8.4829174738843e-05\n",
      "################################  1120  ################################\n",
      "Loss:  8.470608736388385e-05\n",
      "################################  1121  ################################\n",
      "Loss:  8.459015225525945e-05\n",
      "################################  1122  ################################\n",
      "Loss:  8.446761785307899e-05\n",
      "################################  1123  ################################\n",
      "Loss:  8.434821938863024e-05\n",
      "################################  1124  ################################\n",
      "Loss:  8.422875544056296e-05\n",
      "################################  1125  ################################\n",
      "Loss:  8.411364979110658e-05\n",
      "################################  1126  ################################\n",
      "Loss:  8.400055958190933e-05\n",
      "################################  1127  ################################\n",
      "Loss:  8.389108552364632e-05\n",
      "################################  1128  ################################\n",
      "Loss:  8.378464553970844e-05\n",
      "################################  1129  ################################\n",
      "Loss:  8.367786358576268e-05\n",
      "################################  1130  ################################\n",
      "Loss:  8.357307524420321e-05\n",
      "################################  1131  ################################\n",
      "Loss:  8.34691891213879e-05\n",
      "################################  1132  ################################\n",
      "Loss:  8.336116297869012e-05\n",
      "################################  1133  ################################\n",
      "Loss:  8.326699025928974e-05\n",
      "################################  1134  ################################\n",
      "Loss:  8.316520688822493e-05\n",
      "################################  1135  ################################\n",
      "Loss:  8.30531062092632e-05\n",
      "################################  1136  ################################\n",
      "Loss:  8.2939732237719e-05\n",
      "################################  1137  ################################\n",
      "Loss:  8.283471106551588e-05\n",
      "################################  1138  ################################\n",
      "Loss:  8.273644198197871e-05\n",
      "################################  1139  ################################\n",
      "Loss:  8.263690688181669e-05\n",
      "################################  1140  ################################\n",
      "Loss:  8.254451677203178e-05\n",
      "################################  1141  ################################\n",
      "Loss:  8.244998753070831e-05\n",
      "################################  1142  ################################\n",
      "Loss:  8.235473796958104e-05\n",
      "################################  1143  ################################\n",
      "Loss:  8.226391219068319e-05\n",
      "################################  1144  ################################\n",
      "Loss:  8.216586138587445e-05\n",
      "################################  1145  ################################\n",
      "Loss:  8.208509825635701e-05\n",
      "################################  1146  ################################\n",
      "Loss:  8.199183503165841e-05\n",
      "################################  1147  ################################\n",
      "Loss:  8.188671199604869e-05\n",
      "################################  1148  ################################\n",
      "Loss:  8.176277333404869e-05\n",
      "################################  1149  ################################\n",
      "Loss:  8.164568862412125e-05\n",
      "################################  1150  ################################\n",
      "Loss:  8.152692316798493e-05\n",
      "################################  1151  ################################\n",
      "Loss:  8.137088298099115e-05\n",
      "################################  1152  ################################\n",
      "Loss:  8.124973101075739e-05\n",
      "################################  1153  ################################\n",
      "Loss:  8.10946585261263e-05\n",
      "################################  1154  ################################\n",
      "Loss:  8.092829375527799e-05\n",
      "################################  1155  ################################\n",
      "Loss:  8.073722710832953e-05\n",
      "################################  1156  ################################\n",
      "Loss:  8.05695162853226e-05\n",
      "################################  1157  ################################\n",
      "Loss:  8.037563384277746e-05\n",
      "################################  1158  ################################\n",
      "Loss:  8.015889761736616e-05\n",
      "################################  1159  ################################\n",
      "Loss:  7.992015889612958e-05\n",
      "################################  1160  ################################\n",
      "Loss:  7.965267286635935e-05\n",
      "################################  1161  ################################\n",
      "Loss:  7.937676855362952e-05\n",
      "################################  1162  ################################\n",
      "Loss:  7.910208660177886e-05\n",
      "################################  1163  ################################\n",
      "Loss:  7.883013313403353e-05\n",
      "################################  1164  ################################\n",
      "Loss:  7.855119474697858e-05\n",
      "################################  1165  ################################\n",
      "Loss:  7.828150410205126e-05\n",
      "################################  1166  ################################\n",
      "Loss:  7.801647006999701e-05\n",
      "################################  1167  ################################\n",
      "Loss:  7.776405982440338e-05\n",
      "################################  1168  ################################\n",
      "Loss:  7.753043610136956e-05\n",
      "################################  1169  ################################\n",
      "Loss:  7.730215293122455e-05\n",
      "################################  1170  ################################\n",
      "Loss:  7.710171485086903e-05\n",
      "################################  1171  ################################\n",
      "Loss:  7.690413622185588e-05\n",
      "################################  1172  ################################\n",
      "Loss:  7.674113294342533e-05\n",
      "################################  1173  ################################\n",
      "Loss:  7.657944661332294e-05\n",
      "################################  1174  ################################\n",
      "Loss:  7.641078263986856e-05\n",
      "################################  1175  ################################\n",
      "Loss:  7.626384467585012e-05\n",
      "################################  1176  ################################\n",
      "Loss:  7.611565524712205e-05\n",
      "################################  1177  ################################\n",
      "Loss:  7.599337550345808e-05\n",
      "################################  1178  ################################\n",
      "Loss:  7.586731953779235e-05\n",
      "################################  1179  ################################\n",
      "Loss:  7.574667688459158e-05\n",
      "################################  1180  ################################\n",
      "Loss:  7.561412348877639e-05\n",
      "################################  1181  ################################\n",
      "Loss:  7.547152927145362e-05\n",
      "################################  1182  ################################\n",
      "Loss:  7.53376807551831e-05\n",
      "################################  1183  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  7.519972859881818e-05\n",
      "################################  1184  ################################\n",
      "Loss:  7.505740359192714e-05\n",
      "################################  1185  ################################\n",
      "Loss:  7.491916039725766e-05\n",
      "################################  1186  ################################\n",
      "Loss:  7.478253246517852e-05\n",
      "################################  1187  ################################\n",
      "Loss:  7.464686495950446e-05\n",
      "################################  1188  ################################\n",
      "Loss:  7.451405690517277e-05\n",
      "################################  1189  ################################\n",
      "Loss:  7.438042666763067e-05\n",
      "################################  1190  ################################\n",
      "Loss:  7.425204967148602e-05\n",
      "################################  1191  ################################\n",
      "Loss:  7.412418926833197e-05\n",
      "################################  1192  ################################\n",
      "Loss:  7.39951356081292e-05\n",
      "################################  1193  ################################\n",
      "Loss:  7.386482320725918e-05\n",
      "################################  1194  ################################\n",
      "Loss:  7.373106927843764e-05\n",
      "################################  1195  ################################\n",
      "Loss:  7.360958989011124e-05\n",
      "################################  1196  ################################\n",
      "Loss:  7.349472434725612e-05\n",
      "################################  1197  ################################\n",
      "Loss:  7.338501018239185e-05\n",
      "################################  1198  ################################\n",
      "Loss:  7.32792541384697e-05\n",
      "################################  1199  ################################\n",
      "Loss:  7.317657582461834e-05\n",
      "################################  1200  ################################\n",
      "Loss:  7.307391206268221e-05\n",
      "################################  1201  ################################\n",
      "Loss:  7.297552656382322e-05\n",
      "################################  1202  ################################\n",
      "Loss:  7.288308552233502e-05\n",
      "################################  1203  ################################\n",
      "Loss:  7.279019337147474e-05\n",
      "################################  1204  ################################\n",
      "Loss:  7.269981142599136e-05\n",
      "################################  1205  ################################\n",
      "Loss:  7.260667916852981e-05\n",
      "################################  1206  ################################\n",
      "Loss:  7.250935595948249e-05\n",
      "################################  1207  ################################\n",
      "Loss:  7.241244748001918e-05\n",
      "################################  1208  ################################\n",
      "Loss:  7.231712515931576e-05\n",
      "################################  1209  ################################\n",
      "Loss:  7.221983833005652e-05\n",
      "################################  1210  ################################\n",
      "Loss:  7.212395576061681e-05\n",
      "################################  1211  ################################\n",
      "Loss:  7.201893458841369e-05\n",
      "################################  1212  ################################\n",
      "Loss:  7.192260818555951e-05\n",
      "################################  1213  ################################\n",
      "Loss:  7.182876288425177e-05\n",
      "################################  1214  ################################\n",
      "Loss:  7.174778147600591e-05\n",
      "################################  1215  ################################\n",
      "Loss:  7.165365968830884e-05\n",
      "################################  1216  ################################\n",
      "Loss:  7.15468340786174e-05\n",
      "################################  1217  ################################\n",
      "Loss:  7.142943650251254e-05\n",
      "################################  1218  ################################\n",
      "Loss:  7.129920413717628e-05\n",
      "################################  1219  ################################\n",
      "Loss:  7.116846245480701e-05\n",
      "################################  1220  ################################\n",
      "Loss:  7.103039388312027e-05\n",
      "################################  1221  ################################\n",
      "Loss:  7.089821883710101e-05\n",
      "################################  1222  ################################\n",
      "Loss:  7.076699694152921e-05\n",
      "################################  1223  ################################\n",
      "Loss:  7.063586235744879e-05\n",
      "################################  1224  ################################\n",
      "Loss:  7.050437125144526e-05\n",
      "################################  1225  ################################\n",
      "Loss:  7.038202602416277e-05\n",
      "################################  1226  ################################\n",
      "Loss:  7.02626712154597e-05\n",
      "################################  1227  ################################\n",
      "Loss:  7.014735456323251e-05\n",
      "################################  1228  ################################\n",
      "Loss:  7.003925566095859e-05\n",
      "################################  1229  ################################\n",
      "Loss:  6.993216811679304e-05\n",
      "################################  1230  ################################\n",
      "Loss:  6.983542698435485e-05\n",
      "################################  1231  ################################\n",
      "Loss:  6.973969721002504e-05\n",
      "################################  1232  ################################\n",
      "Loss:  6.965453940210864e-05\n",
      "################################  1233  ################################\n",
      "Loss:  6.956732249818742e-05\n",
      "################################  1234  ################################\n",
      "Loss:  6.948017835384235e-05\n",
      "################################  1235  ################################\n",
      "Loss:  6.938246224308386e-05\n",
      "################################  1236  ################################\n",
      "Loss:  6.929752271389589e-05\n",
      "################################  1237  ################################\n",
      "Loss:  6.91874956828542e-05\n",
      "################################  1238  ################################\n",
      "Loss:  6.91014138283208e-05\n",
      "################################  1239  ################################\n",
      "Loss:  6.900391599629074e-05\n",
      "################################  1240  ################################\n",
      "Loss:  6.888721691211686e-05\n",
      "################################  1241  ################################\n",
      "Loss:  6.877990381326526e-05\n",
      "################################  1242  ################################\n",
      "Loss:  6.866842159070075e-05\n",
      "################################  1243  ################################\n",
      "Loss:  6.856593245174736e-05\n",
      "################################  1244  ################################\n",
      "Loss:  6.846441829111427e-05\n",
      "################################  1245  ################################\n",
      "Loss:  6.835328531451523e-05\n",
      "################################  1246  ################################\n",
      "Loss:  6.824791489634663e-05\n",
      "################################  1247  ################################\n",
      "Loss:  6.814719381509349e-05\n",
      "################################  1248  ################################\n",
      "Loss:  6.804822623962536e-05\n",
      "################################  1249  ################################\n",
      "Loss:  6.795654917368665e-05\n",
      "################################  1250  ################################\n",
      "Loss:  6.786039739381522e-05\n",
      "################################  1251  ################################\n",
      "Loss:  6.7780158133246e-05\n",
      "################################  1252  ################################\n",
      "Loss:  6.770201434846967e-05\n",
      "################################  1253  ################################\n",
      "Loss:  6.763570127077401e-05\n",
      "################################  1254  ################################\n",
      "Loss:  6.757442315574735e-05\n",
      "################################  1255  ################################\n",
      "Loss:  6.750783359166235e-05\n",
      "################################  1256  ################################\n",
      "Loss:  6.745025893906131e-05\n",
      "################################  1257  ################################\n",
      "Loss:  6.73897156957537e-05\n",
      "################################  1258  ################################\n",
      "Loss:  6.734505586791784e-05\n",
      "################################  1259  ################################\n",
      "Loss:  6.729066808475181e-05\n",
      "################################  1260  ################################\n",
      "Loss:  6.723180558765307e-05\n",
      "################################  1261  ################################\n",
      "Loss:  6.715868948958814e-05\n",
      "################################  1262  ################################\n",
      "Loss:  6.709478475386277e-05\n",
      "################################  1263  ################################\n",
      "Loss:  6.701129314024001e-05\n",
      "################################  1264  ################################\n",
      "Loss:  6.692943134112284e-05\n",
      "################################  1265  ################################\n",
      "Loss:  6.684137770207599e-05\n",
      "################################  1266  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  6.674408359685913e-05\n",
      "################################  1267  ################################\n",
      "Loss:  6.66529085719958e-05\n",
      "################################  1268  ################################\n",
      "Loss:  6.656007462879643e-05\n",
      "################################  1269  ################################\n",
      "Loss:  6.646553083555773e-05\n",
      "################################  1270  ################################\n",
      "Loss:  6.637300248257816e-05\n",
      "################################  1271  ################################\n",
      "Loss:  6.627937545999885e-05\n",
      "################################  1272  ################################\n",
      "Loss:  6.61871672491543e-05\n",
      "################################  1273  ################################\n",
      "Loss:  6.61019585095346e-05\n",
      "################################  1274  ################################\n",
      "Loss:  6.602186476811767e-05\n",
      "################################  1275  ################################\n",
      "Loss:  6.59512952552177e-05\n",
      "################################  1276  ################################\n",
      "Loss:  6.588241376448423e-05\n",
      "################################  1277  ################################\n",
      "Loss:  6.581554043805227e-05\n",
      "################################  1278  ################################\n",
      "Loss:  6.575732550118119e-05\n",
      "################################  1279  ################################\n",
      "Loss:  6.569330435013399e-05\n",
      "################################  1280  ################################\n",
      "Loss:  6.56438060104847e-05\n",
      "################################  1281  ################################\n",
      "Loss:  6.557765300385654e-05\n",
      "################################  1282  ################################\n",
      "Loss:  6.549360114149749e-05\n",
      "################################  1283  ################################\n",
      "Loss:  6.539892638102174e-05\n",
      "################################  1284  ################################\n",
      "Loss:  6.52883027214557e-05\n",
      "################################  1285  ################################\n",
      "Loss:  6.517668953165412e-05\n",
      "################################  1286  ################################\n",
      "Loss:  6.506049976451322e-05\n",
      "################################  1287  ################################\n",
      "Loss:  6.494730769190937e-05\n",
      "################################  1288  ################################\n",
      "Loss:  6.48281566100195e-05\n",
      "################################  1289  ################################\n",
      "Loss:  6.470238440670073e-05\n",
      "################################  1290  ################################\n",
      "Loss:  6.457147537730634e-05\n",
      "################################  1291  ################################\n",
      "Loss:  6.44376123091206e-05\n",
      "################################  1292  ################################\n",
      "Loss:  6.430457142414525e-05\n",
      "################################  1293  ################################\n",
      "Loss:  6.416750693460926e-05\n",
      "################################  1294  ################################\n",
      "Loss:  6.40344587736763e-05\n",
      "################################  1295  ################################\n",
      "Loss:  6.390156340785325e-05\n",
      "################################  1296  ################################\n",
      "Loss:  6.375922384904698e-05\n",
      "################################  1297  ################################\n",
      "Loss:  6.362599378917366e-05\n",
      "################################  1298  ################################\n",
      "Loss:  6.34914031252265e-05\n",
      "################################  1299  ################################\n",
      "Loss:  6.336242950055748e-05\n",
      "################################  1300  ################################\n",
      "Loss:  6.323269917629659e-05\n",
      "################################  1301  ################################\n",
      "Loss:  6.31079965387471e-05\n",
      "################################  1302  ################################\n",
      "Loss:  6.297371146501973e-05\n",
      "################################  1303  ################################\n",
      "Loss:  6.284908158704638e-05\n",
      "################################  1304  ################################\n",
      "Loss:  6.271652819123119e-05\n",
      "################################  1305  ################################\n",
      "Loss:  6.256244523683563e-05\n",
      "################################  1306  ################################\n",
      "Loss:  6.241642404347658e-05\n",
      "################################  1307  ################################\n",
      "Loss:  6.228347774595022e-05\n",
      "################################  1308  ################################\n",
      "Loss:  6.214345194166526e-05\n",
      "################################  1309  ################################\n",
      "Loss:  6.202213262440637e-05\n",
      "################################  1310  ################################\n",
      "Loss:  6.190758722368628e-05\n",
      "################################  1311  ################################\n",
      "Loss:  6.178448529681191e-05\n",
      "################################  1312  ################################\n",
      "Loss:  6.16810139035806e-05\n",
      "################################  1313  ################################\n",
      "Loss:  6.15792305325158e-05\n",
      "################################  1314  ################################\n",
      "Loss:  6.14620657870546e-05\n",
      "################################  1315  ################################\n",
      "Loss:  6.137491436675191e-05\n",
      "################################  1316  ################################\n",
      "Loss:  6.129578105174005e-05\n",
      "################################  1317  ################################\n",
      "Loss:  6.121830665506423e-05\n",
      "################################  1318  ################################\n",
      "Loss:  6.113949348218739e-05\n",
      "################################  1319  ################################\n",
      "Loss:  6.107479566708207e-05\n",
      "################################  1320  ################################\n",
      "Loss:  6.1011982324998826e-05\n",
      "################################  1321  ################################\n",
      "Loss:  6.0949474573135376e-05\n",
      "################################  1322  ################################\n",
      "Loss:  6.0887145082233474e-05\n",
      "################################  1323  ################################\n",
      "Loss:  6.082897016312927e-05\n",
      "################################  1324  ################################\n",
      "Loss:  6.0773872974095866e-05\n",
      "################################  1325  ################################\n",
      "Loss:  6.071445386623964e-05\n",
      "################################  1326  ################################\n",
      "Loss:  6.066207788535394e-05\n",
      "################################  1327  ################################\n",
      "Loss:  6.060692248865962e-05\n",
      "################################  1328  ################################\n",
      "Loss:  6.0544683947227895e-05\n",
      "################################  1329  ################################\n",
      "Loss:  6.048229261068627e-05\n",
      "################################  1330  ################################\n",
      "Loss:  6.0419493820518255e-05\n",
      "################################  1331  ################################\n",
      "Loss:  6.035427577444352e-05\n",
      "################################  1332  ################################\n",
      "Loss:  6.029215728631243e-05\n",
      "################################  1333  ################################\n",
      "Loss:  6.022844172548503e-05\n",
      "################################  1334  ################################\n",
      "Loss:  6.016597762936726e-05\n",
      "################################  1335  ################################\n",
      "Loss:  6.010195647832006e-05\n",
      "################################  1336  ################################\n",
      "Loss:  6.003546513966285e-05\n",
      "################################  1337  ################################\n",
      "Loss:  5.997072730679065e-05\n",
      "################################  1338  ################################\n",
      "Loss:  5.990392673993483e-05\n",
      "################################  1339  ################################\n",
      "Loss:  5.983976734569296e-05\n",
      "################################  1340  ################################\n",
      "Loss:  5.9772064560092986e-05\n",
      "################################  1341  ################################\n",
      "Loss:  5.9710946516133845e-05\n",
      "################################  1342  ################################\n",
      "Loss:  5.965235686744563e-05\n",
      "################################  1343  ################################\n",
      "Loss:  5.9588383010122925e-05\n",
      "################################  1344  ################################\n",
      "Loss:  5.951496495981701e-05\n",
      "################################  1345  ################################\n",
      "Loss:  5.9435758885229006e-05\n",
      "################################  1346  ################################\n",
      "Loss:  5.937478272244334e-05\n",
      "################################  1347  ################################\n",
      "Loss:  5.9317451814422384e-05\n",
      "################################  1348  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.925462755840272e-05\n",
      "################################  1349  ################################\n",
      "Loss:  5.919487739447504e-05\n",
      "################################  1350  ################################\n",
      "Loss:  5.913869972573593e-05\n",
      "################################  1351  ################################\n",
      "Loss:  5.9081881772726774e-05\n",
      "################################  1352  ################################\n",
      "Loss:  5.902967677684501e-05\n",
      "################################  1353  ################################\n",
      "Loss:  5.897662413190119e-05\n",
      "################################  1354  ################################\n",
      "Loss:  5.892892659176141e-05\n",
      "################################  1355  ################################\n",
      "Loss:  5.888548184884712e-05\n",
      "################################  1356  ################################\n",
      "Loss:  5.883850099053234e-05\n",
      "################################  1357  ################################\n",
      "Loss:  5.879634409211576e-05\n",
      "################################  1358  ################################\n",
      "Loss:  5.87538379477337e-05\n",
      "################################  1359  ################################\n",
      "Loss:  5.87063332204707e-05\n",
      "################################  1360  ################################\n",
      "Loss:  5.866527499165386e-05\n",
      "################################  1361  ################################\n",
      "Loss:  5.862368561793119e-05\n",
      "################################  1362  ################################\n",
      "Loss:  5.858174336026423e-05\n",
      "################################  1363  ################################\n",
      "Loss:  5.854198388988152e-05\n",
      "################################  1364  ################################\n",
      "Loss:  5.8501474995864555e-05\n",
      "################################  1365  ################################\n",
      "Loss:  5.8464534959057346e-05\n",
      "################################  1366  ################################\n",
      "Loss:  5.842640166520141e-05\n",
      "################################  1367  ################################\n",
      "Loss:  5.8385790907777846e-05\n",
      "################################  1368  ################################\n",
      "Loss:  5.834180774400011e-05\n",
      "################################  1369  ################################\n",
      "Loss:  5.8294564951211214e-05\n",
      "################################  1370  ################################\n",
      "Loss:  5.8245779655408114e-05\n",
      "################################  1371  ################################\n",
      "Loss:  5.819408397655934e-05\n",
      "################################  1372  ################################\n",
      "Loss:  5.814719042973593e-05\n",
      "################################  1373  ################################\n",
      "Loss:  5.809815775137395e-05\n",
      "################################  1374  ################################\n",
      "Loss:  5.804961620015092e-05\n",
      "################################  1375  ################################\n",
      "Loss:  5.800357394036837e-05\n",
      "################################  1376  ################################\n",
      "Loss:  5.795616743853316e-05\n",
      "################################  1377  ################################\n",
      "Loss:  5.7911798649001867e-05\n",
      "################################  1378  ################################\n",
      "Loss:  5.786764086224139e-05\n",
      "################################  1379  ################################\n",
      "Loss:  5.782637163065374e-05\n",
      "################################  1380  ################################\n",
      "Loss:  5.778630293207243e-05\n",
      "################################  1381  ################################\n",
      "Loss:  5.7746445236261934e-05\n",
      "################################  1382  ################################\n",
      "Loss:  5.7712342822924256e-05\n",
      "################################  1383  ################################\n",
      "Loss:  5.767313632532023e-05\n",
      "################################  1384  ################################\n",
      "Loss:  5.7640892919152975e-05\n",
      "################################  1385  ################################\n",
      "Loss:  5.760033673141152e-05\n",
      "################################  1386  ################################\n",
      "Loss:  5.755489110015333e-05\n",
      "################################  1387  ################################\n",
      "Loss:  5.7503930293023586e-05\n",
      "################################  1388  ################################\n",
      "Loss:  5.7460125390207395e-05\n",
      "################################  1389  ################################\n",
      "Loss:  5.741636414313689e-05\n",
      "################################  1390  ################################\n",
      "Loss:  5.736270031775348e-05\n",
      "################################  1391  ################################\n",
      "Loss:  5.7308767281938344e-05\n",
      "################################  1392  ################################\n",
      "Loss:  5.7244258641730994e-05\n",
      "################################  1393  ################################\n",
      "Loss:  5.7186989579349756e-05\n",
      "################################  1394  ################################\n",
      "Loss:  5.7112501963274553e-05\n",
      "################################  1395  ################################\n",
      "Loss:  5.703591159544885e-05\n",
      "################################  1396  ################################\n",
      "Loss:  5.695586514775641e-05\n",
      "################################  1397  ################################\n",
      "Loss:  5.687677548849024e-05\n",
      "################################  1398  ################################\n",
      "Loss:  5.679895548382774e-05\n",
      "################################  1399  ################################\n",
      "Loss:  5.672163388226181e-05\n",
      "################################  1400  ################################\n",
      "Loss:  5.6645225413376465e-05\n",
      "################################  1401  ################################\n",
      "Loss:  5.6566168495919555e-05\n",
      "################################  1402  ################################\n",
      "Loss:  5.649183003697544e-05\n",
      "################################  1403  ################################\n",
      "Loss:  5.641725147143006e-05\n",
      "################################  1404  ################################\n",
      "Loss:  5.634809349430725e-05\n",
      "################################  1405  ################################\n",
      "Loss:  5.628275903291069e-05\n",
      "################################  1406  ################################\n",
      "Loss:  5.6217319070128724e-05\n",
      "################################  1407  ################################\n",
      "Loss:  5.6156561186071485e-05\n",
      "################################  1408  ################################\n",
      "Loss:  5.609692379948683e-05\n",
      "################################  1409  ################################\n",
      "Loss:  5.603803219855763e-05\n",
      "################################  1410  ################################\n",
      "Loss:  5.597812560154125e-05\n",
      "################################  1411  ################################\n",
      "Loss:  5.5926120694493875e-05\n",
      "################################  1412  ################################\n",
      "Loss:  5.5876735132187605e-05\n",
      "################################  1413  ################################\n",
      "Loss:  5.582801532000303e-05\n",
      "################################  1414  ################################\n",
      "Loss:  5.578014679485932e-05\n",
      "################################  1415  ################################\n",
      "Loss:  5.573204543907195e-05\n",
      "################################  1416  ################################\n",
      "Loss:  5.568341657635756e-05\n",
      "################################  1417  ################################\n",
      "Loss:  5.563654485740699e-05\n",
      "################################  1418  ################################\n",
      "Loss:  5.559526471188292e-05\n",
      "################################  1419  ################################\n",
      "Loss:  5.555056850425899e-05\n",
      "################################  1420  ################################\n",
      "Loss:  5.5511398386443034e-05\n",
      "################################  1421  ################################\n",
      "Loss:  5.5462187447119504e-05\n",
      "################################  1422  ################################\n",
      "Loss:  5.541190694202669e-05\n",
      "################################  1423  ################################\n",
      "Loss:  5.535568197956309e-05\n",
      "################################  1424  ################################\n",
      "Loss:  5.5293301556957886e-05\n",
      "################################  1425  ################################\n",
      "Loss:  5.5223790695890784e-05\n",
      "################################  1426  ################################\n",
      "Loss:  5.5146796512417495e-05\n",
      "################################  1427  ################################\n",
      "Loss:  5.506510933628306e-05\n",
      "################################  1428  ################################\n",
      "Loss:  5.498290920513682e-05\n",
      "################################  1429  ################################\n",
      "Loss:  5.489658360602334e-05\n",
      "################################  1430  ################################\n",
      "Loss:  5.480711115524173e-05\n",
      "################################  1431  ################################\n",
      "Loss:  5.471710392157547e-05\n",
      "################################  1432  ################################\n",
      "Loss:  5.462241460918449e-05\n",
      "################################  1433  ################################\n",
      "Loss:  5.45310067536775e-05\n",
      "################################  1434  ################################\n",
      "Loss:  5.444014823297039e-05\n",
      "################################  1435  ################################\n",
      "Loss:  5.4353575251298025e-05\n",
      "################################  1436  ################################\n",
      "Loss:  5.427030919236131e-05\n",
      "################################  1437  ################################\n",
      "Loss:  5.418885120889172e-05\n",
      "################################  1438  ################################\n",
      "Loss:  5.411531310528517e-05\n",
      "################################  1439  ################################\n",
      "Loss:  5.404285911936313e-05\n",
      "################################  1440  ################################\n",
      "Loss:  5.3978532378096133e-05\n",
      "################################  1441  ################################\n",
      "Loss:  5.3914885938866064e-05\n",
      "################################  1442  ################################\n",
      "Loss:  5.385831173043698e-05\n",
      "################################  1443  ################################\n",
      "Loss:  5.3800664318259805e-05\n",
      "################################  1444  ################################\n",
      "Loss:  5.37399246240966e-05\n",
      "################################  1445  ################################\n",
      "Loss:  5.368024358176626e-05\n",
      "################################  1446  ################################\n",
      "Loss:  5.361986768548377e-05\n",
      "################################  1447  ################################\n",
      "Loss:  5.356547626433894e-05\n",
      "################################  1448  ################################\n",
      "Loss:  5.3508916607825086e-05\n",
      "################################  1449  ################################\n",
      "Loss:  5.345804675016552e-05\n",
      "################################  1450  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.3405794460559264e-05\n",
      "################################  1451  ################################\n",
      "Loss:  5.3349416702985764e-05\n",
      "################################  1452  ################################\n",
      "Loss:  5.329351552063599e-05\n",
      "################################  1453  ################################\n",
      "Loss:  5.3236923122312874e-05\n",
      "################################  1454  ################################\n",
      "Loss:  5.3177704103291035e-05\n",
      "################################  1455  ################################\n",
      "Loss:  5.312686334946193e-05\n",
      "################################  1456  ################################\n",
      "Loss:  5.30696488567628e-05\n",
      "################################  1457  ################################\n",
      "Loss:  5.30126562807709e-05\n",
      "################################  1458  ################################\n",
      "Loss:  5.2938317821826786e-05\n",
      "################################  1459  ################################\n",
      "Loss:  5.2863979362882674e-05\n",
      "################################  1460  ################################\n",
      "Loss:  5.277092714095488e-05\n",
      "################################  1461  ################################\n",
      "Loss:  5.2677241910714656e-05\n",
      "################################  1462  ################################\n",
      "Loss:  5.2577335736714303e-05\n",
      "################################  1463  ################################\n",
      "Loss:  5.247813533060253e-05\n",
      "################################  1464  ################################\n",
      "Loss:  5.2384370064828545e-05\n",
      "################################  1465  ################################\n",
      "Loss:  5.2278581279097125e-05\n",
      "################################  1466  ################################\n",
      "Loss:  5.2194835006957874e-05\n",
      "################################  1467  ################################\n",
      "Loss:  5.211244570091367e-05\n",
      "################################  1468  ################################\n",
      "Loss:  5.20348476129584e-05\n",
      "################################  1469  ################################\n",
      "Loss:  5.195744233787991e-05\n",
      "################################  1470  ################################\n",
      "Loss:  5.188081195228733e-05\n",
      "################################  1471  ################################\n",
      "Loss:  5.180824882700108e-05\n",
      "################################  1472  ################################\n",
      "Loss:  5.173776298761368e-05\n",
      "################################  1473  ################################\n",
      "Loss:  5.1673669076990336e-05\n",
      "################################  1474  ################################\n",
      "Loss:  5.161190347280353e-05\n",
      "################################  1475  ################################\n",
      "Loss:  5.1554296078393236e-05\n",
      "################################  1476  ################################\n",
      "Loss:  5.149870412424207e-05\n",
      "################################  1477  ################################\n",
      "Loss:  5.145456816535443e-05\n",
      "################################  1478  ################################\n",
      "Loss:  5.140866414876655e-05\n",
      "################################  1479  ################################\n",
      "Loss:  5.1362112571951e-05\n",
      "################################  1480  ################################\n",
      "Loss:  5.132252408657223e-05\n",
      "################################  1481  ################################\n",
      "Loss:  5.1279610488563776e-05\n",
      "################################  1482  ################################\n",
      "Loss:  5.1244773203507066e-05\n",
      "################################  1483  ################################\n",
      "Loss:  5.120869536767714e-05\n",
      "################################  1484  ################################\n",
      "Loss:  5.116737156640738e-05\n",
      "################################  1485  ################################\n",
      "Loss:  5.112440703669563e-05\n",
      "################################  1486  ################################\n",
      "Loss:  5.109062840347178e-05\n",
      "################################  1487  ################################\n",
      "Loss:  5.105890522827394e-05\n",
      "################################  1488  ################################\n",
      "Loss:  5.102922295918688e-05\n",
      "################################  1489  ################################\n",
      "Loss:  5.099777990835719e-05\n",
      "################################  1490  ################################\n",
      "Loss:  5.09649544255808e-05\n",
      "################################  1491  ################################\n",
      "Loss:  5.092909123050049e-05\n",
      "################################  1492  ################################\n",
      "Loss:  5.089242404210381e-05\n",
      "################################  1493  ################################\n",
      "Loss:  5.085408338345587e-05\n",
      "################################  1494  ################################\n",
      "Loss:  5.081294511910528e-05\n",
      "################################  1495  ################################\n",
      "Loss:  5.0776598072843626e-05\n",
      "################################  1496  ################################\n",
      "Loss:  5.0741273298626766e-05\n",
      "################################  1497  ################################\n",
      "Loss:  5.0705122703220695e-05\n",
      "################################  1498  ################################\n",
      "Loss:  5.066640005679801e-05\n",
      "################################  1499  ################################\n",
      "Loss:  5.0635273510124534e-05\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1500\n",
    "history = fit(my_network, training_set, interior, n_epochs, optimizer_, p=2, verbose=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading Model\n",
    "FILE = \"maxwell2D_5.pth\"\n",
    "torch.save(my_network, FILE)\n",
    "\n",
    "# uncomment below when you need to test for different points\n",
    "#my_network = torch.load(FILE)\n",
    "#my_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading Model (this model with reported results)\n",
    "#FILE = \"second.pth\"\n",
    "#torch.save(my_network, FILE)\n",
    "\n",
    "# uncomment below when you need to test for different points\n",
    "#my_network = torch.load(FILE)\n",
    "#my_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.linspace(0, 1, 10000).reshape(-1,1)\n",
    "y_test = torch.linspace(0, 1, 10000).reshape(-1,1)\n",
    "t_test = torch.ones((10000,1))\n",
    "test = torch.cat([x_test, y_test, t_test],1)\n",
    "h_test = exact_solution_h(x_test, y_test, t_test).reshape(-1,1)\n",
    "e1_test = exact_solution_e1(x_test, y_test, t_test).reshape(-1,1)\n",
    "e2_test = exact_solution_e2(x_test, y_test, t_test).reshape(-1,1)\n",
    "w_test_pred = my_network(test)\n",
    "h_test_pred = w_test_pred[:,0].reshape(-1,1)\n",
    "e1_test_pred = w_test_pred[:,1].reshape(-1,1)\n",
    "e2_test_pred = w_test_pred[:,2].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f43300ee880>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(x_test, h_test, label=\"Ground Truth\",lw=2)\n",
    "plt.plot(x_test, h_test_pred.detach(), label=\"Network Prediction\",lw=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"u\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Error Test:  0.021610491967294365 %\n"
     ]
    }
   ],
   "source": [
    "# Compute the relative L2 error norm (generalization error)\n",
    "relative_error_test = torch.mean((h_test_pred - h_test)**2)/torch.mean(h_test**2)\n",
    "#relative_error_test = torch.max(torch.abs(u_test_pred -u_test))/torch.max(torch.abs(u_test))\n",
    "print(\"Relative Error Test: \", relative_error_test.detach().numpy()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f433a4aee20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(x_test, e1_test, label=\"Ground Truth\",lw=2)\n",
    "plt.plot(x_test, e1_test_pred.detach(), label=\"Network Prediction\",lw=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"u\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Error Test:  0.0011403158168832306 %\n"
     ]
    }
   ],
   "source": [
    "# Compute the relative L2 error norm (generalization error)\n",
    "relative_error_test = torch.mean((e1_test_pred - e1_test)**2)/torch.mean(e1_test**2)\n",
    "#relative_error_test = torch.max(torch.abs(u_test_pred -u_test))/torch.max(torch.abs(u_test))\n",
    "print(\"Relative Error Test: \", relative_error_test.detach().numpy()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Error Test:  0.008678590529598296 %\n"
     ]
    }
   ],
   "source": [
    "# Compute the relative L2 error norm (generalization error)\n",
    "relative_error_test = torch.mean((e2_test_pred - e2_test)**2)/torch.mean(e2_test**2)\n",
    "#relative_error_test = torch.max(torch.abs(u_test_pred -u_test))/torch.max(torch.abs(u_test))\n",
    "print(\"Relative Error Test: \", relative_error_test.detach().numpy()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exact_solution_u' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m t_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100000\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_test, t_test],\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m u_test \u001b[38;5;241m=\u001b[39m \u001b[43mexact_solution_u\u001b[49m(x_test,t_test)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m p_test \u001b[38;5;241m=\u001b[39m exact_solution_p(x_test,t_test)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m u_test_pred \u001b[38;5;241m=\u001b[39m my_network(test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exact_solution_u' is not defined"
     ]
    }
   ],
   "source": [
    "model = my_network\n",
    "x_test = pi*torch.rand(100000).reshape(-1,1)\n",
    "t_test = torch.rand(100000).reshape(-1,1)\n",
    "test = torch.cat([x_test, t_test],1)\n",
    "u_test = exact_solution_u(x_test,t_test).reshape(-1,1)\n",
    "p_test = exact_solution_p(x_test,t_test).reshape(-1,1)\n",
    "u_test_pred = my_network(test)\n",
    "u_pred = u_test_pred[:, 0].reshape(-1,1)\n",
    "\n",
    "u_pred1 = u_test_pred[:, 1].reshape(-1,1)\n",
    "\n",
    "\n",
    "relative_error = torch.abs(u_pred- u_test)\n",
    "\n",
    "relative_error1 = torch.abs(u_pred1- p_test)\n",
    "u_pred = u_pred.detach().numpy()\n",
    "x_test = x_test.detach().numpy()\n",
    "t_test = t_test.detach().numpy()\n",
    "p_pred = u_pred1.detach().numpy()\n",
    "relative_error = relative_error.detach().numpy()\n",
    "relative_error1 = relative_error1.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test = x_test.reshape(-1,)\n",
    "t_test = t_test.reshape(-1,)\n",
    "\n",
    "u_pred = u_pred.reshape(-1,)\n",
    "p_pred = p_pred.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "\n",
    "\n",
    "CS = plt.tricontourf(x_test, t_test, u_pred, 20, cmap='turbo')\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(CS)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "     t.set_fontsize(20)\n",
    "\n",
    "\n",
    "plt.xlabel('x', fontsize=20)\n",
    "plt.ylabel('t', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "\n",
    "#plt.savefig('timo_u.png', dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS = plt.tricontourf(x_test, t_test, p_pred, 20, cmap='turbo')\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(CS)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "     t.set_fontsize(20)\n",
    "\n",
    "\n",
    "plt.xlabel('x', fontsize=20)\n",
    "plt.ylabel('t', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "#plt.savefig('timo_p.png', dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test = x_test.reshape(-1, )\n",
    "t_test = t_test.reshape(-1, )\n",
    "relative_error = relative_error.reshape(-1,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CS = plt.tricontourf(x_test, t_test, relative_error, 20, cmap='turbo')\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(CS)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "     t.set_fontsize(20)\n",
    "\n",
    "\n",
    "plt.xlabel('x', fontsize=20)\n",
    "plt.ylabel('t', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "#plt.savefig('relative_error_timo_u.png', dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error1 = relative_error1.reshape(-1,)\n",
    "\n",
    "CS = plt.tricontourf(x_test, t_test, relative_error1, 20, cmap='turbo')\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(CS)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "     t.set_fontsize(20)\n",
    "\n",
    "\n",
    "plt.xlabel('x', fontsize=20)\n",
    "plt.ylabel('t', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "#plt.savefig('relative_error_timo_p.png', dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
