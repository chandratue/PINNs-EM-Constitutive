{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exact solution u = H\n",
    "def exact_solution_h(x, y, t):\n",
    "    return -torch.sin(x)*torch.sin(y)*torch.cos(t)\n",
    "\n",
    "def initial_condition_h(x, y):\n",
    "    return -torch.sin(x)*torch.sin(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exact solution p = E\n",
    "def exact_solution_e1(x, y, t):\n",
    "    return -torch.sin(x)*torch.sin(t)*torch.cos(y)\n",
    "\n",
    "def initial_condition_e1(x, y):\n",
    "    return 0.0*torch.sin(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exact solution p = E\n",
    "def exact_solution_e2(x, y, t):\n",
    "    return torch.sin(y)*torch.sin(t)*torch.cos(x)\n",
    "\n",
    "def initial_condition_e2(x, y):\n",
    "    return 0.0*torch.sin(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning number of points\n",
    "initial_pts = 200 \n",
    "left_boundary_pts = 200 \n",
    "right_boundary_pts = 200\n",
    "back_boundary_pts = 200\n",
    "front_boundary_pts = 200\n",
    "residual_pts = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of optimizer (ADAM or LBFGS)\n",
    "opt_type = \"LBFGS\"\n",
    "\n",
    "x_init = torch.rand((initial_pts,1)) # initial pts\n",
    "y_init = torch.rand((initial_pts,1))\n",
    "t_init =  0*x_init\n",
    "init =  torch.cat([x_init, y_init, t_init],1)\n",
    "h_init = initial_condition_h(init[:,0], init[:, 1]).reshape(-1, 1)\n",
    "e1_init = initial_condition_e1(init[:,0], init[:, 1]).reshape(-1, 1)\n",
    "e2_init = initial_condition_e2(init[:,0], init[:, 1]).reshape(-1, 1)\n",
    "w_init = torch.cat([h_init, e1_init, e2_init],1)\n",
    "\n",
    "\n",
    "xb_left = torch.zeros((left_boundary_pts, 1)) # left spatial boundary\n",
    "yb_left = torch.rand((left_boundary_pts, 1)) # left spatial boundary\n",
    "tb_left = torch.rand((left_boundary_pts, 1)) # \n",
    "b_left = torch.cat([xb_left, yb_left, tb_left ],1)\n",
    "h_b_l = exact_solution_h(xb_left, yb_left, tb_left).reshape(-1, 1)\n",
    "e1_b_l = exact_solution_e1(xb_left, yb_left, tb_left).reshape(-1, 1)\n",
    "e2_b_l = exact_solution_e2(xb_left, yb_left, tb_left).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "xb_right = torch.ones((right_boundary_pts, 1)) # right spatial boundary\n",
    "yb_right = torch.rand((right_boundary_pts, 1)) # right spatial boundary\n",
    "tb_right = torch.rand((right_boundary_pts, 1)) # right boundary pts\n",
    "b_right = torch.cat([xb_right, yb_right, tb_right ],1)\n",
    "h_b_r = exact_solution_h(xb_right, yb_right, tb_right).reshape(-1, 1)\n",
    "e1_b_r = exact_solution_e1(xb_right, yb_right, tb_right).reshape(-1, 1)\n",
    "e2_b_r = exact_solution_e2(xb_right, yb_right, tb_right).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "xb_front = torch.rand((front_boundary_pts, 1)) # front spatial boundary\n",
    "yb_front = torch.zeros((front_boundary_pts, 1)) # front spatial boundary\n",
    "tb_front = torch.rand((front_boundary_pts, 1)) # \n",
    "b_front = torch.cat([xb_front, yb_front, tb_front ],1)\n",
    "h_b_f = exact_solution_h(xb_front, yb_front, tb_front).reshape(-1, 1)\n",
    "e1_b_f = exact_solution_e1(xb_front, yb_front, tb_front).reshape(-1, 1)\n",
    "e2_b_f = exact_solution_e2(xb_front, yb_front, tb_front).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "xb_back = torch.rand((back_boundary_pts, 1)) # back spatial boundary\n",
    "yb_back = torch.ones((back_boundary_pts, 1)) # back spatial boundary\n",
    "tb_back = torch.rand((back_boundary_pts, 1)) # back boundary pts\n",
    "b_back = torch.cat([xb_back, yb_back, tb_back ],1)\n",
    "h_b_b = exact_solution_h(xb_back, yb_back, tb_back).reshape(-1, 1)\n",
    "e1_b_b = exact_solution_e1(xb_back, yb_back, tb_back).reshape(-1, 1)\n",
    "e2_b_b = exact_solution_e2(xb_back, yb_back, tb_back).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "x_interior = torch.rand((residual_pts, 1))\n",
    "y_interior = torch.rand((residual_pts, 1))\n",
    "t_interior = torch.rand((residual_pts, 1))\n",
    "interior = torch.cat([x_interior, y_interior, t_interior],1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_set = DataLoader(torch.utils.data.TensorDataset(init, w_init, b_left,  b_right, b_front, b_back), batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension, output_dimension, n_hidden_layers, neurons):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # Number of input dimensions n\n",
    "        self.input_dimension = input_dimension\n",
    "        # Number of output dimensions m\n",
    "        self.output_dimension = output_dimension\n",
    "        # Number of neurons per layer \n",
    "        self.neurons = neurons\n",
    "        # Number of hidden layers \n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        # Activation function \n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        self.input_layer = nn.Linear(self.input_dimension, self.neurons)\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(self.neurons, self.neurons) for _ in range(n_hidden_layers)])\n",
    "        self.output_layer = nn.Linear(self.neurons, self.output_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward function performs the set of affine and non-linear transformations defining the network \n",
    "        # (see equation above)\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        for k, l in enumerate(self.hidden_layers):\n",
    "            x = self.activation(l(x))\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "my_network = NeuralNet(input_dimension = init.shape[1], output_dimension = w_init.shape[1], n_hidden_layers=4, neurons=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_xavier(model, retrain_seed):\n",
    "    torch.manual_seed(retrain_seed)\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear and m.weight.requires_grad and m.bias.requires_grad:\n",
    "            g = nn.init.calculate_gain('tanh')\n",
    "            torch.nn.init.xavier_uniform_(m.weight, gain=g)\n",
    "            #torch.nn.init.xavier_normal_(m.weight, gain=g)\n",
    "            m.bias.data.fill_(0)\n",
    "    model.apply(init_weights)\n",
    "\n",
    "# Random Seed for weight initialization\n",
    "retrain = 128\n",
    "# Xavier weight initialization\n",
    "init_xavier(my_network, retrain)\n",
    "#print(my_network(init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt_type == \"ADAM\":\n",
    "    optimizer_ = optim.Adam(my_network.parameters(), lr=0.001)\n",
    "elif opt_type == \"LBFGS\":\n",
    "    optimizer_ = optim.LBFGS(my_network.parameters(), lr=0.1, max_iter=1, max_eval=50000, tolerance_change=1.0 * np.finfo(float).eps)\n",
    "else:\n",
    "    raise ValueError(\"Optimizer not recognized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, training_set, interior, num_epochs, optimizer, p, verbose=True):\n",
    "    history = list()\n",
    "    \n",
    "    # Loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose: print(\"################################ \", epoch, \" ################################\")\n",
    "\n",
    "        running_loss = list([0])\n",
    "        \n",
    "        # Loop over batches\n",
    "        for j, (initial, w_initial, bd_left,  bd_right, bd_front, bd_back) in enumerate(training_set):\n",
    "            \n",
    "            def closure():\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # for initial\n",
    "                initial.requires_grad = True\n",
    "                w_initial_pred_ = model(initial)\n",
    "                h_initial_pred_ = w_initial_pred_[:,0].reshape(-1,1)\n",
    "                e1_initial_pred_ = w_initial_pred_[:,1].reshape(-1,1)\n",
    "                e2_initial_pred_ = w_initial_pred_[:,2].reshape(-1,1)\n",
    "                \n",
    "                \n",
    "                # with derivative\n",
    "                inpu = torch.ones(initial_pts, 1 )\n",
    "                \n",
    "                grad_h_ini = torch.autograd.grad(h_initial_pred_, initial, grad_outputs=inpu, create_graph=True, allow_unused=True)[0]\n",
    "                h_initial_t = grad_h_ini[:, 2]\n",
    "                \n",
    "                grad_e1_ini = torch.autograd.grad(e1_initial_pred_, initial, grad_outputs=inpu, create_graph=True, allow_unused=True)[0]\n",
    "                e1_initial_t = grad_e1_ini[:, 2]\n",
    "                \n",
    "                grad_e2_ini = torch.autograd.grad(e2_initial_pred_, initial, grad_outputs=inpu, create_graph=True, allow_unused=True)[0]\n",
    "                e2_initial_t = grad_e2_ini[:, 2]\n",
    "                \n",
    "                \n",
    "                \n",
    "                # for left boundary\n",
    "                w_bd_left_pred_ = model(bd_left)\n",
    "                h_bd_left_pred_ = w_bd_left_pred_[:,0].reshape(-1,1)\n",
    "                e1_bd_left_pred_ = w_bd_left_pred_[:,1].reshape(-1,1)\n",
    "                e2_bd_left_pred_ = w_bd_left_pred_[:,2].reshape(-1,1)\n",
    "                \n",
    "                # for right boundary\n",
    "                w_bd_right_pred_ = model(bd_right)\n",
    "                h_bd_right_pred_ = w_bd_right_pred_[:,0].reshape(-1,1)\n",
    "                e1_bd_right_pred_ = w_bd_right_pred_[:,1].reshape(-1,1)\n",
    "                e2_bd_right_pred_ = w_bd_right_pred_[:,2].reshape(-1,1)\n",
    "                \n",
    "                # for front boundary\n",
    "                w_bd_front_pred_ = model(bd_front)\n",
    "                h_bd_front_pred_ = w_bd_front_pred_[:,0].reshape(-1,1)\n",
    "                e1_bd_front_pred_ = w_bd_front_pred_[:,1].reshape(-1,1)\n",
    "                e2_bd_front_pred_ = w_bd_front_pred_[:,2].reshape(-1,1)\n",
    "                \n",
    "                # for back boundary\n",
    "                w_bd_back_pred_ = model(bd_back)\n",
    "                h_bd_back_pred_ = w_bd_back_pred_[:,0].reshape(-1,1)\n",
    "                e1_bd_back_pred_ = w_bd_back_pred_[:,1].reshape(-1,1)\n",
    "                e2_bd_back_pred_ = w_bd_back_pred_[:,2].reshape(-1,1)\n",
    "                \n",
    "                # residual calculation\n",
    "                interior.requires_grad = True\n",
    "                w_hat = model(interior)\n",
    "                h_hat = w_hat[:,0].reshape(-1,1)\n",
    "                e1_hat = w_hat[:,1].reshape(-1,1)\n",
    "                e2_hat = w_hat[:,2].reshape(-1,1)\n",
    "                \n",
    "                inputs = torch.ones(residual_pts, 1 )\n",
    "                inputs2 = torch.ones(residual_pts, 1)\n",
    "                \n",
    "                grad_h_hat = torch.autograd.grad(h_hat.reshape(-1,1), interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                h_x = grad_h_hat[:, 0].reshape(-1,1)\n",
    "                h_y = grad_h_hat[:, 1].reshape(-1,1)\n",
    "                \n",
    "                grad_e1_hat = torch.autograd.grad(e1_hat, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                e1_x = grad_e1_hat[:, 0].reshape(-1,1)\n",
    "                e1_y = grad_e1_hat[:, 1].reshape(-1,1)\n",
    "                \n",
    "                grad_e2_hat = torch.autograd.grad(e2_hat, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                e2_x = grad_e2_hat[:, 0].reshape(-1,1)\n",
    "                e2_y = grad_e2_hat[:, 1].reshape(-1,1)\n",
    "                \n",
    "                h_t = grad_h_hat[:, 2].reshape(-1,1)\n",
    "                e1_t = grad_e1_hat[:, 2].reshape(-1,1)\n",
    "                e2_t = grad_e2_hat[:, 2].reshape(-1,1)\n",
    "                \n",
    "                \n",
    "                # Item 1. below\n",
    "                loss1 = torch.mean((h_initial_pred_.reshape(-1, ) - w_initial[:,0].reshape(-1, ))**p) + torch.mean((2*h_t.reshape(-1, ) + e2_x.reshape(-1, ) - e1_y.reshape(-1, ))**p)+torch.mean((h_bd_left_pred_.reshape(-1,)- h_b_l.reshape(-1,))**p) + torch.mean((h_bd_right_pred_.reshape(-1,)- h_b_r.reshape(-1,))**p) +torch.mean((h_bd_front_pred_.reshape(-1,)- h_b_f.reshape(-1,))**p) + torch.mean((h_bd_back_pred_.reshape(-1,)- h_b_b.reshape(-1,))**p)\n",
    "                loss2 = torch.mean((e1_initial_pred_.reshape(-1, ) - w_initial[:,1].reshape(-1, ))**p)+ torch.mean((4*e1_t.reshape(-1, ) + 2*e2_t.reshape(-1, ) - h_y.reshape(-1, ) + 3*torch.sin(interior[:, 0])*torch.cos(interior[:, 2])*torch.cos(interior[:, 1]) - 2*torch.cos(interior[:, 0])*torch.cos(interior[:, 2])*torch.sin(interior[:, 1]) )**p) +torch.mean((e1_bd_left_pred_.reshape(-1,)- e1_b_l.reshape(-1,))**p) + torch.mean((e1_bd_right_pred_.reshape(-1,)- e1_b_r.reshape(-1,))**p) +torch.mean((e1_bd_front_pred_.reshape(-1,)- e1_b_f.reshape(-1,))**p) + torch.mean((e1_bd_back_pred_.reshape(-1,)- e1_b_b.reshape(-1,))**p)\n",
    "                loss3 = torch.mean((e2_initial_pred_.reshape(-1, ) - w_initial[:,2].reshape(-1, ))**p)+ torch.mean((2*e1_t.reshape(-1, ) + e2_t.reshape(-1, )  + h_x.reshape(-1, ) + 2*torch.sin(interior[:, 0])*torch.cos(interior[:, 2])*torch.cos(interior[:, 1]))**p) +torch.mean((e2_bd_left_pred_.reshape(-1,)- e2_b_l.reshape(-1,))**p) + torch.mean((e2_bd_right_pred_.reshape(-1,)- e2_b_r.reshape(-1,))**p) +torch.mean((e2_bd_front_pred_.reshape(-1,)- e2_b_f.reshape(-1,))**p) + torch.mean((e2_bd_back_pred_.reshape(-1,)- e2_b_b.reshape(-1,))**p)\n",
    "                loss = loss1 + loss2 + loss3\n",
    "                \n",
    "                # Item 2. below\n",
    "                loss.backward()\n",
    "                # Compute average training loss over batches for the current epoch\n",
    "                running_loss[0] += loss.item()\n",
    "                return loss\n",
    "            \n",
    "            # Item 3. below\n",
    "            optimizer.step(closure=closure)\n",
    "            \n",
    "        print('Loss: ', (running_loss[0] / len(training_set)))\n",
    "        history.append(running_loss[0])\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################  0  ################################\n",
      "Loss:  195.86463928222656\n",
      "################################  1  ################################\n",
      "Loss:  191.5936737060547\n",
      "################################  2  ################################\n",
      "Loss:  163.11566162109375\n",
      "################################  3  ################################\n",
      "Loss:  132.72230529785156\n",
      "################################  4  ################################\n",
      "Loss:  101.83101654052734\n",
      "################################  5  ################################\n",
      "Loss:  77.85144805908203\n",
      "################################  6  ################################\n",
      "Loss:  64.0369873046875\n",
      "################################  7  ################################\n",
      "Loss:  55.33611297607422\n",
      "################################  8  ################################\n",
      "Loss:  48.68509292602539\n",
      "################################  9  ################################\n",
      "Loss:  43.05506134033203\n",
      "################################  10  ################################\n",
      "Loss:  38.054054260253906\n",
      "################################  11  ################################\n",
      "Loss:  33.52473068237305\n",
      "################################  12  ################################\n",
      "Loss:  29.428659439086914\n",
      "################################  13  ################################\n",
      "Loss:  25.775779724121094\n",
      "################################  14  ################################\n",
      "Loss:  22.56867218017578\n",
      "################################  15  ################################\n",
      "Loss:  19.778093338012695\n",
      "################################  16  ################################\n",
      "Loss:  17.351215362548828\n",
      "################################  17  ################################\n",
      "Loss:  15.230059623718262\n",
      "################################  18  ################################\n",
      "Loss:  13.363533973693848\n",
      "################################  19  ################################\n",
      "Loss:  11.711226463317871\n",
      "################################  20  ################################\n",
      "Loss:  10.24282455444336\n",
      "################################  21  ################################\n",
      "Loss:  8.93587589263916\n",
      "################################  22  ################################\n",
      "Loss:  7.77347469329834\n",
      "################################  23  ################################\n",
      "Loss:  6.742465496063232\n",
      "################################  24  ################################\n",
      "Loss:  5.8324174880981445\n",
      "################################  25  ################################\n",
      "Loss:  5.034616470336914\n",
      "################################  26  ################################\n",
      "Loss:  4.340536594390869\n",
      "################################  27  ################################\n",
      "Loss:  3.7406301498413086\n",
      "################################  28  ################################\n",
      "Loss:  3.224785089492798\n",
      "################################  29  ################################\n",
      "Loss:  2.783301591873169\n",
      "################################  30  ################################\n",
      "Loss:  2.40714168548584\n",
      "################################  31  ################################\n",
      "Loss:  2.0879640579223633\n",
      "################################  32  ################################\n",
      "Loss:  1.8181579113006592\n",
      "################################  33  ################################\n",
      "Loss:  1.5908544063568115\n",
      "################################  34  ################################\n",
      "Loss:  1.3992950916290283\n",
      "################################  35  ################################\n",
      "Loss:  1.2351716756820679\n",
      "################################  36  ################################\n",
      "Loss:  1.0669149160385132\n",
      "################################  37  ################################\n",
      "Loss:  0.9627572298049927\n",
      "################################  38  ################################\n",
      "Loss:  0.8763123750686646\n",
      "################################  39  ################################\n",
      "Loss:  0.7964804172515869\n",
      "################################  40  ################################\n",
      "Loss:  0.7218550443649292\n",
      "################################  41  ################################\n",
      "Loss:  0.6535872220993042\n",
      "################################  42  ################################\n",
      "Loss:  0.5983858108520508\n",
      "################################  43  ################################\n",
      "Loss:  0.5487387180328369\n",
      "################################  44  ################################\n",
      "Loss:  0.5044536590576172\n",
      "################################  45  ################################\n",
      "Loss:  0.46583062410354614\n",
      "################################  46  ################################\n",
      "Loss:  0.42642080783843994\n",
      "################################  47  ################################\n",
      "Loss:  0.3921787738800049\n",
      "################################  48  ################################\n",
      "Loss:  0.3634016513824463\n",
      "################################  49  ################################\n",
      "Loss:  0.33690959215164185\n",
      "################################  50  ################################\n",
      "Loss:  0.3142775297164917\n",
      "################################  51  ################################\n",
      "Loss:  0.2931436002254486\n",
      "################################  52  ################################\n",
      "Loss:  0.27285581827163696\n",
      "################################  53  ################################\n",
      "Loss:  0.25414177775382996\n",
      "################################  54  ################################\n",
      "Loss:  0.2336704432964325\n",
      "################################  55  ################################\n",
      "Loss:  0.21543915569782257\n",
      "################################  56  ################################\n",
      "Loss:  0.197677880525589\n",
      "################################  57  ################################\n",
      "Loss:  0.1817742884159088\n",
      "################################  58  ################################\n",
      "Loss:  0.1688682734966278\n",
      "################################  59  ################################\n",
      "Loss:  0.15588587522506714\n",
      "################################  60  ################################\n",
      "Loss:  0.14526765048503876\n",
      "################################  61  ################################\n",
      "Loss:  0.1353054940700531\n",
      "################################  62  ################################\n",
      "Loss:  0.12701547145843506\n",
      "################################  63  ################################\n",
      "Loss:  0.11861826479434967\n",
      "################################  64  ################################\n",
      "Loss:  0.1097135990858078\n",
      "################################  65  ################################\n",
      "Loss:  0.10095985233783722\n",
      "################################  66  ################################\n",
      "Loss:  0.09429415315389633\n",
      "################################  67  ################################\n",
      "Loss:  0.08876703679561615\n",
      "################################  68  ################################\n",
      "Loss:  0.08354513347148895\n",
      "################################  69  ################################\n",
      "Loss:  0.07940717041492462\n",
      "################################  70  ################################\n",
      "Loss:  0.07521024346351624\n",
      "################################  71  ################################\n",
      "Loss:  0.07154729962348938\n",
      "################################  72  ################################\n",
      "Loss:  0.06834225356578827\n",
      "################################  73  ################################\n",
      "Loss:  0.06536935269832611\n",
      "################################  74  ################################\n",
      "Loss:  0.06273926794528961\n",
      "################################  75  ################################\n",
      "Loss:  0.06025242432951927\n",
      "################################  76  ################################\n",
      "Loss:  0.05795909836888313\n",
      "################################  77  ################################\n",
      "Loss:  0.05574537813663483\n",
      "################################  78  ################################\n",
      "Loss:  0.05363379418849945\n",
      "################################  79  ################################\n",
      "Loss:  0.051541246473789215\n",
      "################################  80  ################################\n",
      "Loss:  0.04949554055929184\n",
      "################################  81  ################################\n",
      "Loss:  0.04743581265211105\n",
      "################################  82  ################################\n",
      "Loss:  0.045377399772405624\n",
      "################################  83  ################################\n",
      "Loss:  0.04332087188959122\n",
      "################################  84  ################################\n",
      "Loss:  0.041270602494478226\n",
      "################################  85  ################################\n",
      "Loss:  0.03942718356847763\n",
      "################################  86  ################################\n",
      "Loss:  0.03765732795000076\n",
      "################################  87  ################################\n",
      "Loss:  0.03596240282058716\n",
      "################################  88  ################################\n",
      "Loss:  0.03436250984668732\n",
      "################################  89  ################################\n",
      "Loss:  0.0328187420964241\n",
      "################################  90  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0313430055975914\n",
      "################################  91  ################################\n",
      "Loss:  0.029931198805570602\n",
      "################################  92  ################################\n",
      "Loss:  0.028557434678077698\n",
      "################################  93  ################################\n",
      "Loss:  0.027216553688049316\n",
      "################################  94  ################################\n",
      "Loss:  0.02599407359957695\n",
      "################################  95  ################################\n",
      "Loss:  0.024950657039880753\n",
      "################################  96  ################################\n",
      "Loss:  0.023984018713235855\n",
      "################################  97  ################################\n",
      "Loss:  0.02308110147714615\n",
      "################################  98  ################################\n",
      "Loss:  0.02223317325115204\n",
      "################################  99  ################################\n",
      "Loss:  0.021444186568260193\n",
      "################################  100  ################################\n",
      "Loss:  0.02070486918091774\n",
      "################################  101  ################################\n",
      "Loss:  0.020015748217701912\n",
      "################################  102  ################################\n",
      "Loss:  0.01936788484454155\n",
      "################################  103  ################################\n",
      "Loss:  0.018757199868559837\n",
      "################################  104  ################################\n",
      "Loss:  0.018184728920459747\n",
      "################################  105  ################################\n",
      "Loss:  0.017657002434134483\n",
      "################################  106  ################################\n",
      "Loss:  0.017170945182442665\n",
      "################################  107  ################################\n",
      "Loss:  0.016715597361326218\n",
      "################################  108  ################################\n",
      "Loss:  0.01628834381699562\n",
      "################################  109  ################################\n",
      "Loss:  0.01587718166410923\n",
      "################################  110  ################################\n",
      "Loss:  0.01548176258802414\n",
      "################################  111  ################################\n",
      "Loss:  0.015093185007572174\n",
      "################################  112  ################################\n",
      "Loss:  0.014743724837899208\n",
      "################################  113  ################################\n",
      "Loss:  0.014411630108952522\n",
      "################################  114  ################################\n",
      "Loss:  0.01409422792494297\n",
      "################################  115  ################################\n",
      "Loss:  0.013788687065243721\n",
      "################################  116  ################################\n",
      "Loss:  0.013492947444319725\n",
      "################################  117  ################################\n",
      "Loss:  0.013206563889980316\n",
      "################################  118  ################################\n",
      "Loss:  0.012928406707942486\n",
      "################################  119  ################################\n",
      "Loss:  0.012657186016440392\n",
      "################################  120  ################################\n",
      "Loss:  0.01239271741360426\n",
      "################################  121  ################################\n",
      "Loss:  0.012133382260799408\n",
      "################################  122  ################################\n",
      "Loss:  0.011879431083798409\n",
      "################################  123  ################################\n",
      "Loss:  0.01162896491587162\n",
      "################################  124  ################################\n",
      "Loss:  0.011382725089788437\n",
      "################################  125  ################################\n",
      "Loss:  0.011138337664306164\n",
      "################################  126  ################################\n",
      "Loss:  0.010900191031396389\n",
      "################################  127  ################################\n",
      "Loss:  0.010670101270079613\n",
      "################################  128  ################################\n",
      "Loss:  0.010451201349496841\n",
      "################################  129  ################################\n",
      "Loss:  0.01024041697382927\n",
      "################################  130  ################################\n",
      "Loss:  0.010035926476120949\n",
      "################################  131  ################################\n",
      "Loss:  0.009835093282163143\n",
      "################################  132  ################################\n",
      "Loss:  0.009638629853725433\n",
      "################################  133  ################################\n",
      "Loss:  0.009444516152143478\n",
      "################################  134  ################################\n",
      "Loss:  0.009258057922124863\n",
      "################################  135  ################################\n",
      "Loss:  0.009073611348867416\n",
      "################################  136  ################################\n",
      "Loss:  0.008894222788512707\n",
      "################################  137  ################################\n",
      "Loss:  0.008715064264833927\n",
      "################################  138  ################################\n",
      "Loss:  0.00853374507278204\n",
      "################################  139  ################################\n",
      "Loss:  0.008357259444892406\n",
      "################################  140  ################################\n",
      "Loss:  0.008180612698197365\n",
      "################################  141  ################################\n",
      "Loss:  0.008012275211513042\n",
      "################################  142  ################################\n",
      "Loss:  0.007846045307815075\n",
      "################################  143  ################################\n",
      "Loss:  0.007686411030590534\n",
      "################################  144  ################################\n",
      "Loss:  0.007528737187385559\n",
      "################################  145  ################################\n",
      "Loss:  0.0073736743070185184\n",
      "################################  146  ################################\n",
      "Loss:  0.007220604456961155\n",
      "################################  147  ################################\n",
      "Loss:  0.007070479914546013\n",
      "################################  148  ################################\n",
      "Loss:  0.006924507673829794\n",
      "################################  149  ################################\n",
      "Loss:  0.006778058595955372\n",
      "################################  150  ################################\n",
      "Loss:  0.0066366493701934814\n",
      "################################  151  ################################\n",
      "Loss:  0.006501915864646435\n",
      "################################  152  ################################\n",
      "Loss:  0.00638015940785408\n",
      "################################  153  ################################\n",
      "Loss:  0.006262660026550293\n",
      "################################  154  ################################\n",
      "Loss:  0.006152783520519733\n",
      "################################  155  ################################\n",
      "Loss:  0.006045571994036436\n",
      "################################  156  ################################\n",
      "Loss:  0.0059444112703204155\n",
      "################################  157  ################################\n",
      "Loss:  0.005847553722560406\n",
      "################################  158  ################################\n",
      "Loss:  0.005755398888140917\n",
      "################################  159  ################################\n",
      "Loss:  0.0056693400256335735\n",
      "################################  160  ################################\n",
      "Loss:  0.005585069768130779\n",
      "################################  161  ################################\n",
      "Loss:  0.005505891051143408\n",
      "################################  162  ################################\n",
      "Loss:  0.005429037846624851\n",
      "################################  163  ################################\n",
      "Loss:  0.005356230773031712\n",
      "################################  164  ################################\n",
      "Loss:  0.0052847303450107574\n",
      "################################  165  ################################\n",
      "Loss:  0.005216835532337427\n",
      "################################  166  ################################\n",
      "Loss:  0.005150157492607832\n",
      "################################  167  ################################\n",
      "Loss:  0.005086600314825773\n",
      "################################  168  ################################\n",
      "Loss:  0.005027522332966328\n",
      "################################  169  ################################\n",
      "Loss:  0.004972171038389206\n",
      "################################  170  ################################\n",
      "Loss:  0.004922529682517052\n",
      "################################  171  ################################\n",
      "Loss:  0.0048728035762906075\n",
      "################################  172  ################################\n",
      "Loss:  0.004828048869967461\n",
      "################################  173  ################################\n",
      "Loss:  0.004784412682056427\n",
      "################################  174  ################################\n",
      "Loss:  0.004741004668176174\n",
      "################################  175  ################################\n",
      "Loss:  0.004699345212429762\n",
      "################################  176  ################################\n",
      "Loss:  0.0046565840020775795\n",
      "################################  177  ################################\n",
      "Loss:  0.004615586716681719\n",
      "################################  178  ################################\n",
      "Loss:  0.0045736972242593765\n",
      "################################  179  ################################\n",
      "Loss:  0.004533172585070133\n",
      "################################  180  ################################\n",
      "Loss:  0.00449221208691597\n",
      "################################  181  ################################\n",
      "Loss:  0.004450136795639992\n",
      "################################  182  ################################\n",
      "Loss:  0.004406447522342205\n",
      "################################  183  ################################\n",
      "Loss:  0.0043610939756035805\n",
      "################################  184  ################################\n",
      "Loss:  0.004314403515309095\n",
      "################################  185  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.004266258329153061\n",
      "################################  186  ################################\n",
      "Loss:  0.004219978116452694\n",
      "################################  187  ################################\n",
      "Loss:  0.004174933768808842\n",
      "################################  188  ################################\n",
      "Loss:  0.004131980240345001\n",
      "################################  189  ################################\n",
      "Loss:  0.004088263027369976\n",
      "################################  190  ################################\n",
      "Loss:  0.00404370715841651\n",
      "################################  191  ################################\n",
      "Loss:  0.0039980122819542885\n",
      "################################  192  ################################\n",
      "Loss:  0.003949239384382963\n",
      "################################  193  ################################\n",
      "Loss:  0.0039041421841830015\n",
      "################################  194  ################################\n",
      "Loss:  0.003857884556055069\n",
      "################################  195  ################################\n",
      "Loss:  0.0038141245022416115\n",
      "################################  196  ################################\n",
      "Loss:  0.0037697721272706985\n",
      "################################  197  ################################\n",
      "Loss:  0.0037226579152047634\n",
      "################################  198  ################################\n",
      "Loss:  0.0036743623204529285\n",
      "################################  199  ################################\n",
      "Loss:  0.0036288155242800713\n",
      "################################  200  ################################\n",
      "Loss:  0.0035855122841894627\n",
      "################################  201  ################################\n",
      "Loss:  0.003540400182828307\n",
      "################################  202  ################################\n",
      "Loss:  0.00349517073482275\n",
      "################################  203  ################################\n",
      "Loss:  0.0034482863266021013\n",
      "################################  204  ################################\n",
      "Loss:  0.0034003094770014286\n",
      "################################  205  ################################\n",
      "Loss:  0.0033498164266347885\n",
      "################################  206  ################################\n",
      "Loss:  0.0032990779727697372\n",
      "################################  207  ################################\n",
      "Loss:  0.003245687112212181\n",
      "################################  208  ################################\n",
      "Loss:  0.0031978373881429434\n",
      "################################  209  ################################\n",
      "Loss:  0.003149238182231784\n",
      "################################  210  ################################\n",
      "Loss:  0.0031013728585094213\n",
      "################################  211  ################################\n",
      "Loss:  0.003056187182664871\n",
      "################################  212  ################################\n",
      "Loss:  0.0030102706514298916\n",
      "################################  213  ################################\n",
      "Loss:  0.0029692882671952248\n",
      "################################  214  ################################\n",
      "Loss:  0.002928981091827154\n",
      "################################  215  ################################\n",
      "Loss:  0.0028892774134874344\n",
      "################################  216  ################################\n",
      "Loss:  0.002850406803190708\n",
      "################################  217  ################################\n",
      "Loss:  0.0028144968673586845\n",
      "################################  218  ################################\n",
      "Loss:  0.0027805310674011707\n",
      "################################  219  ################################\n",
      "Loss:  0.0027488572522997856\n",
      "################################  220  ################################\n",
      "Loss:  0.002719240728765726\n",
      "################################  221  ################################\n",
      "Loss:  0.002691777888685465\n",
      "################################  222  ################################\n",
      "Loss:  0.002666119020432234\n",
      "################################  223  ################################\n",
      "Loss:  0.0026417875196784735\n",
      "################################  224  ################################\n",
      "Loss:  0.0026185570750385523\n",
      "################################  225  ################################\n",
      "Loss:  0.002596509177237749\n",
      "################################  226  ################################\n",
      "Loss:  0.0025751939974725246\n",
      "################################  227  ################################\n",
      "Loss:  0.0025544208474457264\n",
      "################################  228  ################################\n",
      "Loss:  0.002534019760787487\n",
      "################################  229  ################################\n",
      "Loss:  0.0025148093700408936\n",
      "################################  230  ################################\n",
      "Loss:  0.002496100030839443\n",
      "################################  231  ################################\n",
      "Loss:  0.00247741024941206\n",
      "################################  232  ################################\n",
      "Loss:  0.0024587768130004406\n",
      "################################  233  ################################\n",
      "Loss:  0.0024403338320553303\n",
      "################################  234  ################################\n",
      "Loss:  0.0024198228493332863\n",
      "################################  235  ################################\n",
      "Loss:  0.0024012885987758636\n",
      "################################  236  ################################\n",
      "Loss:  0.0023816991597414017\n",
      "################################  237  ################################\n",
      "Loss:  0.0023604566231369972\n",
      "################################  238  ################################\n",
      "Loss:  0.0023377290926873684\n",
      "################################  239  ################################\n",
      "Loss:  0.002314419485628605\n",
      "################################  240  ################################\n",
      "Loss:  0.0022917434107512236\n",
      "################################  241  ################################\n",
      "Loss:  0.0022691141348332167\n",
      "################################  242  ################################\n",
      "Loss:  0.0022468576207756996\n",
      "################################  243  ################################\n",
      "Loss:  0.0022228979505598545\n",
      "################################  244  ################################\n",
      "Loss:  0.0021989638917148113\n",
      "################################  245  ################################\n",
      "Loss:  0.0021732444874942303\n",
      "################################  246  ################################\n",
      "Loss:  0.002148302271962166\n",
      "################################  247  ################################\n",
      "Loss:  0.002116559771820903\n",
      "################################  248  ################################\n",
      "Loss:  0.0020895833149552345\n",
      "################################  249  ################################\n",
      "Loss:  0.002055652905255556\n",
      "################################  250  ################################\n",
      "Loss:  0.0020288494415581226\n",
      "################################  251  ################################\n",
      "Loss:  0.001999447587877512\n",
      "################################  252  ################################\n",
      "Loss:  0.0019701002165675163\n",
      "################################  253  ################################\n",
      "Loss:  0.001940956455655396\n",
      "################################  254  ################################\n",
      "Loss:  0.0019121463410556316\n",
      "################################  255  ################################\n",
      "Loss:  0.0018851356580853462\n",
      "################################  256  ################################\n",
      "Loss:  0.0018604982178658247\n",
      "################################  257  ################################\n",
      "Loss:  0.0018370820907875896\n",
      "################################  258  ################################\n",
      "Loss:  0.0018149050883948803\n",
      "################################  259  ################################\n",
      "Loss:  0.001794905518181622\n",
      "################################  260  ################################\n",
      "Loss:  0.0017768144607543945\n",
      "################################  261  ################################\n",
      "Loss:  0.0017602918669581413\n",
      "################################  262  ################################\n",
      "Loss:  0.0017455806955695152\n",
      "################################  263  ################################\n",
      "Loss:  0.001732019940391183\n",
      "################################  264  ################################\n",
      "Loss:  0.0017201895825564861\n",
      "################################  265  ################################\n",
      "Loss:  0.001709435717202723\n",
      "################################  266  ################################\n",
      "Loss:  0.001699789660051465\n",
      "################################  267  ################################\n",
      "Loss:  0.0016908081015571952\n",
      "################################  268  ################################\n",
      "Loss:  0.001682348782196641\n",
      "################################  269  ################################\n",
      "Loss:  0.001674289465881884\n",
      "################################  270  ################################\n",
      "Loss:  0.0016665103612467647\n",
      "################################  271  ################################\n",
      "Loss:  0.001659024623222649\n",
      "################################  272  ################################\n",
      "Loss:  0.0016514736926183105\n",
      "################################  273  ################################\n",
      "Loss:  0.0016441841144114733\n",
      "################################  274  ################################\n",
      "Loss:  0.0016362497117370367\n",
      "################################  275  ################################\n",
      "Loss:  0.0016282524447888136\n",
      "################################  276  ################################\n",
      "Loss:  0.0016186865977942944\n",
      "################################  277  ################################\n",
      "Loss:  0.0016092185396701097\n",
      "################################  278  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0015979743329808116\n",
      "################################  279  ################################\n",
      "Loss:  0.0015862404834479094\n",
      "################################  280  ################################\n",
      "Loss:  0.001574201276525855\n",
      "################################  281  ################################\n",
      "Loss:  0.0015599408652633429\n",
      "################################  282  ################################\n",
      "Loss:  0.0015477745328098536\n",
      "################################  283  ################################\n",
      "Loss:  0.0015345190186053514\n",
      "################################  284  ################################\n",
      "Loss:  0.0015180762857198715\n",
      "################################  285  ################################\n",
      "Loss:  0.0015049793291836977\n",
      "################################  286  ################################\n",
      "Loss:  0.0014904967974871397\n",
      "################################  287  ################################\n",
      "Loss:  0.0014758927281945944\n",
      "################################  288  ################################\n",
      "Loss:  0.0014619121793657541\n",
      "################################  289  ################################\n",
      "Loss:  0.0014486592262983322\n",
      "################################  290  ################################\n",
      "Loss:  0.0014356138417497277\n",
      "################################  291  ################################\n",
      "Loss:  0.0014227256178855896\n",
      "################################  292  ################################\n",
      "Loss:  0.0014112633652985096\n",
      "################################  293  ################################\n",
      "Loss:  0.00140086910687387\n",
      "################################  294  ################################\n",
      "Loss:  0.0013915111776441336\n",
      "################################  295  ################################\n",
      "Loss:  0.001382925664074719\n",
      "################################  296  ################################\n",
      "Loss:  0.0013749628560617566\n",
      "################################  297  ################################\n",
      "Loss:  0.0013673061039298773\n",
      "################################  298  ################################\n",
      "Loss:  0.0013598529621958733\n",
      "################################  299  ################################\n",
      "Loss:  0.0013528831768780947\n",
      "################################  300  ################################\n",
      "Loss:  0.0013463611248880625\n",
      "################################  301  ################################\n",
      "Loss:  0.0013404294149950147\n",
      "################################  302  ################################\n",
      "Loss:  0.001334667787887156\n",
      "################################  303  ################################\n",
      "Loss:  0.0013291098875924945\n",
      "################################  304  ################################\n",
      "Loss:  0.001323607750236988\n",
      "################################  305  ################################\n",
      "Loss:  0.00131813099142164\n",
      "################################  306  ################################\n",
      "Loss:  0.0013124947436153889\n",
      "################################  307  ################################\n",
      "Loss:  0.0013071757275611162\n",
      "################################  308  ################################\n",
      "Loss:  0.0013021016493439674\n",
      "################################  309  ################################\n",
      "Loss:  0.0012970085954293609\n",
      "################################  310  ################################\n",
      "Loss:  0.0012920927256345749\n",
      "################################  311  ################################\n",
      "Loss:  0.0012870881473645568\n",
      "################################  312  ################################\n",
      "Loss:  0.0012821444543078542\n",
      "################################  313  ################################\n",
      "Loss:  0.0012770796893164515\n",
      "################################  314  ################################\n",
      "Loss:  0.0012720976956188679\n",
      "################################  315  ################################\n",
      "Loss:  0.001267135376110673\n",
      "################################  316  ################################\n",
      "Loss:  0.0012621572241187096\n",
      "################################  317  ################################\n",
      "Loss:  0.0012572965351864696\n",
      "################################  318  ################################\n",
      "Loss:  0.0012523173354566097\n",
      "################################  319  ################################\n",
      "Loss:  0.0012475030962377787\n",
      "################################  320  ################################\n",
      "Loss:  0.001242564176209271\n",
      "################################  321  ################################\n",
      "Loss:  0.0012377090752124786\n",
      "################################  322  ################################\n",
      "Loss:  0.001232801005244255\n",
      "################################  323  ################################\n",
      "Loss:  0.0012278561480343342\n",
      "################################  324  ################################\n",
      "Loss:  0.0012229476124048233\n",
      "################################  325  ################################\n",
      "Loss:  0.0012180173071101308\n",
      "################################  326  ################################\n",
      "Loss:  0.0012131346156820655\n",
      "################################  327  ################################\n",
      "Loss:  0.0012082497123628855\n",
      "################################  328  ################################\n",
      "Loss:  0.0012034219689667225\n",
      "################################  329  ################################\n",
      "Loss:  0.001199035905301571\n",
      "################################  330  ################################\n",
      "Loss:  0.0011949311010539532\n",
      "################################  331  ################################\n",
      "Loss:  0.0011909373570233583\n",
      "################################  332  ################################\n",
      "Loss:  0.0011867695720866323\n",
      "################################  333  ################################\n",
      "Loss:  0.0011825818801298738\n",
      "################################  334  ################################\n",
      "Loss:  0.00117836007848382\n",
      "################################  335  ################################\n",
      "Loss:  0.00117403082549572\n",
      "################################  336  ################################\n",
      "Loss:  0.0011690983083099127\n",
      "################################  337  ################################\n",
      "Loss:  0.0011651646345853806\n",
      "################################  338  ################################\n",
      "Loss:  0.0011608661152422428\n",
      "################################  339  ################################\n",
      "Loss:  0.0011569064809009433\n",
      "################################  340  ################################\n",
      "Loss:  0.0011517431121319532\n",
      "################################  341  ################################\n",
      "Loss:  0.0011460139648988843\n",
      "################################  342  ################################\n",
      "Loss:  0.0011395937763154507\n",
      "################################  343  ################################\n",
      "Loss:  0.0011325250379741192\n",
      "################################  344  ################################\n",
      "Loss:  0.001124718924984336\n",
      "################################  345  ################################\n",
      "Loss:  0.0011164986062794924\n",
      "################################  346  ################################\n",
      "Loss:  0.0011080022668465972\n",
      "################################  347  ################################\n",
      "Loss:  0.0010983943939208984\n",
      "################################  348  ################################\n",
      "Loss:  0.0010890911798924208\n",
      "################################  349  ################################\n",
      "Loss:  0.001078569795936346\n",
      "################################  350  ################################\n",
      "Loss:  0.0010705806780606508\n",
      "################################  351  ################################\n",
      "Loss:  0.0010613410267978907\n",
      "################################  352  ################################\n",
      "Loss:  0.0010480086784809828\n",
      "################################  353  ################################\n",
      "Loss:  0.0010391760151833296\n",
      "################################  354  ################################\n",
      "Loss:  0.001030166633427143\n",
      "################################  355  ################################\n",
      "Loss:  0.0010207700543105602\n",
      "################################  356  ################################\n",
      "Loss:  0.001011507585644722\n",
      "################################  357  ################################\n",
      "Loss:  0.0010025500087067485\n",
      "################################  358  ################################\n",
      "Loss:  0.0009937763679772615\n",
      "################################  359  ################################\n",
      "Loss:  0.0009855458047240973\n",
      "################################  360  ################################\n",
      "Loss:  0.0009777218801900744\n",
      "################################  361  ################################\n",
      "Loss:  0.0009705157717689872\n",
      "################################  362  ################################\n",
      "Loss:  0.0009636965114623308\n",
      "################################  363  ################################\n",
      "Loss:  0.0009574179421178997\n",
      "################################  364  ################################\n",
      "Loss:  0.0009514653356745839\n",
      "################################  365  ################################\n",
      "Loss:  0.0009459008579142392\n",
      "################################  366  ################################\n",
      "Loss:  0.0009405501768924296\n",
      "################################  367  ################################\n",
      "Loss:  0.0009354195208288729\n",
      "################################  368  ################################\n",
      "Loss:  0.0009304097620770335\n",
      "################################  369  ################################\n",
      "Loss:  0.0009255397017113864\n",
      "################################  370  ################################\n",
      "Loss:  0.0009207049733959138\n",
      "################################  371  ################################\n",
      "Loss:  0.0009159507462754846\n",
      "################################  372  ################################\n",
      "Loss:  0.0009112189873121679\n",
      "################################  373  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0009066604543477297\n",
      "################################  374  ################################\n",
      "Loss:  0.0009022317826747894\n",
      "################################  375  ################################\n",
      "Loss:  0.0008978464175015688\n",
      "################################  376  ################################\n",
      "Loss:  0.0008935326477512717\n",
      "################################  377  ################################\n",
      "Loss:  0.0008891670731827617\n",
      "################################  378  ################################\n",
      "Loss:  0.0008849102887324989\n",
      "################################  379  ################################\n",
      "Loss:  0.0008806554833427072\n",
      "################################  380  ################################\n",
      "Loss:  0.0008764768717810512\n",
      "################################  381  ################################\n",
      "Loss:  0.0008723473874852061\n",
      "################################  382  ################################\n",
      "Loss:  0.0008682911284267902\n",
      "################################  383  ################################\n",
      "Loss:  0.0008643409237265587\n",
      "################################  384  ################################\n",
      "Loss:  0.0008601425215601921\n",
      "################################  385  ################################\n",
      "Loss:  0.0008561723516322672\n",
      "################################  386  ################################\n",
      "Loss:  0.0008524243021383882\n",
      "################################  387  ################################\n",
      "Loss:  0.0008486307924613357\n",
      "################################  388  ################################\n",
      "Loss:  0.0008449659217149019\n",
      "################################  389  ################################\n",
      "Loss:  0.000841309956740588\n",
      "################################  390  ################################\n",
      "Loss:  0.0008377350168302655\n",
      "################################  391  ################################\n",
      "Loss:  0.0008341451175510883\n",
      "################################  392  ################################\n",
      "Loss:  0.000830500794108957\n",
      "################################  393  ################################\n",
      "Loss:  0.0008269257959909737\n",
      "################################  394  ################################\n",
      "Loss:  0.0008233419503085315\n",
      "################################  395  ################################\n",
      "Loss:  0.0008197439019568264\n",
      "################################  396  ################################\n",
      "Loss:  0.0008161130826920271\n",
      "################################  397  ################################\n",
      "Loss:  0.0008124483283609152\n",
      "################################  398  ################################\n",
      "Loss:  0.000808723911177367\n",
      "################################  399  ################################\n",
      "Loss:  0.000804889714345336\n",
      "################################  400  ################################\n",
      "Loss:  0.0008009925950318575\n",
      "################################  401  ################################\n",
      "Loss:  0.000797493732534349\n",
      "################################  402  ################################\n",
      "Loss:  0.0007941466756165028\n",
      "################################  403  ################################\n",
      "Loss:  0.0007907114340923727\n",
      "################################  404  ################################\n",
      "Loss:  0.0007871969137340784\n",
      "################################  405  ################################\n",
      "Loss:  0.0007836157456040382\n",
      "################################  406  ################################\n",
      "Loss:  0.0007799527375027537\n",
      "################################  407  ################################\n",
      "Loss:  0.00077625154517591\n",
      "################################  408  ################################\n",
      "Loss:  0.0007723640883341432\n",
      "################################  409  ################################\n",
      "Loss:  0.000768527330365032\n",
      "################################  410  ################################\n",
      "Loss:  0.0007647235179319978\n",
      "################################  411  ################################\n",
      "Loss:  0.0007609197054989636\n",
      "################################  412  ################################\n",
      "Loss:  0.0007574110641144216\n",
      "################################  413  ################################\n",
      "Loss:  0.0007537372293882072\n",
      "################################  414  ################################\n",
      "Loss:  0.0007504336535930634\n",
      "################################  415  ################################\n",
      "Loss:  0.0007469853735528886\n",
      "################################  416  ################################\n",
      "Loss:  0.0007435007719323039\n",
      "################################  417  ################################\n",
      "Loss:  0.0007400871254503727\n",
      "################################  418  ################################\n",
      "Loss:  0.0007367315702140331\n",
      "################################  419  ################################\n",
      "Loss:  0.000733516295440495\n",
      "################################  420  ################################\n",
      "Loss:  0.0007305126055143774\n",
      "################################  421  ################################\n",
      "Loss:  0.0007276601390913129\n",
      "################################  422  ################################\n",
      "Loss:  0.0007250253111124039\n",
      "################################  423  ################################\n",
      "Loss:  0.0007225224399007857\n",
      "################################  424  ################################\n",
      "Loss:  0.0007201987900771201\n",
      "################################  425  ################################\n",
      "Loss:  0.000718034221790731\n",
      "################################  426  ################################\n",
      "Loss:  0.0007159658707678318\n",
      "################################  427  ################################\n",
      "Loss:  0.0007140610832720995\n",
      "################################  428  ################################\n",
      "Loss:  0.0007122276001609862\n",
      "################################  429  ################################\n",
      "Loss:  0.000710477470420301\n",
      "################################  430  ################################\n",
      "Loss:  0.0007087241974659264\n",
      "################################  431  ################################\n",
      "Loss:  0.0007069704588502645\n",
      "################################  432  ################################\n",
      "Loss:  0.000705131737049669\n",
      "################################  433  ################################\n",
      "Loss:  0.0007032480207271874\n",
      "################################  434  ################################\n",
      "Loss:  0.0007012018468230963\n",
      "################################  435  ################################\n",
      "Loss:  0.0006990503752604127\n",
      "################################  436  ################################\n",
      "Loss:  0.0006967373192310333\n",
      "################################  437  ################################\n",
      "Loss:  0.0006943962653167546\n",
      "################################  438  ################################\n",
      "Loss:  0.0006919461884535849\n",
      "################################  439  ################################\n",
      "Loss:  0.0006894031539559364\n",
      "################################  440  ################################\n",
      "Loss:  0.0006867566844448447\n",
      "################################  441  ################################\n",
      "Loss:  0.0006840549176558852\n",
      "################################  442  ################################\n",
      "Loss:  0.0006812666542828083\n",
      "################################  443  ################################\n",
      "Loss:  0.0006784065626561642\n",
      "################################  444  ################################\n",
      "Loss:  0.0006756569491699338\n",
      "################################  445  ################################\n",
      "Loss:  0.000672954018227756\n",
      "################################  446  ################################\n",
      "Loss:  0.0006703737890347838\n",
      "################################  447  ################################\n",
      "Loss:  0.0006678183563053608\n",
      "################################  448  ################################\n",
      "Loss:  0.0006652409210801125\n",
      "################################  449  ################################\n",
      "Loss:  0.0006627842085435987\n",
      "################################  450  ################################\n",
      "Loss:  0.0006605781381949782\n",
      "################################  451  ################################\n",
      "Loss:  0.0006585975643247366\n",
      "################################  452  ################################\n",
      "Loss:  0.0006568058161064982\n",
      "################################  453  ################################\n",
      "Loss:  0.0006550663383677602\n",
      "################################  454  ################################\n",
      "Loss:  0.0006534225540235639\n",
      "################################  455  ################################\n",
      "Loss:  0.0006519135786220431\n",
      "################################  456  ################################\n",
      "Loss:  0.0006504471530206501\n",
      "################################  457  ################################\n",
      "Loss:  0.0006489930674433708\n",
      "################################  458  ################################\n",
      "Loss:  0.0006475293193943799\n",
      "################################  459  ################################\n",
      "Loss:  0.0006460835575126112\n",
      "################################  460  ################################\n",
      "Loss:  0.0006446926854550838\n",
      "################################  461  ################################\n",
      "Loss:  0.0006432717782445252\n",
      "################################  462  ################################\n",
      "Loss:  0.0006418409757316113\n",
      "################################  463  ################################\n",
      "Loss:  0.000640440615825355\n",
      "################################  464  ################################\n",
      "Loss:  0.0006390323396772146\n",
      "################################  465  ################################\n",
      "Loss:  0.0006375808152370155\n",
      "################################  466  ################################\n",
      "Loss:  0.0006361341220326722\n",
      "################################  467  ################################\n",
      "Loss:  0.000634754600469023\n",
      "################################  468  ################################\n",
      "Loss:  0.0006334003992378712\n",
      "################################  469  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0006320595275610685\n",
      "################################  470  ################################\n",
      "Loss:  0.0006307232542894781\n",
      "################################  471  ################################\n",
      "Loss:  0.0006293647456914186\n",
      "################################  472  ################################\n",
      "Loss:  0.0006280118832364678\n",
      "################################  473  ################################\n",
      "Loss:  0.0006266196724027395\n",
      "################################  474  ################################\n",
      "Loss:  0.0006252322345972061\n",
      "################################  475  ################################\n",
      "Loss:  0.0006237939815036952\n",
      "################################  476  ################################\n",
      "Loss:  0.0006223515956662595\n",
      "################################  477  ################################\n",
      "Loss:  0.0006208306294865906\n",
      "################################  478  ################################\n",
      "Loss:  0.0006192490691319108\n",
      "################################  479  ################################\n",
      "Loss:  0.0006175664602778852\n",
      "################################  480  ################################\n",
      "Loss:  0.0006158066680654883\n",
      "################################  481  ################################\n",
      "Loss:  0.0006140234181657434\n",
      "################################  482  ################################\n",
      "Loss:  0.0006121554179117084\n",
      "################################  483  ################################\n",
      "Loss:  0.0006102951010689139\n",
      "################################  484  ################################\n",
      "Loss:  0.0006083848420530558\n",
      "################################  485  ################################\n",
      "Loss:  0.0006064813351258636\n",
      "################################  486  ################################\n",
      "Loss:  0.00060457136714831\n",
      "################################  487  ################################\n",
      "Loss:  0.0006026602350175381\n",
      "################################  488  ################################\n",
      "Loss:  0.0006007832707837224\n",
      "################################  489  ################################\n",
      "Loss:  0.0005990130011923611\n",
      "################################  490  ################################\n",
      "Loss:  0.0005974176456220448\n",
      "################################  491  ################################\n",
      "Loss:  0.0005957896937616169\n",
      "################################  492  ################################\n",
      "Loss:  0.0005942778661847115\n",
      "################################  493  ################################\n",
      "Loss:  0.0005927832680754364\n",
      "################################  494  ################################\n",
      "Loss:  0.0005913327331654727\n",
      "################################  495  ################################\n",
      "Loss:  0.0005899539100937545\n",
      "################################  496  ################################\n",
      "Loss:  0.0005885956925339997\n",
      "################################  497  ################################\n",
      "Loss:  0.000587283750064671\n",
      "################################  498  ################################\n",
      "Loss:  0.0005859988741576672\n",
      "################################  499  ################################\n",
      "Loss:  0.0005847468273714185\n",
      "################################  500  ################################\n",
      "Loss:  0.0005835307529196143\n",
      "################################  501  ################################\n",
      "Loss:  0.0005823365645483136\n",
      "################################  502  ################################\n",
      "Loss:  0.0005811744485981762\n",
      "################################  503  ################################\n",
      "Loss:  0.000580034451559186\n",
      "################################  504  ################################\n",
      "Loss:  0.000578859995584935\n",
      "################################  505  ################################\n",
      "Loss:  0.0005777089390903711\n",
      "################################  506  ################################\n",
      "Loss:  0.0005765438545495272\n",
      "################################  507  ################################\n",
      "Loss:  0.0005753797013312578\n",
      "################################  508  ################################\n",
      "Loss:  0.0005742333014495671\n",
      "################################  509  ################################\n",
      "Loss:  0.0005730940611101687\n",
      "################################  510  ################################\n",
      "Loss:  0.0005719760083593428\n",
      "################################  511  ################################\n",
      "Loss:  0.0005709080724045634\n",
      "################################  512  ################################\n",
      "Loss:  0.0005697992746718228\n",
      "################################  513  ################################\n",
      "Loss:  0.0005687610828317702\n",
      "################################  514  ################################\n",
      "Loss:  0.0005676697473973036\n",
      "################################  515  ################################\n",
      "Loss:  0.0005667354562319815\n",
      "################################  516  ################################\n",
      "Loss:  0.000565532420296222\n",
      "################################  517  ################################\n",
      "Loss:  0.0005644725169986486\n",
      "################################  518  ################################\n",
      "Loss:  0.0005631606327369809\n",
      "################################  519  ################################\n",
      "Loss:  0.0005617057322524488\n",
      "################################  520  ################################\n",
      "Loss:  0.0005598028074018657\n",
      "################################  521  ################################\n",
      "Loss:  0.0005584756727330387\n",
      "################################  522  ################################\n",
      "Loss:  0.0005568718770518899\n",
      "################################  523  ################################\n",
      "Loss:  0.0005550754722207785\n",
      "################################  524  ################################\n",
      "Loss:  0.0005529340705834329\n",
      "################################  525  ################################\n",
      "Loss:  0.000551112461835146\n",
      "################################  526  ################################\n",
      "Loss:  0.0005491999909281731\n",
      "################################  527  ################################\n",
      "Loss:  0.000546882045455277\n",
      "################################  528  ################################\n",
      "Loss:  0.0005451730685308576\n",
      "################################  529  ################################\n",
      "Loss:  0.0005433749756775796\n",
      "################################  530  ################################\n",
      "Loss:  0.0005415763007476926\n",
      "################################  531  ################################\n",
      "Loss:  0.0005398395005613565\n",
      "################################  532  ################################\n",
      "Loss:  0.0005382465897127986\n",
      "################################  533  ################################\n",
      "Loss:  0.0005366693367250264\n",
      "################################  534  ################################\n",
      "Loss:  0.0005353320157155395\n",
      "################################  535  ################################\n",
      "Loss:  0.0005341016221791506\n",
      "################################  536  ################################\n",
      "Loss:  0.0005327583639882505\n",
      "################################  537  ################################\n",
      "Loss:  0.0005316458409652114\n",
      "################################  538  ################################\n",
      "Loss:  0.0005306721432134509\n",
      "################################  539  ################################\n",
      "Loss:  0.0005296999006532133\n",
      "################################  540  ################################\n",
      "Loss:  0.0005287255626171827\n",
      "################################  541  ################################\n",
      "Loss:  0.0005278243916109204\n",
      "################################  542  ################################\n",
      "Loss:  0.0005269180401228368\n",
      "################################  543  ################################\n",
      "Loss:  0.0005260689649730921\n",
      "################################  544  ################################\n",
      "Loss:  0.0005252269329503179\n",
      "################################  545  ################################\n",
      "Loss:  0.0005244233761914074\n",
      "################################  546  ################################\n",
      "Loss:  0.000523544498719275\n",
      "################################  547  ################################\n",
      "Loss:  0.0005224852357059717\n",
      "################################  548  ################################\n",
      "Loss:  0.000521363690495491\n",
      "################################  549  ################################\n",
      "Loss:  0.0005202364409342408\n",
      "################################  550  ################################\n",
      "Loss:  0.0005191299133002758\n",
      "################################  551  ################################\n",
      "Loss:  0.0005179846193641424\n",
      "################################  552  ################################\n",
      "Loss:  0.0005168954376131296\n",
      "################################  553  ################################\n",
      "Loss:  0.0005157163832336664\n",
      "################################  554  ################################\n",
      "Loss:  0.0005144791211932898\n",
      "################################  555  ################################\n",
      "Loss:  0.0005130990175530314\n",
      "################################  556  ################################\n",
      "Loss:  0.0005117503460496664\n",
      "################################  557  ################################\n",
      "Loss:  0.0005102301365695894\n",
      "################################  558  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0005085249431431293\n",
      "################################  559  ################################\n",
      "Loss:  0.000506619515363127\n",
      "################################  560  ################################\n",
      "Loss:  0.0005047823651693761\n",
      "################################  561  ################################\n",
      "Loss:  0.0005028063897043467\n",
      "################################  562  ################################\n",
      "Loss:  0.0005007246509194374\n",
      "################################  563  ################################\n",
      "Loss:  0.0004985200939700007\n",
      "################################  564  ################################\n",
      "Loss:  0.0004964080872014165\n",
      "################################  565  ################################\n",
      "Loss:  0.0004942354862578213\n",
      "################################  566  ################################\n",
      "Loss:  0.0004919002531096339\n",
      "################################  567  ################################\n",
      "Loss:  0.0004896745085716248\n",
      "################################  568  ################################\n",
      "Loss:  0.0004873676225543022\n",
      "################################  569  ################################\n",
      "Loss:  0.00048519251868128777\n",
      "################################  570  ################################\n",
      "Loss:  0.00048293767031282187\n",
      "################################  571  ################################\n",
      "Loss:  0.00048077237443067133\n",
      "################################  572  ################################\n",
      "Loss:  0.00047857576282694936\n",
      "################################  573  ################################\n",
      "Loss:  0.000476398563478142\n",
      "################################  574  ################################\n",
      "Loss:  0.00047426222590729594\n",
      "################################  575  ################################\n",
      "Loss:  0.0004722087178379297\n",
      "################################  576  ################################\n",
      "Loss:  0.00047038192860782146\n",
      "################################  577  ################################\n",
      "Loss:  0.00046852760715410113\n",
      "################################  578  ################################\n",
      "Loss:  0.00046694951015524566\n",
      "################################  579  ################################\n",
      "Loss:  0.00046536949230358005\n",
      "################################  580  ################################\n",
      "Loss:  0.0004637347301468253\n",
      "################################  581  ################################\n",
      "Loss:  0.00046220255899243057\n",
      "################################  582  ################################\n",
      "Loss:  0.0004607574373949319\n",
      "################################  583  ################################\n",
      "Loss:  0.00045945271267555654\n",
      "################################  584  ################################\n",
      "Loss:  0.0004582103283610195\n",
      "################################  585  ################################\n",
      "Loss:  0.0004569754237309098\n",
      "################################  586  ################################\n",
      "Loss:  0.00045581557787954807\n",
      "################################  587  ################################\n",
      "Loss:  0.000454651250038296\n",
      "################################  588  ################################\n",
      "Loss:  0.0004535634070634842\n",
      "################################  589  ################################\n",
      "Loss:  0.0004525080439634621\n",
      "################################  590  ################################\n",
      "Loss:  0.0004514993051998317\n",
      "################################  591  ################################\n",
      "Loss:  0.00045050098560750484\n",
      "################################  592  ################################\n",
      "Loss:  0.000449501967523247\n",
      "################################  593  ################################\n",
      "Loss:  0.0004485363606363535\n",
      "################################  594  ################################\n",
      "Loss:  0.00044760090531781316\n",
      "################################  595  ################################\n",
      "Loss:  0.00044668593909591436\n",
      "################################  596  ################################\n",
      "Loss:  0.0004457521717995405\n",
      "################################  597  ################################\n",
      "Loss:  0.00044479744974523783\n",
      "################################  598  ################################\n",
      "Loss:  0.0004438780597411096\n",
      "################################  599  ################################\n",
      "Loss:  0.0004429709224496037\n",
      "################################  600  ################################\n",
      "Loss:  0.0004420443146955222\n",
      "################################  601  ################################\n",
      "Loss:  0.000441113137640059\n",
      "################################  602  ################################\n",
      "Loss:  0.0004401177284307778\n",
      "################################  603  ################################\n",
      "Loss:  0.00043912316323257983\n",
      "################################  604  ################################\n",
      "Loss:  0.00043800455750897527\n",
      "################################  605  ################################\n",
      "Loss:  0.0004368695372249931\n",
      "################################  606  ################################\n",
      "Loss:  0.0004355275013949722\n",
      "################################  607  ################################\n",
      "Loss:  0.0004337708232924342\n",
      "################################  608  ################################\n",
      "Loss:  0.00043200660729780793\n",
      "################################  609  ################################\n",
      "Loss:  0.00043017984717153013\n",
      "################################  610  ################################\n",
      "Loss:  0.00042826234130188823\n",
      "################################  611  ################################\n",
      "Loss:  0.00042637423030100763\n",
      "################################  612  ################################\n",
      "Loss:  0.0004244657466188073\n",
      "################################  613  ################################\n",
      "Loss:  0.0004225925076752901\n",
      "################################  614  ################################\n",
      "Loss:  0.000420726602897048\n",
      "################################  615  ################################\n",
      "Loss:  0.0004188435268588364\n",
      "################################  616  ################################\n",
      "Loss:  0.000417119066696614\n",
      "################################  617  ################################\n",
      "Loss:  0.0004154507187195122\n",
      "################################  618  ################################\n",
      "Loss:  0.0004140239907428622\n",
      "################################  619  ################################\n",
      "Loss:  0.0004126718849875033\n",
      "################################  620  ################################\n",
      "Loss:  0.00041122990660369396\n",
      "################################  621  ################################\n",
      "Loss:  0.00040972750866785645\n",
      "################################  622  ################################\n",
      "Loss:  0.00040785601595416665\n",
      "################################  623  ################################\n",
      "Loss:  0.0004066763212904334\n",
      "################################  624  ################################\n",
      "Loss:  0.00040558609180152416\n",
      "################################  625  ################################\n",
      "Loss:  0.00040441949386149645\n",
      "################################  626  ################################\n",
      "Loss:  0.0004030160780530423\n",
      "################################  627  ################################\n",
      "Loss:  0.0004018603067379445\n",
      "################################  628  ################################\n",
      "Loss:  0.00040072540286928415\n",
      "################################  629  ################################\n",
      "Loss:  0.0003995092702098191\n",
      "################################  630  ################################\n",
      "Loss:  0.0003982390044257045\n",
      "################################  631  ################################\n",
      "Loss:  0.0003967936791013926\n",
      "################################  632  ################################\n",
      "Loss:  0.00039554107934236526\n",
      "################################  633  ################################\n",
      "Loss:  0.00039413670310750604\n",
      "################################  634  ################################\n",
      "Loss:  0.0003925363125745207\n",
      "################################  635  ################################\n",
      "Loss:  0.0003908638027496636\n",
      "################################  636  ################################\n",
      "Loss:  0.00038907938869670033\n",
      "################################  637  ################################\n",
      "Loss:  0.0003871934022754431\n",
      "################################  638  ################################\n",
      "Loss:  0.0003853463858831674\n",
      "################################  639  ################################\n",
      "Loss:  0.0003837092954199761\n",
      "################################  640  ################################\n",
      "Loss:  0.0003820264246314764\n",
      "################################  641  ################################\n",
      "Loss:  0.00038046727422624826\n",
      "################################  642  ################################\n",
      "Loss:  0.00037893286207690835\n",
      "################################  643  ################################\n",
      "Loss:  0.0003773798234760761\n",
      "################################  644  ################################\n",
      "Loss:  0.00037588441045954823\n",
      "################################  645  ################################\n",
      "Loss:  0.00037443090695887804\n",
      "################################  646  ################################\n",
      "Loss:  0.00037298392271623015\n",
      "################################  647  ################################\n",
      "Loss:  0.00037160844658501446\n",
      "################################  648  ################################\n",
      "Loss:  0.0003702685353346169\n",
      "################################  649  ################################\n",
      "Loss:  0.00036889209877699614\n",
      "################################  650  ################################\n",
      "Loss:  0.0003675451152957976\n",
      "################################  651  ################################\n",
      "Loss:  0.00036620174068957567\n",
      "################################  652  ################################\n",
      "Loss:  0.0003648147394414991\n",
      "################################  653  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.00036362098762765527\n",
      "################################  654  ################################\n",
      "Loss:  0.00036234286380931735\n",
      "################################  655  ################################\n",
      "Loss:  0.0003609904379118234\n",
      "################################  656  ################################\n",
      "Loss:  0.0003590777050703764\n",
      "################################  657  ################################\n",
      "Loss:  0.00035742309410125017\n",
      "################################  658  ################################\n",
      "Loss:  0.0003547832020558417\n",
      "################################  659  ################################\n",
      "Loss:  0.00035311462124809623\n",
      "################################  660  ################################\n",
      "Loss:  0.0003510504902806133\n",
      "################################  661  ################################\n",
      "Loss:  0.00034915254218503833\n",
      "################################  662  ################################\n",
      "Loss:  0.00034703454002738\n",
      "################################  663  ################################\n",
      "Loss:  0.00034489011159166694\n",
      "################################  664  ################################\n",
      "Loss:  0.0003426753100939095\n",
      "################################  665  ################################\n",
      "Loss:  0.00034070524270646274\n",
      "################################  666  ################################\n",
      "Loss:  0.0003387723700143397\n",
      "################################  667  ################################\n",
      "Loss:  0.00033697386970743537\n",
      "################################  668  ################################\n",
      "Loss:  0.0003353826468810439\n",
      "################################  669  ################################\n",
      "Loss:  0.0003340272814966738\n",
      "################################  670  ################################\n",
      "Loss:  0.0003327881859149784\n",
      "################################  671  ################################\n",
      "Loss:  0.0003316931251902133\n",
      "################################  672  ################################\n",
      "Loss:  0.0003306758590042591\n",
      "################################  673  ################################\n",
      "Loss:  0.00032977049704641104\n",
      "################################  674  ################################\n",
      "Loss:  0.0003289948799647391\n",
      "################################  675  ################################\n",
      "Loss:  0.0003282372490502894\n",
      "################################  676  ################################\n",
      "Loss:  0.00032754428684711456\n",
      "################################  677  ################################\n",
      "Loss:  0.00032688805367797613\n",
      "################################  678  ################################\n",
      "Loss:  0.0003261361562181264\n",
      "################################  679  ################################\n",
      "Loss:  0.0003255035262554884\n",
      "################################  680  ################################\n",
      "Loss:  0.00032480413210578263\n",
      "################################  681  ################################\n",
      "Loss:  0.00032384746009483933\n",
      "################################  682  ################################\n",
      "Loss:  0.00032305155764333904\n",
      "################################  683  ################################\n",
      "Loss:  0.00032206205651164055\n",
      "################################  684  ################################\n",
      "Loss:  0.0003210689756087959\n",
      "################################  685  ################################\n",
      "Loss:  0.0003199715865775943\n",
      "################################  686  ################################\n",
      "Loss:  0.0003187501570209861\n",
      "################################  687  ################################\n",
      "Loss:  0.0003174972371198237\n",
      "################################  688  ################################\n",
      "Loss:  0.00031619492801837623\n",
      "################################  689  ################################\n",
      "Loss:  0.00031494966242462397\n",
      "################################  690  ################################\n",
      "Loss:  0.00031367025803774595\n",
      "################################  691  ################################\n",
      "Loss:  0.0003124283975921571\n",
      "################################  692  ################################\n",
      "Loss:  0.0003111324040219188\n",
      "################################  693  ################################\n",
      "Loss:  0.00030999130103737116\n",
      "################################  694  ################################\n",
      "Loss:  0.00030886702006682754\n",
      "################################  695  ################################\n",
      "Loss:  0.0003078041481785476\n",
      "################################  696  ################################\n",
      "Loss:  0.00030670862179249525\n",
      "################################  697  ################################\n",
      "Loss:  0.00030558049911633134\n",
      "################################  698  ################################\n",
      "Loss:  0.0003044169279746711\n",
      "################################  699  ################################\n",
      "Loss:  0.0003033080429304391\n",
      "################################  700  ################################\n",
      "Loss:  0.00030226627131924033\n",
      "################################  701  ################################\n",
      "Loss:  0.00030120654264464974\n",
      "################################  702  ################################\n",
      "Loss:  0.0003003084275405854\n",
      "################################  703  ################################\n",
      "Loss:  0.0002994342357851565\n",
      "################################  704  ################################\n",
      "Loss:  0.000298450788250193\n",
      "################################  705  ################################\n",
      "Loss:  0.00029751178226433694\n",
      "################################  706  ################################\n",
      "Loss:  0.00029659620486199856\n",
      "################################  707  ################################\n",
      "Loss:  0.0002957733813673258\n",
      "################################  708  ################################\n",
      "Loss:  0.0002949194167740643\n",
      "################################  709  ################################\n",
      "Loss:  0.00029409979470074177\n",
      "################################  710  ################################\n",
      "Loss:  0.0002933218493126333\n",
      "################################  711  ################################\n",
      "Loss:  0.00029252894455567\n",
      "################################  712  ################################\n",
      "Loss:  0.00029177265241742134\n",
      "################################  713  ################################\n",
      "Loss:  0.0002910241892095655\n",
      "################################  714  ################################\n",
      "Loss:  0.0002902731648646295\n",
      "################################  715  ################################\n",
      "Loss:  0.00028942700009793043\n",
      "################################  716  ################################\n",
      "Loss:  0.00028856738936156034\n",
      "################################  717  ################################\n",
      "Loss:  0.00028776226099580526\n",
      "################################  718  ################################\n",
      "Loss:  0.00028686702717095613\n",
      "################################  719  ################################\n",
      "Loss:  0.00028602100792340934\n",
      "################################  720  ################################\n",
      "Loss:  0.00028523791115731\n",
      "################################  721  ################################\n",
      "Loss:  0.00028438179288059473\n",
      "################################  722  ################################\n",
      "Loss:  0.00028360140277072787\n",
      "################################  723  ################################\n",
      "Loss:  0.0002827646676450968\n",
      "################################  724  ################################\n",
      "Loss:  0.00028179073706269264\n",
      "################################  725  ################################\n",
      "Loss:  0.0002808669814839959\n",
      "################################  726  ################################\n",
      "Loss:  0.00028000687598250806\n",
      "################################  727  ################################\n",
      "Loss:  0.0002791429287753999\n",
      "################################  728  ################################\n",
      "Loss:  0.0002782822120934725\n",
      "################################  729  ################################\n",
      "Loss:  0.000277380138868466\n",
      "################################  730  ################################\n",
      "Loss:  0.00027643563225865364\n",
      "################################  731  ################################\n",
      "Loss:  0.0002755066379904747\n",
      "################################  732  ################################\n",
      "Loss:  0.00027463462902233005\n",
      "################################  733  ################################\n",
      "Loss:  0.0002737862814683467\n",
      "################################  734  ################################\n",
      "Loss:  0.00027293263701722026\n",
      "################################  735  ################################\n",
      "Loss:  0.000272097357083112\n",
      "################################  736  ################################\n",
      "Loss:  0.00027125628548674285\n",
      "################################  737  ################################\n",
      "Loss:  0.0002704040380194783\n",
      "################################  738  ################################\n",
      "Loss:  0.0002695653820410371\n",
      "################################  739  ################################\n",
      "Loss:  0.0002687250671442598\n",
      "################################  740  ################################\n",
      "Loss:  0.0002679356257431209\n",
      "################################  741  ################################\n",
      "Loss:  0.0002671860856935382\n",
      "################################  742  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0002664439380168915\n",
      "################################  743  ################################\n",
      "Loss:  0.0002656503929756582\n",
      "################################  744  ################################\n",
      "Loss:  0.0002648054505698383\n",
      "################################  745  ################################\n",
      "Loss:  0.00026407523546367884\n",
      "################################  746  ################################\n",
      "Loss:  0.0002634220290929079\n",
      "################################  747  ################################\n",
      "Loss:  0.00026269303634762764\n",
      "################################  748  ################################\n",
      "Loss:  0.0002620640443637967\n",
      "################################  749  ################################\n",
      "Loss:  0.00026125373551622033\n",
      "################################  750  ################################\n",
      "Loss:  0.00026038195937871933\n",
      "################################  751  ################################\n",
      "Loss:  0.00025937819737009704\n",
      "################################  752  ################################\n",
      "Loss:  0.000258240062976256\n",
      "################################  753  ################################\n",
      "Loss:  0.0002569564385339618\n",
      "################################  754  ################################\n",
      "Loss:  0.0002557014813646674\n",
      "################################  755  ################################\n",
      "Loss:  0.0002543654409237206\n",
      "################################  756  ################################\n",
      "Loss:  0.00025289435870945454\n",
      "################################  757  ################################\n",
      "Loss:  0.0002513974905014038\n",
      "################################  758  ################################\n",
      "Loss:  0.00024988502264022827\n",
      "################################  759  ################################\n",
      "Loss:  0.0002485201694071293\n",
      "################################  760  ################################\n",
      "Loss:  0.0002471238549333066\n",
      "################################  761  ################################\n",
      "Loss:  0.0002457575174048543\n",
      "################################  762  ################################\n",
      "Loss:  0.0002446091966703534\n",
      "################################  763  ################################\n",
      "Loss:  0.0002435729547869414\n",
      "################################  764  ################################\n",
      "Loss:  0.00024258653866127133\n",
      "################################  765  ################################\n",
      "Loss:  0.00024164245405700058\n",
      "################################  766  ################################\n",
      "Loss:  0.00024078004935290664\n",
      "################################  767  ################################\n",
      "Loss:  0.00023995043011382222\n",
      "################################  768  ################################\n",
      "Loss:  0.00023923287517391145\n",
      "################################  769  ################################\n",
      "Loss:  0.00023857546329963952\n",
      "################################  770  ################################\n",
      "Loss:  0.00023789875558577478\n",
      "################################  771  ################################\n",
      "Loss:  0.00023730484826955944\n",
      "################################  772  ################################\n",
      "Loss:  0.0002365754044149071\n",
      "################################  773  ################################\n",
      "Loss:  0.00023603062436450273\n",
      "################################  774  ################################\n",
      "Loss:  0.00023548136232420802\n",
      "################################  775  ################################\n",
      "Loss:  0.00023481147945858538\n",
      "################################  776  ################################\n",
      "Loss:  0.00023410086578223854\n",
      "################################  777  ################################\n",
      "Loss:  0.00023325078655034304\n",
      "################################  778  ################################\n",
      "Loss:  0.00023252502433024347\n",
      "################################  779  ################################\n",
      "Loss:  0.00023174147645477206\n",
      "################################  780  ################################\n",
      "Loss:  0.0002308750554220751\n",
      "################################  781  ################################\n",
      "Loss:  0.00023003562819212675\n",
      "################################  782  ################################\n",
      "Loss:  0.00022922064817976207\n",
      "################################  783  ################################\n",
      "Loss:  0.00022846224601380527\n",
      "################################  784  ################################\n",
      "Loss:  0.0002276980085298419\n",
      "################################  785  ################################\n",
      "Loss:  0.00022694122162647545\n",
      "################################  786  ################################\n",
      "Loss:  0.00022621155949309468\n",
      "################################  787  ################################\n",
      "Loss:  0.0002255125727970153\n",
      "################################  788  ################################\n",
      "Loss:  0.00022483142674900591\n",
      "################################  789  ################################\n",
      "Loss:  0.00022418025764636695\n",
      "################################  790  ################################\n",
      "Loss:  0.000223513605305925\n",
      "################################  791  ################################\n",
      "Loss:  0.00022295358940027654\n",
      "################################  792  ################################\n",
      "Loss:  0.00022243091370910406\n",
      "################################  793  ################################\n",
      "Loss:  0.00022187031572684646\n",
      "################################  794  ################################\n",
      "Loss:  0.0002213119005318731\n",
      "################################  795  ################################\n",
      "Loss:  0.00022072947467677295\n",
      "################################  796  ################################\n",
      "Loss:  0.0002201206370955333\n",
      "################################  797  ################################\n",
      "Loss:  0.00021946855122223496\n",
      "################################  798  ################################\n",
      "Loss:  0.00021879386622458696\n",
      "################################  799  ################################\n",
      "Loss:  0.00021814851788803935\n",
      "################################  800  ################################\n",
      "Loss:  0.00021750549785792828\n",
      "################################  801  ################################\n",
      "Loss:  0.00021690316498279572\n",
      "################################  802  ################################\n",
      "Loss:  0.00021631940035149455\n",
      "################################  803  ################################\n",
      "Loss:  0.00021574828133452684\n",
      "################################  804  ################################\n",
      "Loss:  0.00021520616428460926\n",
      "################################  805  ################################\n",
      "Loss:  0.0002146929909940809\n",
      "################################  806  ################################\n",
      "Loss:  0.0002141836448572576\n",
      "################################  807  ################################\n",
      "Loss:  0.00021362939151003957\n",
      "################################  808  ################################\n",
      "Loss:  0.00021305226255208254\n",
      "################################  809  ################################\n",
      "Loss:  0.00021261909569147974\n",
      "################################  810  ################################\n",
      "Loss:  0.00021217920584604144\n",
      "################################  811  ################################\n",
      "Loss:  0.00021175702568143606\n",
      "################################  812  ################################\n",
      "Loss:  0.00021133414702489972\n",
      "################################  813  ################################\n",
      "Loss:  0.00021087893401272595\n",
      "################################  814  ################################\n",
      "Loss:  0.00021041402942501009\n",
      "################################  815  ################################\n",
      "Loss:  0.00020993735233787447\n",
      "################################  816  ################################\n",
      "Loss:  0.00020943349227309227\n",
      "################################  817  ################################\n",
      "Loss:  0.00020891310123261064\n",
      "################################  818  ################################\n",
      "Loss:  0.0002083799772663042\n",
      "################################  819  ################################\n",
      "Loss:  0.00020782719366252422\n",
      "################################  820  ################################\n",
      "Loss:  0.0002072565839625895\n",
      "################################  821  ################################\n",
      "Loss:  0.00020675365522038192\n",
      "################################  822  ################################\n",
      "Loss:  0.0002062230050796643\n",
      "################################  823  ################################\n",
      "Loss:  0.00020574995141942054\n",
      "################################  824  ################################\n",
      "Loss:  0.00020524501451291144\n",
      "################################  825  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.00020461942767724395\n",
      "################################  826  ################################\n",
      "Loss:  0.00020412387675605714\n",
      "################################  827  ################################\n",
      "Loss:  0.00020363427756819874\n",
      "################################  828  ################################\n",
      "Loss:  0.00020310853142291307\n",
      "################################  829  ################################\n",
      "Loss:  0.00020260942983441055\n",
      "################################  830  ################################\n",
      "Loss:  0.00020210925140418112\n",
      "################################  831  ################################\n",
      "Loss:  0.00020162916916888207\n",
      "################################  832  ################################\n",
      "Loss:  0.00020114899962209165\n",
      "################################  833  ################################\n",
      "Loss:  0.00020071532344445586\n",
      "################################  834  ################################\n",
      "Loss:  0.00020029334700666368\n",
      "################################  835  ################################\n",
      "Loss:  0.000199847825570032\n",
      "################################  836  ################################\n",
      "Loss:  0.00019944027008023113\n",
      "################################  837  ################################\n",
      "Loss:  0.00019902910571545362\n",
      "################################  838  ################################\n",
      "Loss:  0.00019864641944877803\n",
      "################################  839  ################################\n",
      "Loss:  0.00019822680042125285\n",
      "################################  840  ################################\n",
      "Loss:  0.00019778343266807497\n",
      "################################  841  ################################\n",
      "Loss:  0.00019724032608792186\n",
      "################################  842  ################################\n",
      "Loss:  0.00019670331676024944\n",
      "################################  843  ################################\n",
      "Loss:  0.0001959975197678432\n",
      "################################  844  ################################\n",
      "Loss:  0.0001953476166818291\n",
      "################################  845  ################################\n",
      "Loss:  0.00019464298384264112\n",
      "################################  846  ################################\n",
      "Loss:  0.00019388331566005945\n",
      "################################  847  ################################\n",
      "Loss:  0.00019311736105009913\n",
      "################################  848  ################################\n",
      "Loss:  0.00019233586499467492\n",
      "################################  849  ################################\n",
      "Loss:  0.00019158687791787088\n",
      "################################  850  ################################\n",
      "Loss:  0.00019085445092059672\n",
      "################################  851  ################################\n",
      "Loss:  0.00019012144184671342\n",
      "################################  852  ################################\n",
      "Loss:  0.00018941963207907975\n",
      "################################  853  ################################\n",
      "Loss:  0.0001887383114080876\n",
      "################################  854  ################################\n",
      "Loss:  0.000188088248251006\n",
      "################################  855  ################################\n",
      "Loss:  0.00018746490241028368\n",
      "################################  856  ################################\n",
      "Loss:  0.00018687042756937444\n",
      "################################  857  ################################\n",
      "Loss:  0.00018629095575306565\n",
      "################################  858  ################################\n",
      "Loss:  0.00018573581473901868\n",
      "################################  859  ################################\n",
      "Loss:  0.00018517483840696514\n",
      "################################  860  ################################\n",
      "Loss:  0.00018466002075001597\n",
      "################################  861  ################################\n",
      "Loss:  0.00018417106184642762\n",
      "################################  862  ################################\n",
      "Loss:  0.0001836809969972819\n",
      "################################  863  ################################\n",
      "Loss:  0.00018321344396099448\n",
      "################################  864  ################################\n",
      "Loss:  0.00018275700858794153\n",
      "################################  865  ################################\n",
      "Loss:  0.00018232170259580016\n",
      "################################  866  ################################\n",
      "Loss:  0.0001818967139115557\n",
      "################################  867  ################################\n",
      "Loss:  0.0001815210998756811\n",
      "################################  868  ################################\n",
      "Loss:  0.00018117172294296324\n",
      "################################  869  ################################\n",
      "Loss:  0.00018083176109939814\n",
      "################################  870  ################################\n",
      "Loss:  0.000180500908754766\n",
      "################################  871  ################################\n",
      "Loss:  0.00018017017282545567\n",
      "################################  872  ################################\n",
      "Loss:  0.00017983911675401032\n",
      "################################  873  ################################\n",
      "Loss:  0.00017950846813619137\n",
      "################################  874  ################################\n",
      "Loss:  0.00017913279589265585\n",
      "################################  875  ################################\n",
      "Loss:  0.00017878488870337605\n",
      "################################  876  ################################\n",
      "Loss:  0.00017851773009169847\n",
      "################################  877  ################################\n",
      "Loss:  0.00017822306836023927\n",
      "################################  878  ################################\n",
      "Loss:  0.00017794620362110436\n",
      "################################  879  ################################\n",
      "Loss:  0.0001776372955646366\n",
      "################################  880  ################################\n",
      "Loss:  0.0001773989642970264\n",
      "################################  881  ################################\n",
      "Loss:  0.0001771170791471377\n",
      "################################  882  ################################\n",
      "Loss:  0.000176791480043903\n",
      "################################  883  ################################\n",
      "Loss:  0.00017644328181631863\n",
      "################################  884  ################################\n",
      "Loss:  0.000176091562025249\n",
      "################################  885  ################################\n",
      "Loss:  0.0001757269783411175\n",
      "################################  886  ################################\n",
      "Loss:  0.0001753539254423231\n",
      "################################  887  ################################\n",
      "Loss:  0.00017497618682682514\n",
      "################################  888  ################################\n",
      "Loss:  0.00017460036906413734\n",
      "################################  889  ################################\n",
      "Loss:  0.0001742253080010414\n",
      "################################  890  ################################\n",
      "Loss:  0.00017385203682351857\n",
      "################################  891  ################################\n",
      "Loss:  0.0001734675606712699\n",
      "################################  892  ################################\n",
      "Loss:  0.00017312064301222563\n",
      "################################  893  ################################\n",
      "Loss:  0.00017276767175644636\n",
      "################################  894  ################################\n",
      "Loss:  0.0001723941823001951\n",
      "################################  895  ################################\n",
      "Loss:  0.00017203089373651892\n",
      "################################  896  ################################\n",
      "Loss:  0.00017165960161946714\n",
      "################################  897  ################################\n",
      "Loss:  0.0001712910016067326\n",
      "################################  898  ################################\n",
      "Loss:  0.0001709248317638412\n",
      "################################  899  ################################\n",
      "Loss:  0.00017055199714377522\n",
      "################################  900  ################################\n",
      "Loss:  0.00017016584752127528\n",
      "################################  901  ################################\n",
      "Loss:  0.00016976374899968505\n",
      "################################  902  ################################\n",
      "Loss:  0.0001693466620054096\n",
      "################################  903  ################################\n",
      "Loss:  0.00016897637397050858\n",
      "################################  904  ################################\n",
      "Loss:  0.00016860676987562329\n",
      "################################  905  ################################\n",
      "Loss:  0.00016825849888846278\n",
      "################################  906  ################################\n",
      "Loss:  0.00016788998618721962\n",
      "################################  907  ################################\n",
      "Loss:  0.0001675504317972809\n",
      "################################  908  ################################\n",
      "Loss:  0.0001671680947765708\n",
      "################################  909  ################################\n",
      "Loss:  0.00016682296700309962\n",
      "################################  910  ################################\n",
      "Loss:  0.0001664367300691083\n",
      "################################  911  ################################\n",
      "Loss:  0.0001660413690842688\n",
      "################################  912  ################################\n",
      "Loss:  0.0001656486710999161\n",
      "################################  913  ################################\n",
      "Loss:  0.0001652905048104003\n",
      "################################  914  ################################\n",
      "Loss:  0.0001649326441111043\n",
      "################################  915  ################################\n",
      "Loss:  0.00016458203026559204\n",
      "################################  916  ################################\n",
      "Loss:  0.00016424135537818074\n",
      "################################  917  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.00016389910888392478\n",
      "################################  918  ################################\n",
      "Loss:  0.0001635714143048972\n",
      "################################  919  ################################\n",
      "Loss:  0.00016324801254086196\n",
      "################################  920  ################################\n",
      "Loss:  0.00016294224769808352\n",
      "################################  921  ################################\n",
      "Loss:  0.00016265377053059638\n",
      "################################  922  ################################\n",
      "Loss:  0.00016237562522292137\n",
      "################################  923  ################################\n",
      "Loss:  0.00016211633919738233\n",
      "################################  924  ################################\n",
      "Loss:  0.00016186098218895495\n",
      "################################  925  ################################\n",
      "Loss:  0.0001616193912923336\n",
      "################################  926  ################################\n",
      "Loss:  0.0001613870117580518\n",
      "################################  927  ################################\n",
      "Loss:  0.00016113973106257617\n",
      "################################  928  ################################\n",
      "Loss:  0.00016089013661257923\n",
      "################################  929  ################################\n",
      "Loss:  0.0001606503501534462\n",
      "################################  930  ################################\n",
      "Loss:  0.00016037125897128135\n",
      "################################  931  ################################\n",
      "Loss:  0.00016013011918403208\n",
      "################################  932  ################################\n",
      "Loss:  0.00015977441216818988\n",
      "################################  933  ################################\n",
      "Loss:  0.00015944067854434252\n",
      "################################  934  ################################\n",
      "Loss:  0.00015901040751487017\n",
      "################################  935  ################################\n",
      "Loss:  0.00015851249918341637\n",
      "################################  936  ################################\n",
      "Loss:  0.00015797487867530435\n",
      "################################  937  ################################\n",
      "Loss:  0.0001573860936332494\n",
      "################################  938  ################################\n",
      "Loss:  0.0001567874860484153\n",
      "################################  939  ################################\n",
      "Loss:  0.00015617551980540156\n",
      "################################  940  ################################\n",
      "Loss:  0.0001555526105221361\n",
      "################################  941  ################################\n",
      "Loss:  0.0001549600128782913\n",
      "################################  942  ################################\n",
      "Loss:  0.00015438516857102513\n",
      "################################  943  ################################\n",
      "Loss:  0.0001538208161946386\n",
      "################################  944  ################################\n",
      "Loss:  0.00015329301822930574\n",
      "################################  945  ################################\n",
      "Loss:  0.00015276658814400434\n",
      "################################  946  ################################\n",
      "Loss:  0.00015227080439217389\n",
      "################################  947  ################################\n",
      "Loss:  0.00015179935144260526\n",
      "################################  948  ################################\n",
      "Loss:  0.00015131960390135646\n",
      "################################  949  ################################\n",
      "Loss:  0.0001509017893113196\n",
      "################################  950  ################################\n",
      "Loss:  0.00015049122157506645\n",
      "################################  951  ################################\n",
      "Loss:  0.00015013053780421615\n",
      "################################  952  ################################\n",
      "Loss:  0.0001498143537901342\n",
      "################################  953  ################################\n",
      "Loss:  0.00014949069009162486\n",
      "################################  954  ################################\n",
      "Loss:  0.000149232626426965\n",
      "################################  955  ################################\n",
      "Loss:  0.00014900451060384512\n",
      "################################  956  ################################\n",
      "Loss:  0.00014876721252221614\n",
      "################################  957  ################################\n",
      "Loss:  0.0001485648681409657\n",
      "################################  958  ################################\n",
      "Loss:  0.00014837412163615227\n",
      "################################  959  ################################\n",
      "Loss:  0.00014816015027463436\n",
      "################################  960  ################################\n",
      "Loss:  0.00014797112089581788\n",
      "################################  961  ################################\n",
      "Loss:  0.00014774076407775283\n",
      "################################  962  ################################\n",
      "Loss:  0.0001474610180594027\n",
      "################################  963  ################################\n",
      "Loss:  0.00014710621326230466\n",
      "################################  964  ################################\n",
      "Loss:  0.00014677476428914815\n",
      "################################  965  ################################\n",
      "Loss:  0.0001462768268538639\n",
      "################################  966  ################################\n",
      "Loss:  0.00014595729589927942\n",
      "################################  967  ################################\n",
      "Loss:  0.00014556570386048406\n",
      "################################  968  ################################\n",
      "Loss:  0.00014511501649394631\n",
      "################################  969  ################################\n",
      "Loss:  0.00014466376160271466\n",
      "################################  970  ################################\n",
      "Loss:  0.00014418785576708615\n",
      "################################  971  ################################\n",
      "Loss:  0.0001437159808119759\n",
      "################################  972  ################################\n",
      "Loss:  0.00014323843060992658\n",
      "################################  973  ################################\n",
      "Loss:  0.00014277329319156706\n",
      "################################  974  ################################\n",
      "Loss:  0.00014230345550458878\n",
      "################################  975  ################################\n",
      "Loss:  0.00014186030603013933\n",
      "################################  976  ################################\n",
      "Loss:  0.0001414207072230056\n",
      "################################  977  ################################\n",
      "Loss:  0.00014107537572272122\n",
      "################################  978  ################################\n",
      "Loss:  0.00014074344653636217\n",
      "################################  979  ################################\n",
      "Loss:  0.00014045453281141818\n",
      "################################  980  ################################\n",
      "Loss:  0.00014017525245435536\n",
      "################################  981  ################################\n",
      "Loss:  0.00013989905710332096\n",
      "################################  982  ################################\n",
      "Loss:  0.00013962340017315\n",
      "################################  983  ################################\n",
      "Loss:  0.0001393566926708445\n",
      "################################  984  ################################\n",
      "Loss:  0.00013909352128393948\n",
      "################################  985  ################################\n",
      "Loss:  0.00013888758257962763\n",
      "################################  986  ################################\n",
      "Loss:  0.0001386785734212026\n",
      "################################  987  ################################\n",
      "Loss:  0.00013846461661159992\n",
      "################################  988  ################################\n",
      "Loss:  0.00013824919005855918\n",
      "################################  989  ################################\n",
      "Loss:  0.00013803504407405853\n",
      "################################  990  ################################\n",
      "Loss:  0.00013782463793177158\n",
      "################################  991  ################################\n",
      "Loss:  0.00013762066373601556\n",
      "################################  992  ################################\n",
      "Loss:  0.00013742412556894124\n",
      "################################  993  ################################\n",
      "Loss:  0.0001372278929920867\n",
      "################################  994  ################################\n",
      "Loss:  0.00013703815056942403\n",
      "################################  995  ################################\n",
      "Loss:  0.0001368490920867771\n",
      "################################  996  ################################\n",
      "Loss:  0.00013666266750078648\n",
      "################################  997  ################################\n",
      "Loss:  0.00013647084415424615\n",
      "################################  998  ################################\n",
      "Loss:  0.0001362790062557906\n",
      "################################  999  ################################\n",
      "Loss:  0.00013608395238406956\n",
      "################################  1000  ################################\n",
      "Loss:  0.0001358985755359754\n",
      "################################  1001  ################################\n",
      "Loss:  0.00013571089948527515\n",
      "################################  1002  ################################\n",
      "Loss:  0.00013550811854656786\n",
      "################################  1003  ################################\n",
      "Loss:  0.00013530091382563114\n",
      "################################  1004  ################################\n",
      "Loss:  0.00013507914263755083\n",
      "################################  1005  ################################\n",
      "Loss:  0.00013485259842127562\n",
      "################################  1006  ################################\n",
      "Loss:  0.0001346338540315628\n",
      "################################  1007  ################################\n",
      "Loss:  0.00013439261238090694\n",
      "################################  1008  ################################\n",
      "Loss:  0.00013418823073152453\n",
      "################################  1009  ################################\n",
      "Loss:  0.00013393533299677074\n",
      "################################  1010  ################################\n",
      "Loss:  0.000133633628138341\n",
      "################################  1011  ################################\n",
      "Loss:  0.00013331306399777532\n",
      "################################  1012  ################################\n",
      "Loss:  0.00013297138502821326\n",
      "################################  1013  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.00013261786079965532\n",
      "################################  1014  ################################\n",
      "Loss:  0.00013225359725765884\n",
      "################################  1015  ################################\n",
      "Loss:  0.0001318688300671056\n",
      "################################  1016  ################################\n",
      "Loss:  0.00013151626626495272\n",
      "################################  1017  ################################\n",
      "Loss:  0.00013113129534758627\n",
      "################################  1018  ################################\n",
      "Loss:  0.00013072750880382955\n",
      "################################  1019  ################################\n",
      "Loss:  0.00013026809028815478\n",
      "################################  1020  ################################\n",
      "Loss:  0.0001297628623433411\n",
      "################################  1021  ################################\n",
      "Loss:  0.00012922973837703466\n",
      "################################  1022  ################################\n",
      "Loss:  0.00012875572429038584\n",
      "################################  1023  ################################\n",
      "Loss:  0.00012829730985686183\n",
      "################################  1024  ################################\n",
      "Loss:  0.00012780196266248822\n",
      "################################  1025  ################################\n",
      "Loss:  0.00012732499453704804\n",
      "################################  1026  ################################\n",
      "Loss:  0.0001268422493012622\n",
      "################################  1027  ################################\n",
      "Loss:  0.00012643849186133593\n",
      "################################  1028  ################################\n",
      "Loss:  0.00012593208521138877\n",
      "################################  1029  ################################\n",
      "Loss:  0.00012554637214634567\n",
      "################################  1030  ################################\n",
      "Loss:  0.00012513832189142704\n",
      "################################  1031  ################################\n",
      "Loss:  0.0001247101608896628\n",
      "################################  1032  ################################\n",
      "Loss:  0.000124284066259861\n",
      "################################  1033  ################################\n",
      "Loss:  0.0001239319535670802\n",
      "################################  1034  ################################\n",
      "Loss:  0.00012357279774732888\n",
      "################################  1035  ################################\n",
      "Loss:  0.00012323239934630692\n",
      "################################  1036  ################################\n",
      "Loss:  0.00012289533333387226\n",
      "################################  1037  ################################\n",
      "Loss:  0.0001225379091920331\n",
      "################################  1038  ################################\n",
      "Loss:  0.00012217991752550006\n",
      "################################  1039  ################################\n",
      "Loss:  0.00012183365470264107\n",
      "################################  1040  ################################\n",
      "Loss:  0.00012149591202614829\n",
      "################################  1041  ################################\n",
      "Loss:  0.00012117932783439755\n",
      "################################  1042  ################################\n",
      "Loss:  0.0001208637622767128\n",
      "################################  1043  ################################\n",
      "Loss:  0.00012055823754053563\n",
      "################################  1044  ################################\n",
      "Loss:  0.00012026139302179217\n",
      "################################  1045  ################################\n",
      "Loss:  0.00011996570538030937\n",
      "################################  1046  ################################\n",
      "Loss:  0.00011968659237027168\n",
      "################################  1047  ################################\n",
      "Loss:  0.00011941434786422178\n",
      "################################  1048  ################################\n",
      "Loss:  0.00011915346840396523\n",
      "################################  1049  ################################\n",
      "Loss:  0.00011889776214957237\n",
      "################################  1050  ################################\n",
      "Loss:  0.000118640047730878\n",
      "################################  1051  ################################\n",
      "Loss:  0.00011838470527436584\n",
      "################################  1052  ################################\n",
      "Loss:  0.00011813717719633132\n",
      "################################  1053  ################################\n",
      "Loss:  0.0001179052924271673\n",
      "################################  1054  ################################\n",
      "Loss:  0.00011766998068196699\n",
      "################################  1055  ################################\n",
      "Loss:  0.00011742844799300656\n",
      "################################  1056  ################################\n",
      "Loss:  0.00011720664042513818\n",
      "################################  1057  ################################\n",
      "Loss:  0.00011697325680870563\n",
      "################################  1058  ################################\n",
      "Loss:  0.00011678483861032873\n",
      "################################  1059  ################################\n",
      "Loss:  0.00011656412243610248\n",
      "################################  1060  ################################\n",
      "Loss:  0.0001163030756288208\n",
      "################################  1061  ################################\n",
      "Loss:  0.00011601830192375928\n",
      "################################  1062  ################################\n",
      "Loss:  0.00011576538236113265\n",
      "################################  1063  ################################\n",
      "Loss:  0.00011541963613126427\n",
      "################################  1064  ################################\n",
      "Loss:  0.00011513468052726239\n",
      "################################  1065  ################################\n",
      "Loss:  0.00011481725232442841\n",
      "################################  1066  ################################\n",
      "Loss:  0.0001144470734288916\n",
      "################################  1067  ################################\n",
      "Loss:  0.00011412723688408732\n",
      "################################  1068  ################################\n",
      "Loss:  0.00011380483920220286\n",
      "################################  1069  ################################\n",
      "Loss:  0.00011343986261636019\n",
      "################################  1070  ################################\n",
      "Loss:  0.00011312394053675234\n",
      "################################  1071  ################################\n",
      "Loss:  0.00011282363993814215\n",
      "################################  1072  ################################\n",
      "Loss:  0.00011250963143538684\n",
      "################################  1073  ################################\n",
      "Loss:  0.00011223979527130723\n",
      "################################  1074  ################################\n",
      "Loss:  0.00011198377615073696\n",
      "################################  1075  ################################\n",
      "Loss:  0.00011172612721566111\n",
      "################################  1076  ################################\n",
      "Loss:  0.0001114712722483091\n",
      "################################  1077  ################################\n",
      "Loss:  0.00011124721640953794\n",
      "################################  1078  ################################\n",
      "Loss:  0.0001110472803702578\n",
      "################################  1079  ################################\n",
      "Loss:  0.00011085662117693573\n",
      "################################  1080  ################################\n",
      "Loss:  0.00011070511391153559\n",
      "################################  1081  ################################\n",
      "Loss:  0.00011056373477913439\n",
      "################################  1082  ################################\n",
      "Loss:  0.00011041015386581421\n",
      "################################  1083  ################################\n",
      "Loss:  0.00011028670996893197\n",
      "################################  1084  ################################\n",
      "Loss:  0.00011015842028427869\n",
      "################################  1085  ################################\n",
      "Loss:  0.00011003656254615635\n",
      "################################  1086  ################################\n",
      "Loss:  0.00010990889859385788\n",
      "################################  1087  ################################\n",
      "Loss:  0.00010978252248605713\n",
      "################################  1088  ################################\n",
      "Loss:  0.00010964228567900136\n",
      "################################  1089  ################################\n",
      "Loss:  0.00010947570262942463\n",
      "################################  1090  ################################\n",
      "Loss:  0.00010930046846624464\n",
      "################################  1091  ################################\n",
      "Loss:  0.0001091159792849794\n",
      "################################  1092  ################################\n",
      "Loss:  0.00010891853889916092\n",
      "################################  1093  ################################\n",
      "Loss:  0.00010871203267015517\n",
      "################################  1094  ################################\n",
      "Loss:  0.00010848486272152513\n",
      "################################  1095  ################################\n",
      "Loss:  0.00010825111530721188\n",
      "################################  1096  ################################\n",
      "Loss:  0.00010800009476952255\n",
      "################################  1097  ################################\n",
      "Loss:  0.00010772427049232647\n",
      "################################  1098  ################################\n",
      "Loss:  0.00010742514859884977\n",
      "################################  1099  ################################\n",
      "Loss:  0.00010713044321164489\n",
      "################################  1100  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0001068267083610408\n",
      "################################  1101  ################################\n",
      "Loss:  0.00010650924377841875\n",
      "################################  1102  ################################\n",
      "Loss:  0.00010619292152114213\n",
      "################################  1103  ################################\n",
      "Loss:  0.00010585128620732576\n",
      "################################  1104  ################################\n",
      "Loss:  0.00010549958824412897\n",
      "################################  1105  ################################\n",
      "Loss:  0.0001051663130056113\n",
      "################################  1106  ################################\n",
      "Loss:  0.00010482801008038223\n",
      "################################  1107  ################################\n",
      "Loss:  0.00010450267291162163\n",
      "################################  1108  ################################\n",
      "Loss:  0.00010417302837595344\n",
      "################################  1109  ################################\n",
      "Loss:  0.0001038272021105513\n",
      "################################  1110  ################################\n",
      "Loss:  0.00010348445357521996\n",
      "################################  1111  ################################\n",
      "Loss:  0.00010318501881556585\n",
      "################################  1112  ################################\n",
      "Loss:  0.00010289972124155611\n",
      "################################  1113  ################################\n",
      "Loss:  0.0001026266545522958\n",
      "################################  1114  ################################\n",
      "Loss:  0.00010236480738967657\n",
      "################################  1115  ################################\n",
      "Loss:  0.00010210279288003221\n",
      "################################  1116  ################################\n",
      "Loss:  0.00010184568236581981\n",
      "################################  1117  ################################\n",
      "Loss:  0.00010159591329284012\n",
      "################################  1118  ################################\n",
      "Loss:  0.00010134598414879292\n",
      "################################  1119  ################################\n",
      "Loss:  0.00010112737072631717\n",
      "################################  1120  ################################\n",
      "Loss:  0.0001009222905850038\n",
      "################################  1121  ################################\n",
      "Loss:  0.00010071185533888638\n",
      "################################  1122  ################################\n",
      "Loss:  0.00010050705168396235\n",
      "################################  1123  ################################\n",
      "Loss:  0.00010032385762315243\n",
      "################################  1124  ################################\n",
      "Loss:  0.00010014976578531787\n",
      "################################  1125  ################################\n",
      "Loss:  9.996695735026151e-05\n",
      "################################  1126  ################################\n",
      "Loss:  9.977508307201788e-05\n",
      "################################  1127  ################################\n",
      "Loss:  9.959676390280947e-05\n",
      "################################  1128  ################################\n",
      "Loss:  9.942275937646627e-05\n",
      "################################  1129  ################################\n",
      "Loss:  9.926126222126186e-05\n",
      "################################  1130  ################################\n",
      "Loss:  9.90896878647618e-05\n",
      "################################  1131  ################################\n",
      "Loss:  9.890686487779021e-05\n",
      "################################  1132  ################################\n",
      "Loss:  9.871846123132855e-05\n",
      "################################  1133  ################################\n",
      "Loss:  9.852501534624025e-05\n",
      "################################  1134  ################################\n",
      "Loss:  9.83316422207281e-05\n",
      "################################  1135  ################################\n",
      "Loss:  9.813038923311979e-05\n",
      "################################  1136  ################################\n",
      "Loss:  9.791961929295212e-05\n",
      "################################  1137  ################################\n",
      "Loss:  9.771280747372657e-05\n",
      "################################  1138  ################################\n",
      "Loss:  9.748601587489247e-05\n",
      "################################  1139  ################################\n",
      "Loss:  9.725057316245511e-05\n",
      "################################  1140  ################################\n",
      "Loss:  9.700061491457745e-05\n",
      "################################  1141  ################################\n",
      "Loss:  9.673969179857522e-05\n",
      "################################  1142  ################################\n",
      "Loss:  9.64784121606499e-05\n",
      "################################  1143  ################################\n",
      "Loss:  9.618900367058814e-05\n",
      "################################  1144  ################################\n",
      "Loss:  9.589579713065177e-05\n",
      "################################  1145  ################################\n",
      "Loss:  9.560411126585677e-05\n",
      "################################  1146  ################################\n",
      "Loss:  9.52979244175367e-05\n",
      "################################  1147  ################################\n",
      "Loss:  9.499935549683869e-05\n",
      "################################  1148  ################################\n",
      "Loss:  9.468557254876941e-05\n",
      "################################  1149  ################################\n",
      "Loss:  9.437745029572397e-05\n",
      "################################  1150  ################################\n",
      "Loss:  9.405292803421617e-05\n",
      "################################  1151  ################################\n",
      "Loss:  9.372671047458425e-05\n",
      "################################  1152  ################################\n",
      "Loss:  9.339342068415135e-05\n",
      "################################  1153  ################################\n",
      "Loss:  9.300106466980651e-05\n",
      "################################  1154  ################################\n",
      "Loss:  9.26431966945529e-05\n",
      "################################  1155  ################################\n",
      "Loss:  9.228360431734473e-05\n",
      "################################  1156  ################################\n",
      "Loss:  9.194519225275144e-05\n",
      "################################  1157  ################################\n",
      "Loss:  9.162382048089057e-05\n",
      "################################  1158  ################################\n",
      "Loss:  9.129867248702794e-05\n",
      "################################  1159  ################################\n",
      "Loss:  9.099459566641599e-05\n",
      "################################  1160  ################################\n",
      "Loss:  9.073529508896172e-05\n",
      "################################  1161  ################################\n",
      "Loss:  9.048423089552671e-05\n",
      "################################  1162  ################################\n",
      "Loss:  9.026439511217177e-05\n",
      "################################  1163  ################################\n",
      "Loss:  9.006250184029341e-05\n",
      "################################  1164  ################################\n",
      "Loss:  8.988090849015862e-05\n",
      "################################  1165  ################################\n",
      "Loss:  8.970985072664917e-05\n",
      "################################  1166  ################################\n",
      "Loss:  8.956117380876094e-05\n",
      "################################  1167  ################################\n",
      "Loss:  8.942869317252189e-05\n",
      "################################  1168  ################################\n",
      "Loss:  8.92922980710864e-05\n",
      "################################  1169  ################################\n",
      "Loss:  8.9181077782996e-05\n",
      "################################  1170  ################################\n",
      "Loss:  8.907953451853245e-05\n",
      "################################  1171  ################################\n",
      "Loss:  8.89829098014161e-05\n",
      "################################  1172  ################################\n",
      "Loss:  8.88881622813642e-05\n",
      "################################  1173  ################################\n",
      "Loss:  8.879480446921661e-05\n",
      "################################  1174  ################################\n",
      "Loss:  8.870966848917305e-05\n",
      "################################  1175  ################################\n",
      "Loss:  8.86271009221673e-05\n",
      "################################  1176  ################################\n",
      "Loss:  8.854316547513008e-05\n",
      "################################  1177  ################################\n",
      "Loss:  8.84639157447964e-05\n",
      "################################  1178  ################################\n",
      "Loss:  8.838259964250028e-05\n",
      "################################  1179  ################################\n",
      "Loss:  8.830115257296711e-05\n",
      "################################  1180  ################################\n",
      "Loss:  8.822095696814358e-05\n",
      "################################  1181  ################################\n",
      "Loss:  8.814097964204848e-05\n",
      "################################  1182  ################################\n",
      "Loss:  8.806803089100868e-05\n",
      "################################  1183  ################################\n",
      "Loss:  8.799135684967041e-05\n",
      "################################  1184  ################################\n",
      "Loss:  8.791816071607172e-05\n",
      "################################  1185  ################################\n",
      "Loss:  8.783888188190758e-05\n",
      "################################  1186  ################################\n",
      "Loss:  8.774135494604707e-05\n",
      "################################  1187  ################################\n",
      "Loss:  8.763742516748607e-05\n",
      "################################  1188  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  8.75531550263986e-05\n",
      "################################  1189  ################################\n",
      "Loss:  8.746339881327003e-05\n",
      "################################  1190  ################################\n",
      "Loss:  8.736448944546282e-05\n",
      "################################  1191  ################################\n",
      "Loss:  8.725948282517493e-05\n",
      "################################  1192  ################################\n",
      "Loss:  8.71486627147533e-05\n",
      "################################  1193  ################################\n",
      "Loss:  8.703363710083067e-05\n",
      "################################  1194  ################################\n",
      "Loss:  8.691721450304613e-05\n",
      "################################  1195  ################################\n",
      "Loss:  8.67960843606852e-05\n",
      "################################  1196  ################################\n",
      "Loss:  8.667890506330878e-05\n",
      "################################  1197  ################################\n",
      "Loss:  8.656040881760418e-05\n",
      "################################  1198  ################################\n",
      "Loss:  8.644280023872852e-05\n",
      "################################  1199  ################################\n",
      "Loss:  8.632325625512749e-05\n",
      "################################  1200  ################################\n",
      "Loss:  8.62117885844782e-05\n",
      "################################  1201  ################################\n",
      "Loss:  8.609671203885227e-05\n",
      "################################  1202  ################################\n",
      "Loss:  8.59860228956677e-05\n",
      "################################  1203  ################################\n",
      "Loss:  8.588242053519934e-05\n",
      "################################  1204  ################################\n",
      "Loss:  8.577713742852211e-05\n",
      "################################  1205  ################################\n",
      "Loss:  8.567045733798295e-05\n",
      "################################  1206  ################################\n",
      "Loss:  8.55637263157405e-05\n",
      "################################  1207  ################################\n",
      "Loss:  8.546300523448735e-05\n",
      "################################  1208  ################################\n",
      "Loss:  8.536732639186084e-05\n",
      "################################  1209  ################################\n",
      "Loss:  8.527877071173862e-05\n",
      "################################  1210  ################################\n",
      "Loss:  8.519492257619277e-05\n",
      "################################  1211  ################################\n",
      "Loss:  8.511003397870809e-05\n",
      "################################  1212  ################################\n",
      "Loss:  8.502643322572112e-05\n",
      "################################  1213  ################################\n",
      "Loss:  8.494325447827578e-05\n",
      "################################  1214  ################################\n",
      "Loss:  8.486455772072077e-05\n",
      "################################  1215  ################################\n",
      "Loss:  8.478569361614063e-05\n",
      "################################  1216  ################################\n",
      "Loss:  8.471161709167063e-05\n",
      "################################  1217  ################################\n",
      "Loss:  8.463615085929632e-05\n",
      "################################  1218  ################################\n",
      "Loss:  8.455902570858598e-05\n",
      "################################  1219  ################################\n",
      "Loss:  8.447596337646246e-05\n",
      "################################  1220  ################################\n",
      "Loss:  8.439942757831886e-05\n",
      "################################  1221  ################################\n",
      "Loss:  8.431675814790651e-05\n",
      "################################  1222  ################################\n",
      "Loss:  8.421950042247772e-05\n",
      "################################  1223  ################################\n",
      "Loss:  8.411741873715073e-05\n",
      "################################  1224  ################################\n",
      "Loss:  8.401228114962578e-05\n",
      "################################  1225  ################################\n",
      "Loss:  8.391014853259549e-05\n",
      "################################  1226  ################################\n",
      "Loss:  8.38013511383906e-05\n",
      "################################  1227  ################################\n",
      "Loss:  8.369532588403672e-05\n",
      "################################  1228  ################################\n",
      "Loss:  8.35854298202321e-05\n",
      "################################  1229  ################################\n",
      "Loss:  8.346029790118337e-05\n",
      "################################  1230  ################################\n",
      "Loss:  8.334287849720567e-05\n",
      "################################  1231  ################################\n",
      "Loss:  8.321668428834528e-05\n",
      "################################  1232  ################################\n",
      "Loss:  8.309954137075692e-05\n",
      "################################  1233  ################################\n",
      "Loss:  8.297136810142547e-05\n",
      "################################  1234  ################################\n",
      "Loss:  8.283983333967626e-05\n",
      "################################  1235  ################################\n",
      "Loss:  8.270634134532884e-05\n",
      "################################  1236  ################################\n",
      "Loss:  8.25507304398343e-05\n",
      "################################  1237  ################################\n",
      "Loss:  8.240420720539987e-05\n",
      "################################  1238  ################################\n",
      "Loss:  8.225413330364972e-05\n",
      "################################  1239  ################################\n",
      "Loss:  8.209251973312348e-05\n",
      "################################  1240  ################################\n",
      "Loss:  8.193469693651423e-05\n",
      "################################  1241  ################################\n",
      "Loss:  8.177544077625498e-05\n",
      "################################  1242  ################################\n",
      "Loss:  8.16207320895046e-05\n",
      "################################  1243  ################################\n",
      "Loss:  8.147044718498364e-05\n",
      "################################  1244  ################################\n",
      "Loss:  8.132233051583171e-05\n",
      "################################  1245  ################################\n",
      "Loss:  8.118318510241807e-05\n",
      "################################  1246  ################################\n",
      "Loss:  8.104406879283488e-05\n",
      "################################  1247  ################################\n",
      "Loss:  8.090728078968823e-05\n",
      "################################  1248  ################################\n",
      "Loss:  8.077740494627506e-05\n",
      "################################  1249  ################################\n",
      "Loss:  8.064052963163704e-05\n",
      "################################  1250  ################################\n",
      "Loss:  8.051823533605784e-05\n",
      "################################  1251  ################################\n",
      "Loss:  8.038639498408884e-05\n",
      "################################  1252  ################################\n",
      "Loss:  8.026543946471065e-05\n",
      "################################  1253  ################################\n",
      "Loss:  8.014046761672944e-05\n",
      "################################  1254  ################################\n",
      "Loss:  7.996235945029184e-05\n",
      "################################  1255  ################################\n",
      "Loss:  7.981740054674447e-05\n",
      "################################  1256  ################################\n",
      "Loss:  7.961276423884556e-05\n",
      "################################  1257  ################################\n",
      "Loss:  7.943475793581456e-05\n",
      "################################  1258  ################################\n",
      "Loss:  7.920671487227082e-05\n",
      "################################  1259  ################################\n",
      "Loss:  7.895915769040585e-05\n",
      "################################  1260  ################################\n",
      "Loss:  7.868799002608284e-05\n",
      "################################  1261  ################################\n",
      "Loss:  7.842206105124205e-05\n",
      "################################  1262  ################################\n",
      "Loss:  7.812828698661178e-05\n",
      "################################  1263  ################################\n",
      "Loss:  7.788419316057116e-05\n",
      "################################  1264  ################################\n",
      "Loss:  7.763337634969503e-05\n",
      "################################  1265  ################################\n",
      "Loss:  7.736952102277428e-05\n",
      "################################  1266  ################################\n",
      "Loss:  7.709958299528807e-05\n",
      "################################  1267  ################################\n",
      "Loss:  7.688103505643085e-05\n",
      "################################  1268  ################################\n",
      "Loss:  7.668318721698597e-05\n",
      "################################  1269  ################################\n",
      "Loss:  7.64947835705243e-05\n",
      "################################  1270  ################################\n",
      "Loss:  7.630486652487889e-05\n",
      "################################  1271  ################################\n",
      "Loss:  7.616095535922796e-05\n",
      "################################  1272  ################################\n",
      "Loss:  7.60259063099511e-05\n",
      "################################  1273  ################################\n",
      "Loss:  7.589888264192268e-05\n",
      "################################  1274  ################################\n",
      "Loss:  7.578627992188558e-05\n",
      "################################  1275  ################################\n",
      "Loss:  7.567859574919567e-05\n",
      "################################  1276  ################################\n",
      "Loss:  7.558439392596483e-05\n",
      "################################  1277  ################################\n",
      "Loss:  7.549527799710631e-05\n",
      "################################  1278  ################################\n",
      "Loss:  7.541128434240818e-05\n",
      "################################  1279  ################################\n",
      "Loss:  7.53294734749943e-05\n",
      "################################  1280  ################################\n",
      "Loss:  7.52491905586794e-05\n",
      "################################  1281  ################################\n",
      "Loss:  7.517133781220764e-05\n",
      "################################  1282  ################################\n",
      "Loss:  7.509213901357725e-05\n",
      "################################  1283  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  7.50206527300179e-05\n",
      "################################  1284  ################################\n",
      "Loss:  7.493823068216443e-05\n",
      "################################  1285  ################################\n",
      "Loss:  7.485588866984472e-05\n",
      "################################  1286  ################################\n",
      "Loss:  7.472002471331507e-05\n",
      "################################  1287  ################################\n",
      "Loss:  7.460828055627644e-05\n",
      "################################  1288  ################################\n",
      "Loss:  7.445401570294052e-05\n",
      "################################  1289  ################################\n",
      "Loss:  7.427939272020012e-05\n",
      "################################  1290  ################################\n",
      "Loss:  7.407903467537835e-05\n",
      "################################  1291  ################################\n",
      "Loss:  7.38819144316949e-05\n",
      "################################  1292  ################################\n",
      "Loss:  7.365935744019225e-05\n",
      "################################  1293  ################################\n",
      "Loss:  7.343995093833655e-05\n",
      "################################  1294  ################################\n",
      "Loss:  7.323511090362445e-05\n",
      "################################  1295  ################################\n",
      "Loss:  7.304339669644833e-05\n",
      "################################  1296  ################################\n",
      "Loss:  7.286061008926481e-05\n",
      "################################  1297  ################################\n",
      "Loss:  7.269580964930356e-05\n",
      "################################  1298  ################################\n",
      "Loss:  7.25465506548062e-05\n",
      "################################  1299  ################################\n",
      "Loss:  7.241321145556867e-05\n",
      "################################  1300  ################################\n",
      "Loss:  7.228941831272095e-05\n",
      "################################  1301  ################################\n",
      "Loss:  7.217998791020364e-05\n",
      "################################  1302  ################################\n",
      "Loss:  7.207962335087359e-05\n",
      "################################  1303  ################################\n",
      "Loss:  7.199036190286279e-05\n",
      "################################  1304  ################################\n",
      "Loss:  7.191573968157172e-05\n",
      "################################  1305  ################################\n",
      "Loss:  7.183512934716418e-05\n",
      "################################  1306  ################################\n",
      "Loss:  7.176776125561446e-05\n",
      "################################  1307  ################################\n",
      "Loss:  7.169730088207871e-05\n",
      "################################  1308  ################################\n",
      "Loss:  7.161707617342472e-05\n",
      "################################  1309  ################################\n",
      "Loss:  7.153641490731388e-05\n",
      "################################  1310  ################################\n",
      "Loss:  7.145029667299241e-05\n",
      "################################  1311  ################################\n",
      "Loss:  7.136478234315291e-05\n",
      "################################  1312  ################################\n",
      "Loss:  7.12825421942398e-05\n",
      "################################  1313  ################################\n",
      "Loss:  7.120454392861575e-05\n",
      "################################  1314  ################################\n",
      "Loss:  7.111892045941204e-05\n",
      "################################  1315  ################################\n",
      "Loss:  7.103149255272001e-05\n",
      "################################  1316  ################################\n",
      "Loss:  7.093270687619224e-05\n",
      "################################  1317  ################################\n",
      "Loss:  7.081232615746558e-05\n",
      "################################  1318  ################################\n",
      "Loss:  7.06813734723255e-05\n",
      "################################  1319  ################################\n",
      "Loss:  7.055106107145548e-05\n",
      "################################  1320  ################################\n",
      "Loss:  7.042030483717099e-05\n",
      "################################  1321  ################################\n",
      "Loss:  7.0285597757902e-05\n",
      "################################  1322  ################################\n",
      "Loss:  7.015131996013224e-05\n",
      "################################  1323  ################################\n",
      "Loss:  7.001841731835157e-05\n",
      "################################  1324  ################################\n",
      "Loss:  6.988902896409854e-05\n",
      "################################  1325  ################################\n",
      "Loss:  6.976351869525388e-05\n",
      "################################  1326  ################################\n",
      "Loss:  6.964386557228863e-05\n",
      "################################  1327  ################################\n",
      "Loss:  6.952654803171754e-05\n",
      "################################  1328  ################################\n",
      "Loss:  6.941647734493017e-05\n",
      "################################  1329  ################################\n",
      "Loss:  6.931560346856713e-05\n",
      "################################  1330  ################################\n",
      "Loss:  6.921459862496704e-05\n",
      "################################  1331  ################################\n",
      "Loss:  6.912312528584152e-05\n",
      "################################  1332  ################################\n",
      "Loss:  6.903314351802692e-05\n",
      "################################  1333  ################################\n",
      "Loss:  6.895062688272446e-05\n",
      "################################  1334  ################################\n",
      "Loss:  6.887577910674736e-05\n",
      "################################  1335  ################################\n",
      "Loss:  6.879912689328194e-05\n",
      "################################  1336  ################################\n",
      "Loss:  6.873368693049997e-05\n",
      "################################  1337  ################################\n",
      "Loss:  6.867085176054388e-05\n",
      "################################  1338  ################################\n",
      "Loss:  6.861017754999921e-05\n",
      "################################  1339  ################################\n",
      "Loss:  6.855555693618953e-05\n",
      "################################  1340  ################################\n",
      "Loss:  6.849956116639078e-05\n",
      "################################  1341  ################################\n",
      "Loss:  6.845002644695342e-05\n",
      "################################  1342  ################################\n",
      "Loss:  6.839974957983941e-05\n",
      "################################  1343  ################################\n",
      "Loss:  6.83484468027018e-05\n",
      "################################  1344  ################################\n",
      "Loss:  6.829685298725963e-05\n",
      "################################  1345  ################################\n",
      "Loss:  6.82458485243842e-05\n",
      "################################  1346  ################################\n",
      "Loss:  6.81918318150565e-05\n",
      "################################  1347  ################################\n",
      "Loss:  6.813670916017145e-05\n",
      "################################  1348  ################################\n",
      "Loss:  6.807941099395975e-05\n",
      "################################  1349  ################################\n",
      "Loss:  6.802330608479679e-05\n",
      "################################  1350  ################################\n",
      "Loss:  6.796422530896962e-05\n",
      "################################  1351  ################################\n",
      "Loss:  6.790948827983811e-05\n",
      "################################  1352  ################################\n",
      "Loss:  6.785259756725281e-05\n",
      "################################  1353  ################################\n",
      "Loss:  6.779938121326268e-05\n",
      "################################  1354  ################################\n",
      "Loss:  6.774230860173702e-05\n",
      "################################  1355  ################################\n",
      "Loss:  6.768193270545453e-05\n",
      "################################  1356  ################################\n",
      "Loss:  6.76179988658987e-05\n",
      "################################  1357  ################################\n",
      "Loss:  6.756147195119411e-05\n",
      "################################  1358  ################################\n",
      "Loss:  6.750784814357758e-05\n",
      "################################  1359  ################################\n",
      "Loss:  6.744716665707529e-05\n",
      "################################  1360  ################################\n",
      "Loss:  6.738408410456032e-05\n",
      "################################  1361  ################################\n",
      "Loss:  6.732020119670779e-05\n",
      "################################  1362  ################################\n",
      "Loss:  6.724169361405075e-05\n",
      "################################  1363  ################################\n",
      "Loss:  6.716493226122111e-05\n",
      "################################  1364  ################################\n",
      "Loss:  6.70884910505265e-05\n",
      "################################  1365  ################################\n",
      "Loss:  6.702182872686535e-05\n",
      "################################  1366  ################################\n",
      "Loss:  6.694778858218342e-05\n",
      "################################  1367  ################################\n",
      "Loss:  6.686581764370203e-05\n",
      "################################  1368  ################################\n",
      "Loss:  6.677681813016534e-05\n",
      "################################  1369  ################################\n",
      "Loss:  6.668046989943832e-05\n",
      "################################  1370  ################################\n",
      "Loss:  6.657715130131692e-05\n",
      "################################  1371  ################################\n",
      "Loss:  6.646530528087169e-05\n",
      "################################  1372  ################################\n",
      "Loss:  6.635423778789118e-05\n",
      "################################  1373  ################################\n",
      "Loss:  6.624456000281498e-05\n",
      "################################  1374  ################################\n",
      "Loss:  6.613081495743245e-05\n",
      "################################  1375  ################################\n",
      "Loss:  6.601642962777987e-05\n",
      "################################  1376  ################################\n",
      "Loss:  6.590217526536435e-05\n",
      "################################  1377  ################################\n",
      "Loss:  6.579150795005262e-05\n",
      "################################  1378  ################################\n",
      "Loss:  6.568195385625586e-05\n",
      "################################  1379  ################################\n",
      "Loss:  6.557400047313422e-05\n",
      "################################  1380  ################################\n",
      "Loss:  6.546957592945546e-05\n",
      "################################  1381  ################################\n",
      "Loss:  6.53653041808866e-05\n",
      "################################  1382  ################################\n",
      "Loss:  6.526356446556747e-05\n",
      "################################  1383  ################################\n",
      "Loss:  6.516174471471459e-05\n",
      "################################  1384  ################################\n",
      "Loss:  6.505953206215054e-05\n",
      "################################  1385  ################################\n",
      "Loss:  6.496807327494025e-05\n",
      "################################  1386  ################################\n",
      "Loss:  6.488279905170202e-05\n",
      "################################  1387  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  6.479882722487673e-05\n",
      "################################  1388  ################################\n",
      "Loss:  6.470940570579842e-05\n",
      "################################  1389  ################################\n",
      "Loss:  6.457975541707128e-05\n",
      "################################  1390  ################################\n",
      "Loss:  6.451233639381826e-05\n",
      "################################  1391  ################################\n",
      "Loss:  6.444421160267666e-05\n",
      "################################  1392  ################################\n",
      "Loss:  6.436671537812799e-05\n",
      "################################  1393  ################################\n",
      "Loss:  6.427206244552508e-05\n",
      "################################  1394  ################################\n",
      "Loss:  6.419391138479114e-05\n",
      "################################  1395  ################################\n",
      "Loss:  6.410706555470824e-05\n",
      "################################  1396  ################################\n",
      "Loss:  6.400556594599038e-05\n",
      "################################  1397  ################################\n",
      "Loss:  6.392619252437726e-05\n",
      "################################  1398  ################################\n",
      "Loss:  6.384005246218294e-05\n",
      "################################  1399  ################################\n",
      "Loss:  6.375261000357568e-05\n",
      "################################  1400  ################################\n",
      "Loss:  6.365911394823343e-05\n",
      "################################  1401  ################################\n",
      "Loss:  6.354590732371435e-05\n",
      "################################  1402  ################################\n",
      "Loss:  6.343789573293179e-05\n",
      "################################  1403  ################################\n",
      "Loss:  6.332636985462159e-05\n",
      "################################  1404  ################################\n",
      "Loss:  6.321584805846214e-05\n",
      "################################  1405  ################################\n",
      "Loss:  6.31059956504032e-05\n",
      "################################  1406  ################################\n",
      "Loss:  6.299085362115875e-05\n",
      "################################  1407  ################################\n",
      "Loss:  6.288501754170284e-05\n",
      "################################  1408  ################################\n",
      "Loss:  6.27807094133459e-05\n",
      "################################  1409  ################################\n",
      "Loss:  6.267659773584455e-05\n",
      "################################  1410  ################################\n",
      "Loss:  6.25739703536965e-05\n",
      "################################  1411  ################################\n",
      "Loss:  6.247132841963321e-05\n",
      "################################  1412  ################################\n",
      "Loss:  6.237486377358437e-05\n",
      "################################  1413  ################################\n",
      "Loss:  6.228037091204897e-05\n",
      "################################  1414  ################################\n",
      "Loss:  6.218632915988564e-05\n",
      "################################  1415  ################################\n",
      "Loss:  6.208661216078326e-05\n",
      "################################  1416  ################################\n",
      "Loss:  6.19904458289966e-05\n",
      "################################  1417  ################################\n",
      "Loss:  6.189550913404673e-05\n",
      "################################  1418  ################################\n",
      "Loss:  6.179089541547e-05\n",
      "################################  1419  ################################\n",
      "Loss:  6.168669642647728e-05\n",
      "################################  1420  ################################\n",
      "Loss:  6.157819007057697e-05\n",
      "################################  1421  ################################\n",
      "Loss:  6.14691962255165e-05\n",
      "################################  1422  ################################\n",
      "Loss:  6.136586307547987e-05\n",
      "################################  1423  ################################\n",
      "Loss:  6.125732761574909e-05\n",
      "################################  1424  ################################\n",
      "Loss:  6.115723954280838e-05\n",
      "################################  1425  ################################\n",
      "Loss:  6.105300417402759e-05\n",
      "################################  1426  ################################\n",
      "Loss:  6.094442869652994e-05\n",
      "################################  1427  ################################\n",
      "Loss:  6.083268817747012e-05\n",
      "################################  1428  ################################\n",
      "Loss:  6.070919334888458e-05\n",
      "################################  1429  ################################\n",
      "Loss:  6.058256985852495e-05\n",
      "################################  1430  ################################\n",
      "Loss:  6.0455371567513794e-05\n",
      "################################  1431  ################################\n",
      "Loss:  6.033063618815504e-05\n",
      "################################  1432  ################################\n",
      "Loss:  6.0207341448403895e-05\n",
      "################################  1433  ################################\n",
      "Loss:  6.0089543694630265e-05\n",
      "################################  1434  ################################\n",
      "Loss:  5.996997788315639e-05\n",
      "################################  1435  ################################\n",
      "Loss:  5.986075848340988e-05\n",
      "################################  1436  ################################\n",
      "Loss:  5.97545804339461e-05\n",
      "################################  1437  ################################\n",
      "Loss:  5.964561569271609e-05\n",
      "################################  1438  ################################\n",
      "Loss:  5.954641164862551e-05\n",
      "################################  1439  ################################\n",
      "Loss:  5.9442576457513496e-05\n",
      "################################  1440  ################################\n",
      "Loss:  5.935225999564864e-05\n",
      "################################  1441  ################################\n",
      "Loss:  5.926134326728061e-05\n",
      "################################  1442  ################################\n",
      "Loss:  5.9159800002817065e-05\n",
      "################################  1443  ################################\n",
      "Loss:  5.906602382310666e-05\n",
      "################################  1444  ################################\n",
      "Loss:  5.897434311918914e-05\n",
      "################################  1445  ################################\n",
      "Loss:  5.889028398087248e-05\n",
      "################################  1446  ################################\n",
      "Loss:  5.8803467254620045e-05\n",
      "################################  1447  ################################\n",
      "Loss:  5.871871326235123e-05\n",
      "################################  1448  ################################\n",
      "Loss:  5.863214755663648e-05\n",
      "################################  1449  ################################\n",
      "Loss:  5.853858237969689e-05\n",
      "################################  1450  ################################\n",
      "Loss:  5.844524275744334e-05\n",
      "################################  1451  ################################\n",
      "Loss:  5.835068441228941e-05\n",
      "################################  1452  ################################\n",
      "Loss:  5.826217238791287e-05\n",
      "################################  1453  ################################\n",
      "Loss:  5.817009514430538e-05\n",
      "################################  1454  ################################\n",
      "Loss:  5.808816058561206e-05\n",
      "################################  1455  ################################\n",
      "Loss:  5.800552025903016e-05\n",
      "################################  1456  ################################\n",
      "Loss:  5.7917455706046894e-05\n",
      "################################  1457  ################################\n",
      "Loss:  5.782812513643876e-05\n",
      "################################  1458  ################################\n",
      "Loss:  5.7744917285162956e-05\n",
      "################################  1459  ################################\n",
      "Loss:  5.7664787163957953e-05\n",
      "################################  1460  ################################\n",
      "Loss:  5.7576173276174814e-05\n",
      "################################  1461  ################################\n",
      "Loss:  5.749892443418503e-05\n",
      "################################  1462  ################################\n",
      "Loss:  5.7414115872234106e-05\n",
      "################################  1463  ################################\n",
      "Loss:  5.731493729399517e-05\n",
      "################################  1464  ################################\n",
      "Loss:  5.720440822187811e-05\n",
      "################################  1465  ################################\n",
      "Loss:  5.709763354388997e-05\n",
      "################################  1466  ################################\n",
      "Loss:  5.6976390624186024e-05\n",
      "################################  1467  ################################\n",
      "Loss:  5.688800956704654e-05\n",
      "################################  1468  ################################\n",
      "Loss:  5.6796874559950083e-05\n",
      "################################  1469  ################################\n",
      "Loss:  5.6691758800297976e-05\n",
      "################################  1470  ################################\n",
      "Loss:  5.657093061017804e-05\n",
      "################################  1471  ################################\n",
      "Loss:  5.643128679366782e-05\n",
      "################################  1472  ################################\n",
      "Loss:  5.6304728786926717e-05\n",
      "################################  1473  ################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.61654451303184e-05\n",
      "################################  1474  ################################\n",
      "Loss:  5.6012082495726645e-05\n",
      "################################  1475  ################################\n",
      "Loss:  5.584493919741362e-05\n",
      "################################  1476  ################################\n",
      "Loss:  5.569527274928987e-05\n",
      "################################  1477  ################################\n",
      "Loss:  5.5536678701173514e-05\n",
      "################################  1478  ################################\n",
      "Loss:  5.536368189495988e-05\n",
      "################################  1479  ################################\n",
      "Loss:  5.519492697203532e-05\n",
      "################################  1480  ################################\n",
      "Loss:  5.503667489392683e-05\n",
      "################################  1481  ################################\n",
      "Loss:  5.488972965395078e-05\n",
      "################################  1482  ################################\n",
      "Loss:  5.474544741446152e-05\n",
      "################################  1483  ################################\n",
      "Loss:  5.461665568873286e-05\n",
      "################################  1484  ################################\n",
      "Loss:  5.4495678341481835e-05\n",
      "################################  1485  ################################\n",
      "Loss:  5.438584412331693e-05\n",
      "################################  1486  ################################\n",
      "Loss:  5.428139411378652e-05\n",
      "################################  1487  ################################\n",
      "Loss:  5.419136869022623e-05\n",
      "################################  1488  ################################\n",
      "Loss:  5.411291203927249e-05\n",
      "################################  1489  ################################\n",
      "Loss:  5.4030217143008485e-05\n",
      "################################  1490  ################################\n",
      "Loss:  5.3957577620167285e-05\n",
      "################################  1491  ################################\n",
      "Loss:  5.388291538110934e-05\n",
      "################################  1492  ################################\n",
      "Loss:  5.37901978532318e-05\n",
      "################################  1493  ################################\n",
      "Loss:  5.371352017391473e-05\n",
      "################################  1494  ################################\n",
      "Loss:  5.363659875001758e-05\n",
      "################################  1495  ################################\n",
      "Loss:  5.356323890737258e-05\n",
      "################################  1496  ################################\n",
      "Loss:  5.3484087402466685e-05\n",
      "################################  1497  ################################\n",
      "Loss:  5.338999835657887e-05\n",
      "################################  1498  ################################\n",
      "Loss:  5.329161649569869e-05\n",
      "################################  1499  ################################\n",
      "Loss:  5.319423507899046e-05\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1500\n",
    "history = fit(my_network, training_set, interior, n_epochs, optimizer_, p=2, verbose=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading Model\n",
    "FILE = \"maxwell2D_3.pth\"\n",
    "torch.save(my_network, FILE)\n",
    "\n",
    "# uncomment below when you need to test for different points\n",
    "#my_network = torch.load(FILE)\n",
    "#my_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading Model (this model with reported results)\n",
    "#FILE = \"second.pth\"\n",
    "#torch.save(my_network, FILE)\n",
    "\n",
    "# uncomment below when you need to test for different points\n",
    "#my_network = torch.load(FILE)\n",
    "#my_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.linspace(0, 1, 10000).reshape(-1,1)\n",
    "y_test = torch.linspace(0, 1, 10000).reshape(-1,1)\n",
    "t_test = torch.ones((10000,1))\n",
    "test = torch.cat([x_test, y_test, t_test],1)\n",
    "h_test = exact_solution_h(x_test, y_test, t_test).reshape(-1,1)\n",
    "e1_test = exact_solution_e1(x_test, y_test, t_test).reshape(-1,1)\n",
    "e2_test = exact_solution_e2(x_test, y_test, t_test).reshape(-1,1)\n",
    "w_test_pred = my_network(test)\n",
    "h_test_pred = w_test_pred[:,0].reshape(-1,1)\n",
    "e1_test_pred = w_test_pred[:,1].reshape(-1,1)\n",
    "e2_test_pred = w_test_pred[:,2].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6bc0570610>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(x_test, h_test, label=\"Ground Truth\",lw=2)\n",
    "plt.plot(x_test, h_test_pred.detach(), label=\"Network Prediction\",lw=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"u\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Error Test:  0.004095898475497961 %\n"
     ]
    }
   ],
   "source": [
    "# Compute the relative L2 error norm (generalization error)\n",
    "relative_error_test = torch.mean((h_test_pred - h_test)**2)/torch.mean(h_test**2)\n",
    "#relative_error_test = torch.max(torch.abs(u_test_pred -u_test))/torch.max(torch.abs(u_test))\n",
    "print(\"Relative Error Test: \", relative_error_test.detach().numpy()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6bca15e940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(x_test, e1_test, label=\"Ground Truth\",lw=2)\n",
    "plt.plot(x_test, e1_test_pred.detach(), label=\"Network Prediction\",lw=2)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"u\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Error Test:  0.006403361476259306 %\n"
     ]
    }
   ],
   "source": [
    "# Compute the relative L2 error norm (generalization error)\n",
    "relative_error_test = torch.mean((e1_test_pred - e1_test)**2)/torch.mean(e1_test**2)\n",
    "#relative_error_test = torch.max(torch.abs(u_test_pred -u_test))/torch.max(torch.abs(u_test))\n",
    "print(\"Relative Error Test: \", relative_error_test.detach().numpy()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Error Test:  0.026115114451386034 %\n"
     ]
    }
   ],
   "source": [
    "# Compute the relative L2 error norm (generalization error)\n",
    "relative_error_test = torch.mean((e2_test_pred - e2_test)**2)/torch.mean(e2_test**2)\n",
    "#relative_error_test = torch.max(torch.abs(u_test_pred -u_test))/torch.max(torch.abs(u_test))\n",
    "print(\"Relative Error Test: \", relative_error_test.detach().numpy()*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exact_solution_u' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m t_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100000\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_test, t_test],\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m u_test \u001b[38;5;241m=\u001b[39m \u001b[43mexact_solution_u\u001b[49m(x_test,t_test)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m p_test \u001b[38;5;241m=\u001b[39m exact_solution_p(x_test,t_test)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m u_test_pred \u001b[38;5;241m=\u001b[39m my_network(test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exact_solution_u' is not defined"
     ]
    }
   ],
   "source": [
    "model = my_network\n",
    "x_test = pi*torch.rand(100000).reshape(-1,1)\n",
    "t_test = torch.rand(100000).reshape(-1,1)\n",
    "test = torch.cat([x_test, t_test],1)\n",
    "u_test = exact_solution_u(x_test,t_test).reshape(-1,1)\n",
    "p_test = exact_solution_p(x_test,t_test).reshape(-1,1)\n",
    "u_test_pred = my_network(test)\n",
    "u_pred = u_test_pred[:, 0].reshape(-1,1)\n",
    "\n",
    "u_pred1 = u_test_pred[:, 1].reshape(-1,1)\n",
    "\n",
    "\n",
    "relative_error = torch.abs(u_pred- u_test)\n",
    "\n",
    "relative_error1 = torch.abs(u_pred1- p_test)\n",
    "u_pred = u_pred.detach().numpy()\n",
    "x_test = x_test.detach().numpy()\n",
    "t_test = t_test.detach().numpy()\n",
    "p_pred = u_pred1.detach().numpy()\n",
    "relative_error = relative_error.detach().numpy()\n",
    "relative_error1 = relative_error1.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test = x_test.reshape(-1,)\n",
    "t_test = t_test.reshape(-1,)\n",
    "\n",
    "u_pred = u_pred.reshape(-1,)\n",
    "p_pred = p_pred.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "\n",
    "\n",
    "CS = plt.tricontourf(x_test, t_test, u_pred, 20, cmap='turbo')\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(CS)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "     t.set_fontsize(20)\n",
    "\n",
    "\n",
    "plt.xlabel('x', fontsize=20)\n",
    "plt.ylabel('t', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "\n",
    "#plt.savefig('timo_u.png', dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS = plt.tricontourf(x_test, t_test, p_pred, 20, cmap='turbo')\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(CS)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "     t.set_fontsize(20)\n",
    "\n",
    "\n",
    "plt.xlabel('x', fontsize=20)\n",
    "plt.ylabel('t', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "#plt.savefig('timo_p.png', dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test = x_test.reshape(-1, )\n",
    "t_test = t_test.reshape(-1, )\n",
    "relative_error = relative_error.reshape(-1,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CS = plt.tricontourf(x_test, t_test, relative_error, 20, cmap='turbo')\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(CS)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "     t.set_fontsize(20)\n",
    "\n",
    "\n",
    "plt.xlabel('x', fontsize=20)\n",
    "plt.ylabel('t', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "#plt.savefig('relative_error_timo_u.png', dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error1 = relative_error1.reshape(-1,)\n",
    "\n",
    "CS = plt.tricontourf(x_test, t_test, relative_error1, 20, cmap='turbo')\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(CS)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "     t.set_fontsize(20)\n",
    "\n",
    "\n",
    "plt.xlabel('x', fontsize=20)\n",
    "plt.ylabel('t', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "#plt.savefig('relative_error_timo_p.png', dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
